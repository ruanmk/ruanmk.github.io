<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[C++11右值引用与完美转发]]></title>
    <url>%2F2019%2F05%2FC-11%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E4%B8%8E%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91%2F</url>
    <content type="text"><![CDATA[C++11右值引用与完美转发C++11中右值引用常与完美转发相联系在一起。在详细深入之前，我们需要了解这样几条规律： 1.”右值和左值”，”右值引用和左值引用”两组概念是独立的。具有右值引用型的变量可能是左值。凡是可以取地址的均为左值，凡是命名变量，均为左值。比如说：1234void g(int &amp;&amp; a)&#123;&#125; 其中变量a虽然具有右值引用类型，但是在函数体内却是左值，有人会问，那这个右值引用有什么意义，意义就是外面在调用f的时候，必须传一个右值才能够匹配这个g，这个右值也告诉g函数内部，这个a是可以随时被强制类型转换到右值，或者move掉的。C++在实际调用g并传入a的时候，构造实参a的过程是在函数外部进行的，函数内部不再像按值调用一样需要重新初始化a，我们看到，下列代码中a只会被初始化一次，完整代码的运行结果如下。12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;using namespace std;class A&#123;public:A()&#123; std::cout &lt;&lt; &quot;Constructor&quot; &lt;&lt; std::endl;&#125;~A()&#123; std::cout &lt;&lt; &quot;Destructor&quot; &lt;&lt; std::endl;&#125;&#125;;void f(const A&amp; a)&#123; std::cout &lt;&lt; &quot;Calling LValue Version&quot; &lt;&lt; std::endl;&#125;void f(A&amp;&amp; a)&#123; std::cout &lt;&lt; &quot;Calling RValue Version&quot; &lt;&lt; std::endl;&#125;void g(A&amp;&amp; e)&#123; std::cout &lt;&lt; &quot;sentinel 3&quot; &lt;&lt; std::endl; f(e);&#125;int main()&#123; A a; std::cout &lt;&lt; &quot;sentinel 1&quot; &lt;&lt; std::endl; g(std::move(a)); std::cout &lt;&lt; &quot;sentinel 2&quot; &lt;&lt; std::endl; return 0;&#125;// 运行结果Constructorsentinel 1sentinel 3Calling LValue Versionsentinel 2Destructor 2.万能引用必须涉及类型推导，带类型推导不一定是万能引用。带类型推导的方式有模板函数以及auto decltype组合等。例如下面的代码块是万能引用，而上面的代码块只能是右值引用。 1234567891011121314template &lt;class A&gt;void f(A&amp;&amp; a) // 万能引用&#123;&#125;void f1(const A&amp;&amp; a) // 右值引用&#123;&#125;template &lt;class A&gt;class TemplateClass&#123;public:f(A&amp;&amp; a)&#123;&#125; // 右值引用，因为实例化TemplateClass的时候类型已经确定，函数调用时无需进行类型推导。template &lt;class B&gt;f1(B&amp;&amp; b)&#123;&#125; // 万能引用，因为函数调用时依然需要推导B的类型。&#125;; 3.const T&amp;可以接受任何实参，但是优先级不是最高的，如果存在同名的接受右值的形参，那么会优先调用右值形参的函数，否则会进行强制类型转换调用左值引用，const的存在使得即使原本是一个右值实参，也不会在函数内被改变，不会造成令调用者误解的情况，同时const的存在会延长右值的生命周期，使得至少在函数体内，右值是有效的。 4.move()并不会引发实际的操作，比如下面的代码中，A a的构造析构都与move无关，move只是一种强制类型转换，或者说是一种语法糖，告诉调用者，”a现在可以被安全移走，后续不保证a是有效的”等信息。1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;using namespace std;class A&#123;public:A()&#123; std::cout &lt;&lt; &quot;Constructor&quot; &lt;&lt; std::endl;&#125;~A()&#123; std::cout &lt;&lt; &quot;Destructor&quot; &lt;&lt; std::endl;&#125;&#125;;void f(const A&amp; a)&#123; std::cout &lt;&lt; &quot;Calling LValue Version&quot; &lt;&lt; std::endl;&#125;// void f(A&amp;&amp; a)&#123;// std::cout &lt;&lt; &quot;Calling RValue Version&quot; &lt;&lt; std::endl;// &#125;int main()&#123; A a; std::cout &lt;&lt; &quot;sentinel 1&quot; &lt;&lt; std::endl; f(std::move(a)); std::cout &lt;&lt; &quot;sentinel 2&quot; &lt;&lt; std::endl; return 0;&#125;// 输出结果Constructorsentinel 1Calling LValue Versionsentinel 2 Destructor 若最后一段稍微进行修改：12345678910111213int main()&#123; std::cout &lt;&lt; &quot;sentinel 1&quot; &lt;&lt; std::endl; f(A()); std::cout &lt;&lt; &quot;sentinel 2&quot; &lt;&lt; std::endl; return 0;&#125;// 输出结果sentinel 1ConstructorCalling LValue VersionDestructorsentinel 2 模板的推导规则带模板的引用参数推导规则：要理解参数推导规则，我们先来看一下引用叠加规则，注意下面的T不一定是模板，而是实际的类：1、T&amp; + &amp; = T&amp;2、T&amp; + &amp;&amp; = T&amp;3、T&amp;&amp; + &amp; = T&amp;4、T或T&amp;&amp; + &amp;&amp; = T&amp;&amp; 我们可以看到，只要存在一个&amp;,那就按左值引用&amp;来算，而只有只出现一个或者两个&amp;&amp;才是右值引用。当然，形参实参一个&amp;都没有必然是传值调用了。于是，如果我们的函数形参定义为&amp;&amp;，那么不管传入的参数是啥，都能够保持它的引用特性。引用的折叠是编译器的特性，也就是编译器如果看到三个&amp;&amp;&amp;，会直接用一个&amp;来进行替代。引用的折叠只能够发生在类型需要推导的情况下，如果类型不需要推导而出现了多个引用符号那么编译器会直接报错，比如我们是无法定义int&amp;&amp;&amp; i=0;这样的句子的，因为不涉及类型的推导，编译器不会自动将三个&amp;换成一个。 我们将示例代码稍微进行修改，以下面这段代码为例分析一下带模板的引用参数推导规则：123456789101112void F(const Widget&amp; a);void F(Widget&amp;&amp; a);template&lt;class A&gt;void G(A &amp;&amp;a)&#123;F(a); &#125;Widget w;G(w); // 传入左值，A被推导为Widget&amp;（注意万能引用传入左值就变成左值引用）， 左值， // 调用的是void F(const Widget&amp; a);G(std::move(w)) // 传入右值，A被推导为Widget，a的类型是右值引用，但是a本身在函数G内是一个左值，因此调用的依然是void F(const Widget&amp; a); 首先分析函数G引用参数的推导规则：分为两种情况讨论（再次提醒，T是实际编程时候一个确定的类型，不是template）：1、若实参为T&amp;，则模板参数A应被推导为引用类型T&amp;。（由引用叠加规则第2点T&amp; + &amp;&amp; = T&amp;和A&amp;&amp;=T&amp;，可得出A=T&amp;）唔，换个角度，这么理解, 传入T&amp;，也就是A &amp;&amp;a = T&amp; a, 只有当A = T&amp;才能达成，因为T &amp;&amp;&amp; = T&amp;。 2、若实参为T&amp;&amp;，则模板参数A应被推导为非引用类型T。（由引用叠加规则第4点T或T&amp;&amp; + &amp;&amp; = T&amp;&amp;和A&amp;&amp;=T&amp;&amp;，可得出A=T或T&amp;&amp;，强制规定A=T）同样，如果实参是T&amp;&amp;， 那么只有当A=T或者A=T&amp;&amp;才能做到，C++直接规定，这个时候，A=T而不是T&amp;&amp;. 这一切看起来都非常自然，然而，不能够忽略的是，上述函数G的函数体内，a实际上是一个左值，只是带有右值引用的型别，因此G(std::move(w))调用的f依然是void f(const A&amp; a);,这实际上大部分时候会与调用者的需求不一致。 完美转发为了解决这样的问题，需要有一种机制，使得调用实参的左右值特性能够被保留下来，于是就有了完美转发这样的概念。即std::forward&lt;T&gt;。将上述改为：12345template&lt;class A&gt;void G(A &amp;&amp;a)&#123;F(std::forward&lt;A&gt;(a)); &#125; 则能够将a的左右值特性和其他修饰完整转发到F函数中。和move不同的是，如果G接收的实参是左值，那么forward不会像move一样强制将实参转为右值。这是怎么做到的呢？上述例子中，如果G接收实参类型为T&amp;, 那么A推导为T&amp;，此时G实例化调用的是F(std::forward&lt;T&amp;&gt;(a));如果实参类型是T&amp;&amp;， 那么A推导为T，此时G实例化调用的是F(std::forward&lt;T&gt;(a));，forward会执行强制类型转换，转为右值类型。也就是说，std::forward会自动对非引用类型进行强制类型转换到右值。一个非常简单实现的forward函数如下, 如果G被传入右值，那么T推导为A, 这时候static_cast param折叠后变成static_cast param， 是一个右值。如果G被传入左值，那么T被推导为A&amp;, 这时候static_cast param折叠后变成static_cast param，是一个左值，不会被强制类型转换。12345template&lt;typename T&gt;T&amp;&amp; forward(typename remove_reference&lt;T&gt;::type&amp; param)&#123;return static_cast&lt;T&amp;&amp;&gt; param;&#125; forward在不带模板推导的情况下是非常容易出错的，不带模板推导的情况下，forward常用错引用符号，将完美转发的结果搞反，所以如果明确知道要使用一个右值，应该用move而不是forward, forward主要是针对带有模板推导的参数转发。]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++11泛型编程]]></title>
    <url>%2F2019%2F05%2FC-11%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[C++11型别推导数组类型与指针类型的转换C++有一个一直以来大家都习以为常的特性，那就是数组名字就是数组首元素的指针。一个数组形参可以接受一个指向数组首元素指针的实参，看起来这两者是一样的，但是其实进行了某种程度的退化，如果使用不当，很可能会造成析构不当(数组部分元素没有被析构到)。注意有一种情况下，数组是不会退化成指针(也就是保留其大小信息)， 那就是被传引用调用时。 数组其实是有型别的，比如说const char name[]=&quot;hello&quot;;的型别就是const char [6], 它的引用版本(作为函数参数的时候)是 const char (&amp;)[6]。123template &lt;typename T&gt;void f(T&amp; param);void g(T param) 传引用调用的时候，利用数组类型带大小这个特点，我们能够在编译器就能够获得传入数组的大小，利用的是非类型模板参数。12345template &lt;typename T, std::size_t N&gt;constexpr std::size_t arraySize(T (&amp;)[N]) noexcept&#123;return N;&#125; auto关键字auto关键字在很多情况下和模板类型的推导是一致的，以下这种情况却需要区别对待，那就是initializer_list这一个新出的初始化变量的方法。（以后我们分别将这两种类型推导叫做模板类型推导和auto类型推导。）1234auto x1=27; //auto为intauto x2(27); // auto 为intauto x3&#123;27&#125; // auto为std::initializer_list&lt;int&gt;, 且只有一个元素，27auto x4=&#123;27&#125; //同上 auto推导会将大括号推导为initializer_list，这一点和其他推导是不同的，比如：123456789101112#include &lt;iostream&gt;using namespace std;auto x=&#123;11, 12, 13&#125;;template &lt;typename T&gt;void f(T param)&#123;std::cout &lt;&lt; &quot;I am called&quot; &lt;&lt; std::endl;&#125;;int main()&#123;f(&#123;11, 12, 13&#125;); // 错误，无法通过编译，默认不会讲花括号内转换成一个initializer_list类型。f(x); //正确， 输出I am called&#125; 另一个需要注意的是，auto用作函数返回值时，采用的是模板类型推导而不是auto类型推导，所以返回类似于{1, 2, 3}这样的initializer_list也是不被允许的。 还有一个容易被混淆的点就是auto非常类似于 模板类型推导，但是不同于函数模板参数中会保留修饰词如const, auto并不会保留（函数按值传递不保留修饰词，这里也一样，auto是复制变量时，就不会保留修饰词）。要想要保留修饰词，需要使用decltype关键字。1234Widget w;const Widget&amp; cw = w;auto myWidget1 = cw; // myWidget1是Widget类型，不再具有const和引用decltype(auto) myWidget2 = cw; // myWidget2是const Widget&amp;类型，能够保留修饰词 实际的编程中，应该多用auto来代替显式指定变量类型，以避免没必要的隐式的强制类型装换。 decltype关键字decltype一般用于返回值类型随着输入参数变化的函数，它的作用就是返回一个表达式或者一个值得型别。 decltype与C++11中的返回值型别尾序语法(trailing return type syntax)12345678910111213141516#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;template &lt;typename T, typename Index&gt;auto f(const T&amp; container, Index i) -&gt; decltype(container[i])&#123;std::cout &lt;&lt; container[i] &lt;&lt; std::endl;return container[i];&#125;int main()&#123;std::vector&lt;int&gt; v&#123;11, 12, 13&#125;; f(v, 0); //正确， 输出11&#125; 函数将会返回container[i]的类型的返回值，且是引用返回。decltype如果作用于比名字更加复杂的左值表达式中，将总是返回一个引用，比如对int x, decltype((x))将返回int&amp;, 而decltype(x)的推导结果却是int， 不带引用。这个区别只在C++14上面，自动推导返回值类型的时候比较重要，而在C++11中几乎不会用到。 非类型模板参数https://blog.csdn.net/lanchunhui/article/details/49634077 类的非类型模板参数类的非类型模板参数需要在实例化类的时候手工进行指定，而函数的非类型模板化参数则可以纯粹由编译器推导得出。非类型模板参数不允许类对象(enum除外)和浮点数，其余的是可以的。123456789101112131415161718emplate&lt;typename T, int MAXSIZE=20&gt;class Stack&#123;public:Stack():idx(0)&#123;&#125;bool empty() const &#123; return idx == 0;&#125;bool full() const &#123; return idx == MAXSIZE;&#125;void push(const T&amp;);void pop();T&amp; top();const T&amp; top() const;private:int idx; T elems[MAXSIZE];&#125;Stack&lt;int, 10&gt; stackSize10;Stack&lt;int&gt; stackSize20; //使用了缺省参数 函数的非类型模板参数形如下面的代码，不一样的是模板类型可以由推导得出，不一定需要显式传入。12345678template &lt;typename T, std::size_t N&gt;constexpr std::size_t arraySize(T (&amp;)[N]) noexcept&#123;return N;&#125;char helloStr[] = &quot;hello&quot;;arraySize(helloStr); //返回6 又如：12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;template &lt;typename T&gt;bool f(const T&amp; a, const T&amp; b)&#123;std::cout &lt;&lt; (a &gt; b) &lt;&lt; std::endl;return a &gt; b;&#125;template &lt;typename T&gt;class A&#123;public:A(T a)&#123;std::cout &lt;&lt; &quot;Constructor&quot; &lt;&lt; std::endl;&#125;&#125;;int main()&#123;f&lt;int&gt;(0, 1); //正确， f(0, 1); //正确，T会被正确推导 A&lt;int&gt; a(1); // 正确A b(1); // 错误，编译不通过&#125; C++泛型编程以及函数重载 enable_if_t enable_if SFINAE(Substitution Failure Is Not An Error)123456789101112long multiply(int i, int j) &#123; return i * j; &#125;template &lt;class T&gt;typename T::multiplication_result multiply(T t1, T t2)&#123;return t1 * t2;&#125;int main(void)&#123;multiply(4, 5);&#125; main 函数调用 multiply 会使编译器会尽可能去匹配所有候选函数，虽然第一个 multiply 函数明显是较优的匹配，但是为了得到一个最精确的匹配，编译器依然会尝试去匹配剩下的候选函数，此时就会去推导 第二个multiply 函数，中间在参数推导的过程中出现了一个无效的类型 int::multiplication_result ，但是因为 SFINAE 原则并不会报错。 待续]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[颜色模型与显示]]></title>
    <url>%2F2019%2F04%2F%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%98%BE%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[导言总用有五类颜色模型，分别是：CIE, RGB, YUV, HSL/HSV, and CMYK 来自色彩空间中的HSL、HSV、HSB有什么区别？ - MoonCancer的回答 - 知乎https://www.zhihu.com/question/22077462/answer/105844680 的回答可以很好地解释描述颜色的几个重要的方面： 色相（表，表现）：即色彩的相貌和特征。自然界中色彩的种类很多，色相指色彩的种类和名称。如；红、橙、黄、绿、青、蓝、紫等等颜色的种类变化就叫色相。明度（表，面子）：指色彩的亮度或明度，也叫明亮度。颜色有深浅、明暗的变化。比如，深黄、中黄、淡黄、柠檬黄等黄颜色在明度上就不一样，紫红、深红、玫瑰红、大红、朱红、桔红等红颜色在亮度上也不尽相同。这些颜色在明暗、深浅上的不同变化，也就是色彩的又一重要特征一一明度变化。色彩的明度变化有许多种情况，一是不同色相之间的明度变化。如：白比黄亮、黄比橙亮、橙比红亮、红比紫亮、紫比黑亮；二是在某种颜色中加白色，亮度就会逐渐提高，加黑色亮度就会变暗，但同时它们的纯度(颜色的饱和度)就会降低，三是相同的颜色，因光线照射的强弱不同也会产生不同的明暗变化。。纯度（里，里子）：指色彩的鲜艳程度，也叫饱和度。原色是纯度最高的色彩。颜色混合的次数越多，纯度越低，反之，纯度则高。原色中混入补色，纯度会立即降低、变灰。物体本身的色彩，也有纯度高低之分，西红柿与苹果相比，西红柿的纯度高些，苹果的纯度低些。 所谓的颜色模型，大都是在这几个方面进行的描述。 CIE颜色模型CIE是首个基于人类对颜色的感受来定义的颜色空间，后续也有一些改进版本，计算机视觉中接触较少，这里不多展开。 RGB颜色模型RGB模型是最容易理解的一个颜色模型了，RGB不是一种颜色空间，而是一种颜色模型，因为RGB以及其颜色混合是符合物理意义的，它的三个值都是代表着实际的物理意义。 sRGB主要用于互联网的图片，这涉及到一个叫做gamma校正的知识点，gamma校正也是一种常见的预处理方法。gamma校正主要原因是RGB是一种线性的模型，认为(0.5, 0, 0)的颜色亮度就是(1.0, 0, 0)的一半，但是显示器实际上并不是线性的。 YUV或者YIQ, YCbCr等。YUV中的Y是Luminance，流明，也就是明度，UV则用于指定色彩（色相）和饱和度(纯度)，YUV的产生主要是为了分离出灰度图，如果YUV只有Y，那么也是能够显示出来的，只不过只能够显示出灰度图而不带有颜色。 YCbCr是YUV的翻版，属于YUV系列，Y依然是明度，但是Cb和Cr则是蓝色色度和红色色度的分量。我们知道，灰度可以由RGB三个分量计算得出，那么如果知道RB和灰度，其实也是可以推算回来G的，这也是为什么大部分颜色空间都是三维的，因为最终基于的颜色模型就是只有三维，再怎么转换秩也不会提升，多余三维的都是因为某种目的故意添加冗余信息。 YCbCr 有许多取样格式，主要的采样格式有YCbCr 4:2:0、YCbCr 4:2:2、YCbCr 4:1:1和 YCbCr 4:4:4。其中YCbCr 4:1:1 比较常用，其含义为：每个点保存一个 8bit 的亮度值（也就是Y值），每 2x2 个点保存一个 Cr 和Cb 值，图像在肉眼中的感觉不会起太大的变化。所以，原来用 RGB(R,G,B 都是 8bit unsigned) 模型，每个点需要 8x3=24 bits（如下图第一个图）. 而使用YUV411仅需要 $8+(8/4)+(8/4)=12bits$，平均每个点占12bits。这样就把图像的数据压缩了一半。简而言之，就是认为人眼看的没那么精细，就让多个像素点共用一个颜色值来粗暴地达到压缩的效果。 YUV 444，未经压缩的版本 YUV 411, 水平每四个像素共用一个色度 YUV 422， 水平每两个像素共用一个色度 YUV 420， 这个有点特殊，也比较神奇。420不是说Cr就不要了，而是Cr和Cb轮流着要。什么意思呢，就是说，水平方向，第一行每两个像素抽一个Cr, 第二行每两个像素抽一个Cb，上下两行共享Cr和Cb，也就是说第一行用第二行的Cb, 第二行用第一行的Cr。这样子，一个2x2的像素框中，存4个Y值，1个Cr和一个Cb值，共需要六个byte， 比RGB需要的4 * 3 =12 bytes减少一倍。 HSV(又叫HSB)或者HSLHSV(HSB)或者HSL实际上是RGB颜色模型转换到柱坐标空间。也就是说，它们并不是一种新的颜色模型，只是RGB用某种方式由柱坐标所表示出来而已，RGB对于计算机非常友好，但是对于艺术创造者就不是了，很简单的例子，没人能说请往RGB三个通道进行调整所代表的颜色变动，人眼一般只能区分颜色，亮度，饱和度这样感性的问题 。HSV转换后的空间是: H (hue), S (saturation), V (value)，最后一个值也可以叫做B (brightness)，也就是 HSV == HSB，完全只是冠名权不同。HSV更多的是被艺术创造者所使用，因为它的三个值能够最直观地反映颜色的感官的变化。 HSL和HSV非常类似，只是L代表(Lightness)，和HSV的前两个字母虽然一样，但是实际空间是不一样的，只是用了一样的名字罢了。 HSB 和 HSL 在字面意思上是一样的： H 指的是色相（Hue），就是颜色名称，例如“红色”、“蓝色”； S 指的是饱和度（Saturation），即颜色的纯度； L（Lightness） 和 B（Brightness）是明度，颜色的明亮程度在原理和表现上，HSL 和 HSB 中的 H（色相） 完全一致，但二者的 S（饱和度）不一样， L 和 B （明度 ）也不一样： HSB 中的 S 控制纯色中混入白色的量，值越大，白色越少，颜色越纯； HSB 中的 B 控制纯色中混入黑色的量，值越大，黑色越少，明度越高 HSL 中的 S 和黑白没有关系，饱和度不控制颜色中混入黑白的多寡； HSL 中的 L 控制纯色中的混入的黑白两种颜色。 gamma校正当我们计算出场景中所有元素的最终颜色(RGB)后，我们必须将颜色显示到显示器上，但是显示器的显示能力是不同的，计算机的真彩色65535显示器并不能全部显示出来。显示器有一个物理特性，就是两倍的输入电压产生的并不是两倍的亮度，传统的CRT显示器输入电压产生的亮度约为输入电压（注意电压已经被归一化到0-1范围）的2.2次幂，这个2.2被称为显示器的gamma值。由gamma值我们知道显示器的亮度输出并不是线性的，线性的亮度输出需要非线性的电压调节。每一种设备都有其特定的gamma值，任何设备的gamma值基本不会等于1，等于1的设备是一种理想的线性的状态。 上图是人眼感受亮度和实际物理亮度的对比，人眼对比较暗的亮度变化比较敏感，对于比较亮的部分的变化则不那么敏感，上图中上面一行是人感受到的亮度变化，而下面一行则是光子数量的变化。可以看到，上面一行亮度由0.3到0.6,视觉上相当于下面一行0.1到0.2的变化。 我们从0.1到0.2这一档就可以看出，光子数量无需增加一倍，人眼感受到的亮度已经增加了一倍。而在亮的部分，下面一行(光子数)从0.7变化到1.0, 人眼感受到的亮度变化则几乎不变。人眼感受到的亮度这样的变化规律和显示器的gamma规律其实是非常接近的，这也是用gamma的一个原因，举个例子，假如gamma是2， 输入电压从0.1到0.2，实际上显示器显示的亮度是从$0.1^2$变成$0.2^2 = (0.1 + 0.1)^2 = 4 x 0.1^2$, 变成了四倍，而光子亮度（与电压相关）则只是增长了一倍。同样可以尝试比较下电压从0.9到1.0, 显示亮度 CRT中，物理亮度为电压的2.2次幂，而对于人眼，物理亮度也是人眼感受亮度的2次幂，这就解决了显示器亮度非线性的问题，因为非线性显示的亮度反而更加贴合人的肉眼观感，换句话说，我们只需线性变化电压即可获得线性的人眼感受亮度。在RGB颜色中，我们可以认为1就是最大电压，也就是颜色(1, 0, 0)就是强度最大的红色光。 在渲染图像时，又会产生另外的一种问题，这是因为大部分算法都假设是在线性空间里工作的，认为颜色的大小代表他的强度，是线性的。举个例子，(1.0, 0,0)代表红色，而(0.5, 0,0)就是强度减半的红色。不幸的是，在显示器中显示出来时，(1.0.0)依然是(1, 0, 0)但是， (0.5, 0, 0)则是(0.28, 0, 0)了，也就是强度不再是翻倍的关系，而是接近4.5倍。如果每个颜色都是人工调出来的还好，设计师的肉眼能够自动进行校正，本身就是在一个非线性的颜色空间里面工作，只要肉眼看起来强度是两倍就行了，不管实际的电压已经不是2倍关系。但是渲染还有一些计算光照等的算法可不是人眼，它假设就是颜色强度是线性的，0.5和1就能够产生强度是两倍而不是4.5倍的肉眼效果。这就是为啥需要对颜色进行gamma校正。校正的做法就是将颜色强度首先进行一定程度的加强，然后让显示器显示出来。上图中， 为了获得线性的颜色输出，我们将(0.5, 0,0 )进行以下转换： $(0.5, 0,0)^{\frac{1}{2.2}} =(0.5, 0,0)^{0.45}=(0.73, 0,0)$。然后显示出来的时候再被显示器进行一次转换变回0.5,$(0.5, 0,0)^{\frac{1}{2.2}}*(0.5, 0,0)^{2.2} =(0.5, 0,0)$ ，这样子，我们的颜色依然可以在线性空间中计算，只是显示到显示器之前进行一次gamma校正，这样，设计师在实际设计的时候也会在线性空间中进行，算法计算出来的结果也在该空间，就不会造成冲突了。从工作原理我们可以看到，gamma校正应该只在输出到显示器之前做一次，否则进行多次gamma校正会使得强度过大而失真。 CMYKCMKT是用于打印机的颜色模型，由于打印机是反射光，和RGB这样的光源不同，其颜色模型也是不同的，反射光用的是一种减法模型，白纸是能够反射所有光线的，颜料涂上去后，则只能反射颜料的颜色了。CMYK存储了四种基色，青色 Cyan， 品红 （magenta， 偏紫色的红色），黄色 Yellow和黑色 Dark， 我们知道，黑色就是从白色中减去所有的颜色得到的最终颜色。CMYK主要用于打印，这里不再继续展开。]]></content>
      <categories>
        <category>理论基础</category>
        <category>图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PCA推导]]></title>
    <url>%2F2019%2F04%2FPCA%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[PCA原理在介绍PCA的原理前，首先回顾一下坐标系的变换以及向量的点积。两个向量的点乘代表着一个向量在另一个向量方向上的投影，并乘上另一个向量的长度。如果另一个向量刚好是单位向量，那就纯粹是一个向量在另一个单位向量上的投影：$\frac{\vec{a}\vec{b}}{|\vec{a}|} = |\vec{b}|cos\theta$。回顾坐标系，一个向量在某个坐标系的坐标分别是该向量在各坐标轴上的投影长度，因此向量的坐标可以由其在某坐标系$x’Oy’$的坐标$x’, y’$与各坐标轴方向的单位向量的乘积得出。举个例子，在平面直角坐标系中，向量(1, 1)的坐标就是(1, 1)，如果将其坐标系整体逆时针旋转45度，即新的坐标轴变成 $(\frac{\sqrt{2}}{2}, \frac{\sqrt{2}}{2})$以及$(\frac{-\sqrt{2}}{2}, \frac{\sqrt{2}}{2})$，那么新的坐标将变成： \begin{vmatrix} \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} \\ \frac{-\sqrt{2}}{2}& \frac{\sqrt{2}}{2} \end{vmatrix} \cdot \begin{vmatrix} 1 \\ 1 \end{vmatrix} = \begin{vmatrix} \sqrt{2} \\ 0 \end{vmatrix}PCA的作用就是给原始数据找一个新的坐标系，使得数据在新的坐标系下，每个字段方差最大，也就是最容易区分彼此，尽可能保留原始数据。假设这样的一个新的坐标系记为$H$, 其中$H$每一行向量都是新坐标系的每一个坐标轴坐标，是单位向量，而数据矩阵$X$每一列就是原始的一个数据样本。因此经过PCA转换后的坐标为： Z=HX在这里，我们假设X已经进行中心化，也就是所有样本每一维的均值都是0，我们还希望转换后每一个样本尽可能分散分布，也就是转换后的坐标字段间协方差最大，防止出现冗余数据，尽量加大压缩比例。总结而言就是两个目标： 字段方差最大，从而保留尽可能多的信息 字段间协方差最大，尽量减少冗余信息 即： argmax_H ZZ^T = argmax_H HXX^TH^T这里我们解释下为什么需要$ZZ^T$而不是$Z^TZ$等之类的其他式子最大：我们知道，$Z$的每一列都是一个新的样本(sample)，每一行是坐标的一维，或称一个字段，那么$ZZ^T$的对角线就是每一个字段的方差和，第i行第j列的元素表示第i个字段和第j个字段的协方差。注意，是字段的方差和协方差，直接讨论样本的方差和协方差（即$Z^TZ$）是没有意义的，下面我们再解释为什么。同时我们知道，转换后的坐标系彼此之间应该线性无关，为什么呢，因为仅凭上述约束条件，$H$的每一行的约束没有差别，将得到完全一样的结果。因此我们有一个额外的约束就是$H$每行向量单位正交，也就是： HH^T = I综上，使用拉格朗日乘子法，列出： f(H, XX^T) = HXX^TH^T - \vec{\alpha} (HH^T-I)分别求导得： \begin{align} \frac{df}{dH} = 2XX^TH^T - 2\vec{\alpha} H^T &= 0 \\ \Rightarrow XX^TH^T &= \vec{\alpha} H^T \\ \end{align}显然$H$是$XX^T$的特征向量，代回$f(H, XX^T)$得$f(H, XX^T) = \vec{\alpha} I$注意理解时将$f$拆开成一行一行来看，每一行的最大化实际上就是最大化这一行对应的特征值，由此可知，若$\vec{\alpha}$取$XX^T$最大的前k个特征值便可最大化$f$，与此相对应，H总共有k行，每一行是对应的特征向量。 P.S. 解释下为什么$Z^TZ$没有意义，因为不管哪个假设，我们都限定了$H$是单位正交，我们有： Z^TZ =X^TH^THX = X^TX也就是，$Z^TZ$根本与$H$的选取无关，如果$H$满足单位正交矩阵的性质。 整体流程 首先对$X$进行中心化 求出$XX^T$的特征值和特征向量 根据要求，取前k大特征值及其对应的特征向量，特征向量作为$H$每行的向量，转换后的数据为$Z = H\cdot X$]]></content>
      <categories>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CMake基础]]></title>
    <url>%2F2019%2F03%2FCMake%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[主要参考资料https://cmake.org/cmake/help/v3.14/manual/cmake-language.7.html这份资料将cmake的语言特性完全讲述，是了解其他所有模块的基础。 cmake的组织cmake主要有两个类型的文件 CMakeLists.txt以及 *.cmake，按照逻辑分为三种： Directory (每个目录下面的CMakeLists.txt) Scripts&lt;Scripts&gt;.cmake Modules&lt;Module&gt;.cmake最顶层的CMakeLists.txt是通过cmake .. 来进行调用的，子模块的CMakeList.txt则通过上层的add_subdirectory()来引用。不管后缀名是.txt还是.cmake，实际上就类似于一个shell脚本。Script是另外一种，需要通过 cmake -P &lt;scripts&gt;.script来执行。script不会产生build system，不能定义target。Modules可以由Directory或者Scripts进行调用，详细可以看 cmake-modules， modules通过include()来调用。 CMake的编写CMake需要使用全英文编写，因为只有7位ASCII可以跨更多的平台使用。 variablecmake的variable是cmake的基础存储单元，很多命令都是以variable的方式进行存储的。variable的类型只有string一种，即使是逻辑上的int，bool之类的数据类型，也只不过是解析时候转换成相应的类型而已。直接修改variable的命令只有set和unset两个，其余的命令均为间接的方式进行的。 变量的引用采用${&lt;variable&gt;} 的方式，并且支持嵌套，${outer_${inner_variable}_variable}， 这样就variable有相应的作用域，一共有三种作用域： Function Scope在function()…endfunction()之间的代码，如果不指定PARENT_SCOPE, 那么所有的变量定义都只在该函数内有效(通过参数传进来的外部变量不受此限制)， 也就是说在function scope内部定义的变量只能在function内部及其嵌套子函数内部有效。 Directory Scope每一个目录下的CMakeLists.txt都使用一个特定的scope，该scope会继承所有父级目录的变量，因此可以默认使用来自上一级目录的变量。 Persistent CacheCache entries have an isolated binding scope modified only by explicit request, such as by the CACHE option of the set() and unset() commands. 要添加或者修改cache变量必须要显式指定，否则cache变量将一直独立存在。cache优先级是最低的, 优先级排序是function &gt; directory &gt; cache。看官网的这一段描述。 When evaluating Variable References, CMake first searches the function call stack, if any, for a binding and then falls back to the binding in the current directory scope, if any. If a “set” binding is found, its value is used. If an “unset” binding is found, or no binding is found, CMake then searches for a cache entry. If a cache entry is found, its value is used. Otherwise, the variable reference evaluates to an empty string. 如果希望修改Parent Scope的变量，需要加上parent scope这个参数。否则，修改只会在当前scope生效。注意，cache变量时独立一个scope，无所谓parent variable的set以及unsetnormal variableSet Normal Variableset( … [PARENT_SCOPE])Set the given in the current function or directory scope. If the PARENT_SCOPE option is given the variable will be set in the scope above the current scope. Each new directory or function creates a new scope. This command will set the value of a variable into the parent directory or calling function (whichever is applicable to the case at hand). cache variableset(&lt;variable&gt; &lt;value&gt;... CACHE &lt;type&gt; &lt;docstring&gt; [FORCE])Since cache entries are meant to provide user-settable values this does not overwrite existing cache entries by default. Use the FORCE option to overwrite existing entries.这个用来定义默认变量最好了，如果不开启force, 那么在存在这个变量时，将不会改变，这样子如果用户提供了参数，那么默认参数就不会生效。cache变量还需要指定type，The must be specified as one of: BOOLBoolean ON/OFF value. cmake-gui(1) offers a checkbox. FILEPATHPath to a file on disk. cmake-gui(1) offers a file dialog. PATHPath to a directory on disk. cmake-gui(1) offers a file dialog. STRINGA line of text. cmake-gui(1) offers a text field or a drop-down selection if the STRINGS cache entry property is set. INTERNALA line of text. cmake-gui(1) does not show internal entries. They may be used to store variables persistently across runs. Use of this type implies FORCE. Set Environment Variableset(ENV{&lt;variable&gt;} &lt;value&gt;...) listlist实际上是一个有特殊格式的string, 但是通过分号隔开， 如果想要打一个分号，那必须通过转义字符。建立list有以下几种方式：set(srcs a.c b.c c.c) # sets &quot;srcs&quot; to &quot;a.c;b.c;c.c&quot;或者： set(x a &quot;b;c&quot;) # sets &quot;x&quot; to &quot;a;b;c&quot;, not &quot;a;b\;c&quot; cmake的variable分为normal, cache, environment三种。 functioncmake的function定义规则如下：function(&lt;name&gt; [arg1 [arg2 [arg3 ...]]]) COMMAND1(ARGS ...) COMMAND2(ARGS ...) ... endfunction(&lt;name&gt;)]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[神经网络结构术语合集]]></title>
    <url>%2F2019%2F01%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%9C%AF%E8%AF%AD%E5%90%88%E9%9B%86%2F</url>
    <content type="text"><![CDATA[导言快速过一遍计算机视觉中用到的网络结构的名词描述。 Inception V1-V3 Inception系列InceptionV1 https://zhuanlan.zhihu.com/p/30756181InceptionV2 + InceptionV3 https://arxiv.org/pdf/1512.00567.pdf 设计思想主要来自InceptionV2V3的论文： https://arxiv.org/pdf/1512.00567.pdf Avoid representational bottlenecks, especially early in the network. Feed-forward networks can be represented by an acyclic graph from the input layer(s) to the classifier or regressor. This defines a clear direction for the information flow. For any cut separating the inputs from the outputs, one can access the amount of information passing though the cut. One should avoidbottlenecks with extreme compression. In general the representation size should gently decrease from the inputs to the outputs before reaching the final representation used for the task at hand. Theoretically, information content can not be assessed merely by the dimensionality of the representation as it discards important factors like correlation structure; the dimensionality merely provides a rough estimate of information content.第一条就是不要尝试在网络早期就将网络的信息压缩到太小，被前面网络去除掉的信息是不能够被后续找回的，因为CNN是一个无环路的图。 Higher dimensional representations are easier to process locally within a network. Increasing the activations per tile in a convolutional network allows for more disentangled features. The resulting networks will train faster.第二条的意思就是，更加高维的输入会更加方便寻找local feature, 也就是更加方便cnn来获得局部特征，因此神经网络的激活神经元应该高一些，保留的激活部分多一些，而不是压抑激活单元。 Spatial aggregation can be done over lower dimensional embeddings without much or any loss in representational power. For example, before performing a more spread out (e.g. 3 × 3) convolution, one can reduce the dimension of the input representation before the spatial aggregation without expecting serious adverse effects. We hypothesize that the reason for that is the strong correlation between adjacent unit results in much less loss of information during dimension reduction, if the outputs are used in a spatial aggregation context. Given that these signals should be easily compressible, the dimension reduction even promotes faster learning.第三条说的是，在底层的特征可以先压缩再进行卷积，并不会影响到最终的效果，这个假设成立的前提就是，上一层的神经网络输出存在相关性，允许被压缩。注意到这条和第一条是稍微有一些相反的，第一条建议的是不要过快进行信息的压缩，而这里提出的是可以先进行1x1压缩再进行卷积是不会对最终结果有太大影响。这里的度就是玄学所在了。 Balance the width and depth of the network. Optimal performance of the network can be reached by balancing the number of filters per stage and the depth of the network. Increasing both the width and the depth of the network can contribute to higher quality networks. However, the optimal improvement for a constant amount of computation can be reached if both areincreased in parallel. The computational budget should therefore be distributed in a balanced way between the depth and width of the network.第四条就更玄学了，增加网络的宽(每层更多的filter)和深(更深的网络，少用stride)都能够提高网络的表达能力，但是特定的计算能力预算下，怎样分配宽和深是一个不容易，甚至是玄学的事情。唔，道理都懂…其实有没有人想过为什么CNN一层一层垒在一起就能够有这么强的表达能力？ Inception系列网络Inception系列网络可以参考这个链接： https://zhuanlan.zhihu.com/p/30756181Inception是一种常见的模块，其作用是在同一层获得不同scale的卷积结果。scale在物体检测领域是非常重要的一个参数，设计再良好的特征，如果scale不对也很难获得好的检测结果，当前基于RPN或者基于Anchor的two-stage detection主要也是致力于解决scale问题，因为数据刷到现在，难点一般都是对小的物体存在大量的漏检，而增强对小物体的检测能力（recall）一般又会伴随而来是大量的误检(FP)。Inception系列网络最主要的思想就是在同一层卷积神经网络里面并行多个卷积核，并将卷积结果concat起来，从而在同一层中就能够获得不同感受野的feature map。 第一代GoogleNet提出InceptionV1论文来自： https://arxiv.org/pdf/1409.4842.pdf 图1 为什么能够用1x1来进行channel数量的缩减，因为存在这样的一个假设，在神经网络最后的输出层里面，feature map有多个部分是高度相关的，可以按照相关性分为多个组，每个组可以认为是抓住了原图像中特定的区域或者特定的特征，换句话说，信息存在冗余，这是可以用1x1来进行reduce的理论基础。 同样的，文章认为，这些相关组有些cover的区域比较小，有些比较大，这就要求同一层同scale的卷积应该有多种卷积核，至于为什么采用3x3 5x5并不是因为经过精确计算这些大小的核符合要求，而是因为方便和常用，有现成的实现。 由于高层网络更应该抓住高层信息，因此论文建议，越高的层，其3x3, 5x5的卷积核应该相应地增多。当然，实际上并没有这么做，因为会额外增加网络设计的复杂性，同时这个也是非常heuristic的想法，需要手工进行设置。 有人会比较好奇，3x3, 5x5之后的结果怎样进行concate，大小不是不一致的吗，其实主要是通过对原图padding然后进行convolution得到的，比如3x3比5x5输出feature map大小是要大2的，只需要让5x5padding为1（两边共补2）就可以了。看这个tensorflow实现的方法：12345678910111213141516171819202122232425262728import d2lzh as d2lfrom mxnet import gluon, init, ndfrom mxnet.gluon import nnclass Inception(nn.Block): # c1 - c4为每条线路里的层的输出通道数 def __init__(self, c1, c2, c3, c4, **kwargs): super(Inception, self).__init__(**kwargs) # 线路1，单1 x 1卷积层 self.p1_1 = nn.Conv2D(c1, kernel_size=1, activation=&apos;relu&apos;) # 线路2，1 x 1卷积层后接3 x 3卷积层 self.p2_1 = nn.Conv2D(c2[0], kernel_size=1, activation=&apos;relu&apos;) self.p2_2 = nn.Conv2D(c2[1], kernel_size=3, padding=1, activation=&apos;relu&apos;) # 线路3，1 x 1卷积层后接5 x 5卷积层 self.p3_1 = nn.Conv2D(c3[0], kernel_size=1, activation=&apos;relu&apos;) self.p3_2 = nn.Conv2D(c3[1], kernel_size=5, padding=2, activation=&apos;relu&apos;) # 线路4，3 x 3最大池化层后接1 x 1卷积层 self.p4_1 = nn.MaxPool2D(pool_size=3, strides=1, padding=1) self.p4_2 = nn.Conv2D(c4, kernel_size=1, activation=&apos;relu&apos;) def forward(self, x): p1 = self.p1_1(x) p2 = self.p2_2(self.p2_1(x)) p3 = self.p3_2(self.p3_1(x)) p4 = self.p4_2(self.p4_1(x)) return nd.concat(p1, p2, p3, p4, dim=1) # 在通道维上连结输出 其中1x1, 3x3, 5x5分别pad 0， 1， 2个像素，来使得输出和输入大小一致。 Inception V2 在V1基础上，添加了Batch Norm 用两个3x3代替一个5x5， 参数量减少，同时增加了网络的深度，计算到的感受野却没有改变。 作者想，那能不能用2x2或者更小的卷积核来替代大核呢，于是，极端地，作者认为可以用1xn和nx1的组合来替代一个nxn的大核。这样的替代在中层（输入大小从12到20部分）是有效的，但是不能够被用于底层，也就是一开始几层。原因没有进一步说明。用1xn和nx1来替代n x n, 同样减少参数，同时增加了网络深度。实验证明，在中间层网络，用1x7和7x1的效果不错。(玄学) 增加输出的channel数量(原则2)，如下图所示，将3x3拆成1x3和3x1两个平行的channel(注意不是串联)，从而保留高维的表达。 图2 可以使用并行结构来优化Pooling。前面的规则1提到Pooling会造成represtation bottleneck，一种解决办法就是在Pooling前用1x1卷积把特征数加倍（见图3右侧），这种加倍可以理解加入了冗余的特征，然后再作Pooling就只是把冗余的信息重新去掉，没有减少信息量。这种方法有很好的效果但因为加入了1x1卷积会极大的增大 计算量。替代的方法是使用两个并行的支路，一路1x1卷积，由于特征维度没有加倍计算量相比之前减少了一倍，一路是Pooling，最后再在特征维度拼合到一起（见图4）。这种方法即有很好的效果，又没有增大计算量。图3图4Inception V3 Inception V2 + 辅助的分类器就变成了v3。 这个新的思想就是使用一个分类器来筛选有用的梯度，使得有效信息能够传回到底层网络，避免梯度消失等情况。这个相当于早期的监督信息，这个输出层插在网络的中间，可以理解为将梯度回传的起始点设置在了中间，辅助整体的学习。 Inception V4https://arxiv.org/pdf/1602.07261.pdf在此基础上，添加stem模块，Inception A， B， C， Reduction A， B等。 Reduction主要的区别就是不是直接pool为2，而是分了几个分支做stride为2的conv。实际上感觉没有InceptionV2, V3那样的比较根本性的创新。 ResnetResnet残差结构是神经网络另外一个神仙操作，可以较好地解决梯度消失等困难。使用残差结构的比较经典的论文有ResNet, DenseNet和SENet等。 ResnetResNet的一个重大创新设计就是这个Residual block DenseNet 使用DenseBlock，每一个block的输出都会直接输入到后面的每一个Block DenseBlock之间加入过渡层(Transition Layer)，实质就是1x1卷积核一个stride&gt;1的pooling操作， 当然作者选择了stride=2 Spatial and Channel AttentionSENethttps://arxiv.org/pdf/1709.01507.pdfSqueeze-and-Excitation Net, SE网络对每一个输出通道计算一个重要性权重加在输出feature中。这个权重是通过几层FC和激活得到的。应该也属于某种程度的attention. SCA-CNNhttps://arxiv.org/pdf/1611.05594.pdfCNN领域Attention的经典之作。待续… 移动端优化方面MobileNetShuffleNet]]></content>
      <categories>
        <category>理论基础</category>
        <category>神经网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[配置PyCharm远程调试并本地显示matplotlib图像]]></title>
    <url>%2F2018%2F10%2F%E9%85%8D%E7%BD%AEPyCharm%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E5%B9%B6%E6%9C%AC%E5%9C%B0%E6%98%BE%E7%A4%BAmatplotlib%E5%9B%BE%E5%83%8F%2F</url>
    <content type="text"><![CDATA[背景远程机器为Ubuntu，本地机器为Linux、Mac、Window均可，这里以Mac为例。需要在Pycharm远程执行调试，但是部分中间结果，特别是图像处理结果通过matplotlib即时显示在本地机器上。该功能依赖X11forward。 远程机器（Ubuntu）需要执行的操作首先开启openssh-server的X11转发1、1sudo vim /etc/ssh/sshd_config 2、找到相应的项并修改为以下值：123X11Forwarding yesX11DisplayOffset 10X11UseLocalhost no 3、重启ssh服务 安装openbox1sudo apt-get install openbox 本地机器（Mac）需要执行的操作首先安装xquartz1brew install caskroom/cask/xquartz 其次开启ssh的X11，由于我们直接用PyCharm的shell，因此就改Pycharm即可1、通过Pycharm-&gt;Run-&gt;Edit Configurations，添加一条python的环境变量1DISPLAY=thucloud-PowerEdge-T630:10.0; 其中DISPLAY的值需要由以下命令获得：通过命令ssh -X user@IP连接到远程主机,执行echo $DISPLAY即可获得DISPLAY的值，将这个值填在Pycharm的环境变量里即可。注意，如果这个DISPLAY的值是空的，证明配置不对。 大功告成]]></content>
      <categories>
        <category>系统</category>
        <category>环境配置</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络爬虫SCRAPY爬取GOOGLE PLAY APPS]]></title>
    <url>%2F2018%2F10%2F%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%ABSCRAPY%E7%88%AC%E5%8F%96GOOGLE-PLAY-APPS%2F</url>
    <content type="text"><![CDATA[Scrapy框架介绍scrapy作为一种可以轻易扩展为分布式的爬虫框架，其内部框架采用类似于消息队列的方式进行任务的调度分发也就不奇怪了，消息队列使得各组件低耦合。至于这个消息队列是存在于单机内存中还是分布式集群中的一个节点，就看业务的需要了。采用生产者-消费者模式进行组织的系统实际上就是三块：任务的生产者，消费者以及消息队列。对应框架图上：生产者：Spiders消费者：Downloader消息队列：Scheduler以及Engine各部分组件由Engine进行驱动，Engine可以看做是一个main函数吧。生产者生产任务（在这里就是要爬取的url）放到消息队列，消费者从消息队列中取得任务进行实际的下载。下载结果交给生产者进行解析，解析结果的一部分是我们要提取的信息，它直接进入Pipeline进行处理，另一部分则是从下载结果中提取的新的任务（url），它将进入消息队列中。整个流程是： (1)一开始Scheduler的队列是空的，所以需要人工hard code一个起始的种子url列表，spider将这些url封装成Request，Engine将这些Request转给Scheduler (2)与此同时，一旦Scheduler队列非空，Engine将从Scheduler中抽取一个Request给Downloader进行实际下载，Downloader的产出即Response由engine转给spider (3)Spider抽取Response里面两类信息：第一类就是页面上我们实际要爬取的内容Item，以及这个页面包含的符合要求的url列表。Item由Engine转入Item的深层加工流水线Pipeline，进行进一步的筛选、存储等， url由Spider封装为Request经由Engine交给Scheduler。重复(2)框架图中engine和各组件交换Request和Response的过程中可以插入各种额外的流程，称之为中间件，所以不难想象一共有两种种中间件：Downloader middlewares(对应图中4，5)和 Spider middlewares(对应图中6，7)。除此之外，Item Pipeline中可以插入处理Item的各个步骤。 工程框架我们以爬取google play上面apk应用的信息为例。安装完scrapy后，可以采用scrapy startproject gglplay来创建一个叫做gglplay的爬虫工程，其结构如下：项目框架其中settings.py类似于一种静态配置文件，所有增加的中间件以及pipeline等都需要在settings中进行注册，类似于Android的manifest这样的角色。run_spider.py是人工添加进去的，下面会说到。 Spider首先，创建的项目中是没有默认Spider的，需要手工新建一个Spider类，继承scrapy.Spider或它的子类。也可以采用scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt; 来根据模板生成一个spider。 所有新增的Spider都需要放在spider文件夹下。 name变量每一个Spider的关键变量就是 name， 在启动的时候通过name来搜索这个spider。比如说scrapy crawl gglplay就启动了一个name=&#39;gglplay&#39;的爬虫。新增爬虫无需更新settings，只需要保证每个Spider都有唯一的name就好了。 allow_domains爬虫允许爬取的域 start_urls如上面所介绍，就是起始的url，种子url rule定义url匹配了某个规则后，用什么样的parse函数进行内容提取。比如说：Rule(LinkExtractor(allow=(“/store/apps/details”,)), callback=’parse_app’, follow=True)就定义了一旦LinkExtractor获得了匹配的url，那么对这个url进行下载后的内容将由parse_app这一个回调函数进行处理。这样子就能使得每个不同的页面，对应不同的parse函数，不会说要一个parse函数去处理所有的页面，毕竟格式不同，xpath不同，所需的信息也不同。MiddlewaresMiddleware分为Downloader middlewares和Spider middlewares。但是需要注意的是，Middleware需要在setting进行注册，定义middleware的处理顺序。 Spider middlewaresSpider middlewares在Spider的输入和输出做文章，所以关键的两个钩子就是process_spider_input和process_spider_output,都是顾名思义的了。12345678910111213141516171819class GglplaySpiderMiddleware(object): def process_spider_input(self, response, spider): # Called for each response that goes through the spider # middleware and into the spider. # Should return None or raise an exception. return None def process_spider_output(self, response, result, spider): # Called with the results returned from the Spider, after # it has processed the response. # Must return an iterable of Request, dict or Item objects. for i in result: # if result[&apos;package&apos;] not in spider.bf: # spider.bf.add(result[&apos;package&apos;]) # yield i # else: # continue yield i 在settings中的注册语句：123SPIDER_MIDDLEWARES = &#123; &apos;gglplay.middlewares.GglplaySpiderMiddleware&apos;: 543,&#125; 关于Spider Middleware，详细可以看http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html Downloader MiddlewareDownloader Middleware和Spider Middleware几乎一样，详细可以看：http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html Item Pipeline一般在Item Pipeline中进行item的筛选，持久化存储等工作，如果Pipeline中某个item被认定为需要丢弃，可以通过raise DropItem来发起，该Item就不会再经过后续的pipeline。定义好pipeline后还需要在settings中定义他们的顺序，比如：1234ITEM_PIPELINES = &#123; &apos;gglplay.pipelines.GglplayPipeline&apos;: 300, &apos;gglplay.pipelines.StoreItemPipeline&apos;: 400,&#125; 定义了两个模块的处理流程，item先经过gglplay.pipelines.GglplayPipeline,再经过gglplay.pipelines.StoreItemPipeline,注意到数字越小，处理优先级越高。详细可以看：http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html 运行脚本直接命令行scrapy crawl的方式难以调试，为了方便调试，我们可以在项目顶层建立一个driver，这样子在pycharm之类的IDE中就能够比较方便进行断点调试了。run_spider.py内容如下：1234567if __name__ == &quot;__main__&quot;: # TODO: do something here from scrapy import cmdline name = &apos;gglplay&apos; cmd = &apos;scrapy crawl &#123;0&#125;&apos;.format(name) cmdline.execute(cmd.split()) pass 整个项目放置在(private, 仅作者可见)：https://github.com/ruanmk/google-play-crawler]]></content>
      <categories>
        <category>系统</category>
        <category>系统架构</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[UBUNTU搭建DEEPSPEECH语音转录系统]]></title>
    <url>%2F2018%2F10%2FUBUNTU%E6%90%AD%E5%BB%BADEEPSPEECH%E8%AF%AD%E9%9F%B3%E8%BD%AC%E5%BD%95%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[介绍Mozilla开源了百度的DeepSpeech，实际上模型的关键突破在于既提高了速度，也提高了准确性，其提升来源于RNN的结构设计，还有匹配的并行化方案。开源的版本由于修改了CTCLoss的计算op，因此配置上比较恶心，需要一个特定版本的tensorflow，实际上我们可以通过修改代码，直接将WarpCTC作为一个op动态加载进来。DeepSpeech项目地址： https://github.com/mozilla/DeepSpeechTest WarpCTC地址（暂时不会用到）：https://github.com/baidu-research/warp-ctc 注意我们这里直接根据DeepSpeech的项目进行部署，不进行任何修改，也不手动引入WarpCTC。 安装在介绍其原理前，我们首先将这个库跑起来。关键步骤实际上都在https://github.com/mozilla/DeepSpeech/blob/master/README.md中，但是由于其采用了一个修改的op，因此还是会出现一些坑。以下安装流程基于 Ubuntu 14.04 x86_64， python 2.7基础上。 使用模型1、安装git large file storage各平台的安装说明在https://github.com/git-lfs/git-lfs/blob/master/INSTALLING.md, 针对Ubuntu 14.04, 执行下面代码即可：1curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash 2、下载代码安装完git-lfs之后，我们直接clone repo即可。1git clone https://github.com/mozilla/DeepSpeech 3、下载预训练好的文件（非必要）项目自带了一个英文的语音识别模型，大小为1.2G，可以另开一个线程下载，用于deepspeech的尝试。由于下载时间较长，到这步可以放着下载，先做后面的步骤。 4、创建python虚拟环境（当然也可以装在系统python中）,这里起名字py27，注意要安装virtualenv。12virtualenv py27 --python=python2.7source py27/bin/activate 5、安装deepspeech的python客户端(Python Binding)deepspeech有预编译的二进制文件（也可以自己编译）1pip install deepspeech 到这一步已经能够完成了整个的使用了，具体的使用参数为：1deepspeech -h 6、安装deepspeech的二进制命令行客户端（python和命令行客户端任选其一即可，只是个客户端程序）1python util/taskcluster.py --target . 至此，仅仅使用deepspeech进行inferrence的情况下，配置完成，如果需要训练自己的模型，还需要进行下面的配置。 训练模型要想训练模型，在完成使用模型相应的安装步骤后，还需要安装tensorflow训练库，由于使用了warpCTC，因此这里直接打包了一个修改过的tensorflow，个人认为没必要，还不如弄成一个独立的库。 1、 安装必要的库1234cd DeepSpeechpython util/taskcluster.py --target /tmp --source tensorflow --artifact tensorflow_warpctc-1.4.0-cp27-cp27mu-linux_x86_64.whlpip install /tmp/tensorflow_warpctc-1.4.0-cp27-cp27mu-linux_x86_64.whlpip install -r requirements.txt 每一步都必须做完。 如果是mac系统下，安装这个tensorflow版本即可（实际上最好最为额外的op引入，我非常讨厌这样重新打包tensorflow的方式）1pip install https://index.taskcluster.net/v1/task/project.deepspeech.tensorflow.pip.osx.08894f64fc67b7a8031fc68cb838a27009c3e6e6/artifacts/public/tensorflow_warpctc-1.4.0-cp27-cp27m-macosx_10_12_x86_64.whl 2、 必须下载native client(也就是上面的python binding基础上不再是选择，而是必须下载)1python util/taskcluster.py --target . 3、 检查1./DeepSpeech.py --help 如果不出错，那么训练的环境配置完成。具体的训练步骤可以继续参考README.md. 问题列表 pip install deepspeech返回can not find …之类的1、首先确保python是合适的版本，如果不放心。12sudo apt-get install python2.7 python2.7-dev build-essential libssl-dev libffi-dev python-devpip install --upgrade pip 问题的原因实际上来自libssl和libffi，因为不能识别部分header导致不能够正确比对python版本要求等。]]></content>
      <categories>
        <category>系统</category>
        <category>环境配置</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++虚函数的意义]]></title>
    <url>%2F2018%2F05%2FCpp%E8%99%9A%E5%87%BD%E6%95%B0%E7%9A%84%E6%84%8F%E4%B9%89%2F</url>
    <content type="text"><![CDATA[下面以一个简单的例子说明virtual的作用，作为继承和多态的重要组件，如果没有虚函数，那么多态的实现将非常的困难。首先明确一点，类成员函数中this的类型取决于该函数定义的位置，在父类中，this的类型是父类，在子类中，this的类型是子类。比如父类A和B，父类有一个成员函数test(), 其函数体中通过this调用了test1, 如果子类没有override这个函数，那么子类中，test()函数体里面this的类型依然是父类的类型。我们看下面三个例子来理解这一点：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;thread&gt;//This function will be called from a threadclass A&#123;public: void test()&#123; this-&gt;test1(); &#125; void test1()&#123; std::cout &lt;&lt; &quot;I am base&quot; &lt;&lt; std::endl; &#125;&#125;;class B:public A&#123; virtual void test1()&#123; std::cout &lt;&lt; &quot;I am Not Base&quot; &lt;&lt; std::endl; &#125;&#125;;int main() &#123; //Launch a thread B b; b.test(); return 0;&#125;// 运行结果// I am base// I am base 这个例子中，子类B没有覆盖A::test，因此test函数体内，this类型依然是A*，这就造成了b.test()调用的是A::test1()，这往往不是想要的结果。而如果加上virtual, 那么就能够调用到真正想要调用的函数了，看下面的改动：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;class A&#123;public: void test()&#123; this-&gt;test1(); &#125; virtual void test1()&#123; std::cout &lt;&lt; &quot;I am base&quot; &lt;&lt; std::endl; &#125;&#125;;class B:public A&#123; virtual void test1()&#123; std::cout &lt;&lt; &quot;I am Not Base&quot; &lt;&lt; std::endl; &#125;&#125;;int main() &#123; B b; b.test(); A a; a.test(); return 0;&#125;// 运行结果// I am Not Base// I am base 这个例子中，test1是虚函数，因此即使B没有覆盖test函数，this的编译时类型依然是A*，但是在调用this-&gt;test1()的时候会查找虚函数表，然后知道this实际类型应该是B*并调用B::test1()。具体要调用A::test1还是B::test1只能在运行时知道。注意哦，如果子类同时覆盖了调用的函数test，那么也是能够调用到想要的test1的，因为此时编译时this的类型就已经是B*了。看下面的代码：123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;class A&#123;public: void test()&#123; this-&gt;test1(); &#125; void test1()&#123; std::cout &lt;&lt; &quot;I am base&quot; &lt;&lt; std::endl; &#125;&#125;;class B:public A&#123;public: void test1()&#123; std::cout &lt;&lt; &quot;I am Not Base&quot; &lt;&lt; std::endl; &#125; void test()&#123; this-&gt;test1(); &#125;&#125;;int main() &#123; B b; b.test(); A a; a.test(); return 0;&#125;// 运行结果// I am Not Base// I am base]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++Map的区别]]></title>
    <url>%2F2018%2F05%2FCppMap%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[导言面试别人时我常问一个编程题，也就是leetcode上的two sum，其中使用map和unordered_map的速度区别高达(打败)40%和(打败)88%,也就是快了接近一倍。使用map打败40%, 20ms, 使用unorderred_map打败88%， 12ms。 123456789101112131415class Solution &#123;public:vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; std::unordered_map&lt;int, int&gt; m; for(int i=0; i &lt; nums.size(); i++ )&#123; int residual = target-nums[i]; if(m.find(nums[i]) != m.end())&#123; return &#123;m[nums[i]], i&#125;; &#125;else&#123; m.insert(pair&lt;int, int&gt;(residual, i)); &#125; &#125; return &#123;&#125;;&#125;&#125;; 那么他们有什么区别呢？ 原理上的区别原理上来说，map采用二叉树(如红黑树等)来存储键值，键是有序的，而unordered_map则是采用哈希的方法来存储，是无序的。map的键必须定义operator &lt;，而unordered_map必须定义operator =。C++的unordered_map其实就是Hashmap，但是因为c++有太多第三方库占用了std::hash_map这么一个名字，因此起名叫做unordered_map. (毕竟大家都能给std加料，这也是namespace的设计我感觉到还存在不足的地方) 另有hash_set, hash_multiset等数据结构https://cloud.tencent.com/developer/article/1338322 使用上的区别map由于是有序的，因此可以按区间取元素，存在以下方法，而unordered_map则不存在以下方法： lower_boundReturn iterator to lower bound (public member function ) upper_boundReturn iterator to upper bound (public member function ) equal_rangeGet range of equal elements (public member function ) 其他容器也类似，有两个版本，在原理上分使用二叉树的和使用hashmap的，在是否允许键重复分multiXXX和非multi的。]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[卡尔曼滤波器]]></title>
    <url>%2F2018%2F04%2F%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8%2F</url>
    <content type="text"><![CDATA[卡尔曼滤波器卡尔曼滤波可以看这篇文章：http://web.mit.edu/kirtley/kirtley/binlustuff/literature/control/Kalman%20filter.pdf 基本假设卡尔曼滤波器的基本假设是，对于t时刻一个状态值 x_t ,注意状态值是一个n维向量。它是通过某种转换关系从上一个时刻的状态 x_{t-1} 转换过来的，并且这个转换过程是存在白噪的，也就是： \begin{equation} x_t = \Phi x_{t-1} + \omega_t \end{equation}同时，卡尔曼滤波认为$x_t$的观测值$z_t$（观测值是一个m维向量，m和n不一定相等，取决于测量方法）与其状态值也存在一个关系： z_t = Hx_t + v_t这里显然$v_t​$就是测量误差，这里也认为这个测量误差符合高斯分布。 卡尔曼滤波认为这两个转换关系中的$\Phi​$和$H​$都是不随着时间改变的，是一个固定的值，由所建模的物理问题所决定，不需要每一帧重新计算，至于初始值是什么，就需要看卡尔曼滤波建模的实际物理量是什么了，比如说这个物理量是速度的话，且是匀加速运动，由于两帧之间的速度关系由加速度来决定，那么加速度就由$\Phi​$来进行建模。 问题定义定义了这么多，实际上我们要怎样从每一帧及其历史的观测值找到实际的$x_t$呢？答案是，找不到真实的$x_t$, 只能找到它的最优估计值$\hat{x_t}$，定义计算到的$\hat{x_t}$与实际的$x_t$的误差为$e_t = x_t- \hat{x_t}$， 显然，我们的目标函数可以定义为： \tag{loss} \min\sum_i^n E(e_{t,i}^2)也就是每一维误差的平方和。换一种角度，用概率的思维可以表达为最大似然函数，也就是给定观测值，求实际值的最大似然： \max P(\hat{x_t}|z_t)我们认为测量误差$v_t$符合高斯分布，那么 \begin{align} \max P(\hat{x_t}|z_t) &= \max P(z_t/H - v_t/H|z_t) \\ &=\max P(v_t|z_t) \\ &= \max P(v_t) \\ &= \max C_t e^{\frac{-(z_t-Hx_t)^2}{2\sigma^2}} \\ \end{align}其中$C_t$是高斯分布的常数项，最大化多帧似然函数为： \max \Pi_t{P(\hat{x_t}|z_t)}取对数改连乘为连加，再对$\sigma_t$求导即可求出每一帧最优的$\sigma_t$ 卡尔曼滤波变量定义以均方误差为例，我们优化的目标是： \min\sum_i^n E(e_{t,i}^2)为了获得这个最小的均方误差，我们先定义三个协方差矩阵： \begin{align} Q &= E[\omega_t\omega_t^T] \\ R &= E[v_tv_t^T] \\ P_t &= E[e_te_t^T] \\ &= E[(x_t-\hat{x_t})(x_t-\hat{x_t})^T] \end{align}那么我们需要最小化的就是$P_t$的迹$Tr(P_t)$。现在我们使用类似迭代证明的方式来进行说明，假如通过某种途径，我们初步获得了$x_t$的估计值，记为$\hat{x’_t}$，这时候需要通过卡尔曼滤波来进一步优化这样的一个结果。假如我们认为每一步的精细化都是一种线性变换，那么精细化的公式都是类似于$\hat{x_t}=a\hat{x’_t} + b$这样的形式，卡尔曼滤波认为更加精细化的结果可以通过以下的式子获得： \hat{x_t} = \hat{x'_{t}} + K_t(z_t - H\hat{x'_{t}})这条公式为什么成立下面会说明。其中$K_t$称之为Kalman gain, 记所谓的innovation 或measurement residual为 i_t = z_t - H\hat{x'_{t}}将$z_t$代入得： \hat{x_t} = \hat{x'_{t}} + K_t(Hx_t+ v_t - H\hat{x'_{t}})现在我们知道了怎样精细化对$x_t$的预测，那么接下来的问题就是解决$K_t$以及消除$x_t$了。由优化目标，我们应该选择一个$K_t$使其最小化$Tr(P_t)$，因此我们需要获得$P_t$关于$K_t$的式子，再进行求导计算。由于： x_t-\hat{x_t} = x_t-\hat{x'_{t}} - K_t(Hx_t + v_t - H\hat{x'_{t}}) = (I-K_tH)(x_t-\hat{x'_{t}})-K_tv_t将\hat{x_t}代入P_t中，注意到噪声v_t和x_t以及\hat{x'_{t}}显然都不相关，因此: \begin{align} P_t &= E[(x_t-\hat{x_t})(x_t-\hat{x_t})^T] \\ &= (I-K_tH)E[(x_t-\hat{x_t})(x_t-\hat{x_t})^T](I-K_tH) + K_tE[v_tv_t^T]K_t^T \\ &= (I-K_tH)P'_t(I-K_tH) + K_tRK_t^T \\ &= P'_t - K_tHP'_t - P'_tH^TK_t^T + K_t(HP'_kH^T+R)K_t^T \end{align}上式用$P’_t$消除了对$x_t$的依赖，而$P’_t$同$\hat{x’_t}$一样认为是通过某种途径初步获得的，两者在迭代一开始的初始值一般是0。将$P_t$的迹与$K_t$进行求导，注意到公式： \nabla_ATr(AB) = B^T我们有： \frac{dTr(P_t)}{dK_t} = -2(HP'_t)^T + 2K_t(HP'_kH^T+R)使之为0，求得最优的$K_t$为： K_t = P'_tH^T(HP'_tH^T+R)^{-1}其中记$S_t = HP’_tH^T+R$。将$K_t$代入$P_t$, 可以消除后两项得： \begin{align} P_t &= P'_t - K_tHP'_t \\ &= P'_t - P'_tH^T(HP'_tH^T+R)^{-1}HP'_t \\ &= (I-K_tH)P'_k \\ \end{align}我们现在获得了同一帧之间所有变量的迭代优化公式，现在需要将前后两帧联系起来。卡尔曼滤波认为，下一帧的粗略估计值与上一帧的精细估计值存在这样的关系： \hat{x}'_{t+1} = \Phi \hat{x_t}根据这一假设，我们能得到所有其他的粗略估计值： \begin{align} e'_{t+1} &= x_{t+1}-x'_{t+1} \\ &=(\Phi x_t + \omega_t) - \Phi \hat{x}_t \\ &= \Phi e_t + \omega_t \\ \end{align} \begin{align} P'_{t+1} &= E[(\Phi e_t+\omega_t)(\Phi e_t+\omega_t)^T] \\ &= E[(\Phi e_t)(\Phi e_t)^T] + E[\omega_t\omega_t^T] \\ &= \Phi P_t\Phi + Q \end{align}整体流程 初始化$P’_0, e’_0, \hat{x’_0}$为0，或者为其他数字，这是根据建模需求的求出来的 计算$K_t = P’_tH^T(HP’_tH^T+R)^{-1}$ 计算出当前帧调整后的状态 \hat{x_t} = \hat{x'_{t}} + K_t(Hx_t+ v_t - H\hat{x'_{t}}) 更新卡尔曼滤波的参数 $P_t = P’_t - K_tHP’_t$ 准备下一帧的粗略估计值 $\hat{x}’_{t+1} = \Phi \hat{x_t}​$ $P’_{t+1}= \Phi P_t\Phi + Q$ 小结可以看出，卡尔曼滤波的更新跟状态量一点关系都没有，即使没有状态量，卡尔曼滤波每一帧的参数更新都是固定的。这也是为什么称之为滤波器的原因之一。]]></content>
      <categories>
        <category>理论基础</category>
        <category>动态跟踪</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++11并发技术]]></title>
    <url>%2F2018%2F03%2FC-11%E5%B9%B6%E5%8F%91%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[thread与std::asyncC++ 11 增加了对线程的基本支持，其使用方式与其他语言的线程写法几乎一样，也就是定义需要跑的函数，然后开启多个线程，线程内部提供同步的数据结构。一个标准的线程写法如下图所示： 1234567891011121314#include &lt;iostream&gt;#include &lt;thread&gt;//This function will be called from a threadvoid call_from_thread() &#123; std::cout &lt;&lt; &quot;Hello, World&quot; &lt;&lt; std::endl;&#125;int main() &#123; //Launch a thread std::thread t1(call_from_thread); //Join the thread with the main thread t1.join(); return 0;&#125; C++11除了线程外，还提供了一个更高阶抽象的std::async， 如果没有其他的要求，最好使用std::async这样的方法，而不是裸的线程，这是因为async可以获得返回的结果。总结而言，C++11新引入的并发元素有： 任务、期值、线程、互斥量条件变量和原子对象等一套。 thread_local线程一个重要的概念就是线程的局部变量，因为局部变量的创建与普通的C++变量创建时机是不一样的，仅在线程使用变量时才会创建，且每个线程创建一次。部分内容可以参考：http://cifangyiquan.net/programming/thread_local/我们看以下例子来了解下thread_local这一关键字的重要作用：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;thread&gt;//This function will be called from a threadclass A&#123;public: int data=0; void p(int i)&#123; data += i; std::cout &lt;&lt; data &lt;&lt; std::endl; &#125;&#125;;thread_local A a;void call_from_thread(A&amp; a, int i) &#123; a.p(i);&#125;int main() &#123; //Launch a thread std::thread t1(call_from_thread, std::ref(a), 1); std::thread t2(call_from_thread, std::ref(a), 3); //Join the thread with the main thread t1.join(); t2.join(); return 0;&#125;// 输出结果// 3// 4 稍微改变一下：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;thread&gt;//This function will be called from a threadclass A&#123;public: int data=0; void p(int i)&#123; data += i; std::cout &lt;&lt; data &lt;&lt; std::endl; &#125;&#125;;thread_local A a;void call_from_thread(int i) &#123; a.p(i);&#125;int main() &#123; //Launch a thread std::thread t1(call_from_thread, 1); std::thread t2(call_from_thread, 3); //Join the thread with the main thread t1.join(); t2.join(); return 0;&#125;// 输出结果// 1// 3 为什么呢？这是因为第一种通过ref调用的方式，a是在主线程创建并传递到子线程的，而第二种方式，则是在线程创建时，每个线程创建时才创建的a。为了展示这一过程，我们将构造函数和析构函数打印出来：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;//This function will be called from a threadstd::mutex cout_mutex; class A&#123;public: int data=0; A()&#123; cout_mutex.lock(); std::cout &lt;&lt; &quot;ID: &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;Object A Constructed&quot; &lt;&lt; std::endl; cout_mutex.unlock(); &#125; ~A()&#123; cout_mutex.lock(); std::cout &lt;&lt; &quot;ID: &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;Object A Destroyed&quot; &lt;&lt; std::endl; cout_mutex.unlock(); &#125; void p(int i)&#123; data += i; std::cout &lt;&lt; data &lt;&lt; std::endl; &#125;&#125;;thread_local A a;void call_from_thread(int i) &#123; std::cout &lt;&lt; &quot;ID: &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot; Thread created&quot; &lt;&lt; std::endl; a.p(i);&#125;int main() &#123; //Launch a thread std::thread t1(call_from_thread, 1); std::thread t2(call_from_thread, 3); //Join the thread with the main thread t1.join(); t2.join(); return 0;&#125;// 输出结果ID: 140123813201664 Thread created ID: 140123813201664Object A Constructed 3 ID: 140123813201664Object A DestroyedID: 140123821594368 Thread createdID: 140123821594368Object A Constructed1 ID: 140123821594368Object A Destroyed]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
</search>

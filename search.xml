<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Cython制作C++动态库的python binding]]></title>
    <url>%2F2019%2F08%2FCython%E5%88%B6%E4%BD%9CC-%E5%8A%A8%E6%80%81%E5%BA%93%E7%9A%84python-binding%2F</url>
    <content type="text"><![CDATA[参考链接https://docs.python.org/2/extending/building.html#buildingpython3官方文档： https://docs.python.org/3/extending/extending.htmlhttps://www.tutorialspoint.com/python/python_further_extensions.htm关键参考这个例子https://github.com/JacekPierzchlewski/CppClass4Python3/blob/master/car/car2py.cpp网上下载了Cython的书籍，已经上传nashttp://www.jyguagua.com/wp-content/uploads/2017/03/OReilly.Cython-A-Guide-for-Python-Programmers.pdf直接看第八章吧，其他的说的都是用不上的。https://notes-on-cython.readthedocs.io/en/latest/function_declarations.html 导言首先先上结论，对于c++ 11，使用pybind11能够更加完美支持C++11的新特性，Cython更加适合纯C或者C++11之前的C++，包括对模板类以及MemoryView的支持。手工写这两者都需要大量的转换，最好是能够写一个自动wrap的小工具会好一些。Cython主要的问题在于对enum class的支持不足，其他的坑暂时还没有发现更多。 主要概念需要认清以下几个主要的概念： ExtensionPython大部分的解释器都是CPython，也就是实际上就是一个能够运行.py文件的C程序，python是支持通过so的方式对这个C程序进行扩展的，这个扩展是相当于直接加在了运行时的解释器上面，而不是类似于解析器读取py文件运行这样的机制，因此称之为Python的扩展Extension而不是package, setup函数setup函数来自setup_tools, setup_tools主要是改写了原本distutils里面的setup函数，我们一般只用setup_tools的setup函数，能够支持一些新的特性。常见的开头长这样： 123import setuptoolsfrom setuptools import setup, Extensionfrom Cython.Build import cythonize 下面我们会具体说明使用到的cythonize函数，也就是Cython方案的核心之一。 Cython方案Cython方案是诸多C++ wrapper中最接近python语法的一种，它能够比较好地用接近python的语法调用c++，不足之处就是对于enum class的支持非常差，导致无法在接口模块直接使用。为了使用一些C++支持而Cython不支持的特性，我们需要独立出来这部分代码，用纯C++来wrap一遍，去掉enum class这一类输入，用简单变量比如纯C的enum或者int来简单包装一下，再输入到最早需要接收enum class的函数中去。 123456789101112131415// shared_lib.henum class Flag&#123; FLAG1, FLAG2, ...&#125;;void func(enum class Flag)&#123;&#125;// write a wrapper so that cython need not interact directly with shared_lib.h// wrapper.hvoid func_wrapper(int flag)&#123; if(flag == 1) Flag cflag = Flag::FLAG1 ... return func(cflag);&#125; Cython编译整体有两个阶段，第一阶段就是pyx转c/c++， 第二阶段就是这个c/c++转换为python的extension。第一阶段由cython提供，第二阶段就用的python官方的setuptools来实现了。第二阶段还能加入很多纯C/C++的代码，也最灵活。 pyx和pyd类比于C++的.cpp和.h文件，pyx和pyd就是Cython的实现和头文件，注意声明来自C的变量和函数一定要在pyd里面进行，否则编译的时候会出现符号重定义的现象，这和C++是一样一样的。 wrap函数返回bool值返回bool值得函数在这里需要用bint来替代作为python object wrap变量接收str变量到char*123456# void process_func(unsigned char*);#cpdef init_humanface_module(self, pystr): cstr = pystr.encode(&apos;utf-8&apos;) # now cstr can be passed to c function as an unsigned char* pointer process_func(cstr) 接收numpy变量numpy的array在传到C++层面时候，其存储不一定是连续的，因此不能够直接取array.data作为buffer的起点，而应该先转换为continuous array之后，这个array.data才是能够直接作为c++指针的起点。比如我们用opencv在python层读了一个图片进来，这时候要怎样变成一个unsigned char* 的指针呢？注意，这个指针指向的内存由python所管理，因此千万别尝试接管这部分内存，否则很可能出现内存泄漏。1234567cpdef receive_numpy(self, image_data): row, col = image_data.shape[0], image_data.shape[1] cdef np.ndarray[np.uint8_t, ndim=3, mode = &apos;c&apos;] np_buff = np.ascontiguousarray(image_data, dtype = np.uint8) cdef unsigned char* im_buff = &lt;unsigned char*&gt; np_buff.data # do whatever you want with im_buff, but do not free the memory it points to. # ... pass 接收bool变量有一个比较奇怪的现象，就是容器里面的bool不能用bint替换，因为没有默认的强制类型转换函数，必须使用原生的c++ bool1234from libcpp cimport boolcdef extern from &quot;wrapper.h&quot;: cdef struct Foo: vector[bool] boolFlags shared library的依赖管理我们给shared library添加wrapper, 在这样的使用场景下，so库是预编译的，拿到的时候应该就是so库及其相应的头文件，我们知道，python作为C程序的一种，他要想要使用到这个so库，加载的方式和传统的C程序也是没有什么两样的，比如搜索/usr/lib, /lib， ${LD_LIBRARY_PATH}, RPATH等等，因为我们希望在pip install 和uninstall的时候，pip能够管理我们全部生成的文件，在卸载的时候也能够卸载干净，因此我们不可能将so库放在/usr/lib或者/lib这样的全局位置，并且这样的操作setuptools默认是不支持的，且需要sudo权限。而设置LD_IBRARY_PATH则需要在启动python之前就完成设置，一旦python启动，后续不能够再设置，当然也有办法是python设置完之后，重启python，这种骚操作我觉得还是少用为妙。123456789101112131415import sys, osmymodule_path = &quot;/home/me/python/mymodule&quot;try: sys.path.append(mymodule_path) import mymoduleexcept ImportError: if sys.platform == &apos;win32&apos;: os.environ[&apos;PATH&apos;] = mymodule_path elif sys.platform == &apos;darwin&apos;: os.environ[&apos;DYLD_LIBRARY_PATH&apos;] = mymodule_path else: os.environ[&apos;LD_LIBRARY_PATH&apos;] = mymodule_path args = [sys.executable] args.extend(sys.argv) os.execv(sys.executable, args) 那么就只剩下一个关键的途径了，那就是设置RPATH，也就是runtime_library_dirs了，这是写在so库中的一个路径，我们可以用readelf -d xxx.so来看到，也可以用ldd xxx.so来看到如果在ldd当前目录下运行程序，有什么样的xxx.so依赖的其他so库能够被找到。RPATH有一个特殊的符号，$ORIGIN，注意这个不是一个变量，而是一个特定的符号，他表示，无论这个so被扔到那里了，$ORIGIN就是so所在的目录位置，于是，相对路径就变得可行起来了，比如我们添加这样的一行编译：123set_target_properties(xxx PROPERTIES LINK_FLAGS &quot;-Wl,-rpath,$ORIGIN&quot;)或者set_target_properties(xxx PROPERTIES INSTALL_RPATH &quot;$ORIGIN&quot;) 而在setuptools里面，则是在Extension加上这个property:1ext = Extension(runtime_library_dirs=[&quot;$ORIGIN&quot;], ... , ) 再次提醒，这个$ORIGIN并不会被替换成其他的变量，因为这是一个特殊符号。但是，这个只解决了由wrapper直接依赖的so的问题，假设我们的模块是mylib, mylib依赖的A.so可以由上述方式找到，但是A.so可能依赖另外一些shared lib, 比如B.so， 这就要求A.so在编译的时候就已经将RPATH设置正确，否则也是没有办法的，不过一般A.so, B.so这些也都是我们能够接触到源码的，所以改一下编译也不是难题，并且实在不行还可以用patchelf这个工具做后处理修改掉rpath. Cython打包过程像我们这种打包shared lib的，不可避免需要将被wrap的so安装到site_package里面去，那么怎么实现这件事呢？那就是用package_data啦，注意，package_data只能打包在package所在的文件夹之内的数据文件，不在这个路径下的，是不能被打包的，也不会报错。并且，某个文件要想被打包，其顶层一定有一个123456```|--data |--model.bin |--model.lib |--__init__.py|--setup.py 在setup.py里面，要想打包data里面的内容，那么：只需要setup(package_data={&#39;data&#39;: [&quot;model.*&quot;]}, ..., )即可，当然目录还能更加复杂一些。 python setup.py install/sdist/bdist/bdist_wheelinstall为直接安装，一般就是安装到本机sdist作用基本相当于直接将当前源码打包，然后放到其他机器同样运行python setup.py install来安装，就是所谓的源码发布bdist作用相当于将pyx, pyd等编译之后只取二进制文件，实际上并不好用bdist_wheel是我觉得最好用的，它切掉了全部的源码，只留下必要的文件。 所有需要被打包的文件，都通过MANIFEST.in来进行指定。 static问题由于python的extension在不同的系统，动态库其symbol的可见性是不一样的，比如windows就全局共享一个可见性，因此建议所有的extension的函数都带上static，只有模块的初始化函数XXX_Init除外。]]></content>
      <categories>
        <category>语言基础</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[OpenGLES跨平台Context的建立]]></title>
    <url>%2F2019%2F08%2FOpenGLES%E8%B7%A8%E5%B9%B3%E5%8F%B0Context%E7%9A%84%E5%BB%BA%E7%AB%8B%2F</url>
    <content type="text"><![CDATA[OpenGL与GLES不同点OpenGL和GLES最大的不同点，我觉得就是对于纹理坐标的设置上。对于OpenGL，其纹理坐标原点在纹理图片的左下角，和OpenCV的图片坐标在y轴上是相反的.OpenGLES则不遵守这一规定，GLES的纹理坐标原点在左上角，和OpenCV一致。 GLES几个关键的概念除iOS、OSX以外，其他平台初始化OpenGLES的代码段12345678910111213141516171819202122EGLint configSpec[] = &#123; EGL_RED_SIZE, 8, EGL_GREEN_SIZE, 8, EGL_BLUE_SIZE, 8, EGL_SURFACE_TYPE, EGL_PBUFFER_BIT, EGL_NONE &#125;; EGLint surfaceAttr[] = &#123; EGL_WIDTH, width, EGL_HEIGHT, height, EGL_NONE &#125;; this-&gt;glContext-&gt;eglDisp = eglGetDisplay(EGL_DEFAULT_DISPLAY); EGLint eglMajVers, eglMinVers; EGLint numConfigs; eglInitialize(this-&gt;glContext-&gt;eglDisp, &amp;eglMajVers, &amp;eglMinVers); // std::cout &lt;&lt; eglMajVers &lt;&lt; &quot; &quot; &lt;&lt; eglMinVers &lt;&lt; std::endl; eglChooseConfig(this-&gt;glContext-&gt;eglDisp, configSpec, &amp;this-&gt;glContext-&gt;eglConf, 1, &amp;numConfigs); this-&gt;glContext-&gt;eglSurface = eglCreatePbufferSurface(this-&gt;glContext-&gt;eglDisp, this-&gt;glContext-&gt;eglConf, surfaceAttr); const EGLint ctxAttr[] = &#123; EGL_CONTEXT_CLIENT_VERSION, 2, EGL_NONE &#125;; this-&gt;glContext-&gt;eglCtx = eglCreateContext(this-&gt;glContext-&gt;eglDisp, this-&gt;glContext-&gt;eglConf,EGL_NO_CONTEXT, ctxAttr); eglMakeCurrent(this-&gt;glContext-&gt;eglDisp, this-&gt;glContext-&gt;eglSurface, this-&gt;glContext-&gt;eglSurface, this-&gt;glContext-&gt;eglCtx); 整个流程是：获得DISPLAY， 在DISPLAY基础上创建Surface，将DISPLAY、Surface等一系列上下文写入创建Context中去。 获取Display。 Display代表显示器，在有些系统上可以有多个显示器，也就会有多个Display。获得Display要调用EGLboolean eglGetDisplay(NativeDisplay dpy)，参数一般为 EGL_DEFAULT_DISPLAY 。该参数实际的意义是平台实现相关的，在X-Window下是XDisplay ID，在MS Windows下是Window DC。 初始化egl。 调用 EGLboolean eglInitialize(EGLDisplay dpy, EGLint major, EGLint minor)，该函数会进行一些内部初始化工作，并传回EGL版本号(major.minor)。 选择Config。 所谓Config实际指的是FrameBuffer的参数，在MS Windows下对应于PixelFormat，在X-Window下对应Visual。一般用EGLboolean eglChooseConfig(EGLDisplay dpy, const EGLint attr_list, EGLConfig config, EGLint config_size, EGLint num_config)，其中attr_list是以EGL_NONE结束的参数数组，通常以id,value依次存放，对于个别标识性的属性可以只有 id，没有value。另一个办法是用EGLboolean eglGetConfigs(EGLDisplay dpy, EGLConfig config, EGLint config_size, EGLint *num_config) 来获得所有config。这两个函数都会返回不多于config_size个Config，结果保存在config[]中，系统的总Config个数保存 在num_config中。可以利用eglGetConfig()中间两个参数为0来查询系统支持的Config总个数。 Config有众多的Attribute，这些Attribute决定FrameBuffer的格式和能力，通过eglGetConfigAttrib ()来读取，但不能修改。 构造Surface。 Surface实际上就是一个FrameBuffer，通过 EGLSurface eglCreateWindowSurface(EGLDisplay dpy, EGLConfig confg, NativeWindow win, EGLint *cfg_attr) 来创建一个可实际显示的Surface。系统通常还支持另外两种Surface：PixmapSurface和PBufferSurface，这两种都不 是可显示的Surface，PixmapSurface是保存在系统内存中的位图，PBuffer则是保存在显存中的帧。 Surface也有一些attribute，基本上都可以故名思意， EGL_HEIGHT EGL_WIDTH EGL_LARGEST_PBUFFER EGL_TEXTURE_FORMAT EGL_TEXTURE_TARGET EGL_MIPMAP_TEXTURE EGL_MIPMAP_LEVEL，通过eglSurfaceAttrib()设置、eglQuerySurface()读取。 创建Context。 OpenGL的pipeline从程序的角度看就是一个状态机，有当前的颜色、纹理坐标、变换矩阵、绚染模式等一大堆状态，这些状态作用于程序提交的顶点 坐标等图元从而形成帧缓冲内的像素。在OpenGL的编程接口中，Context就代表这个状态机，程序的主要工作就是向Context提供图元、设置状 态，偶尔也从Context里获取一些信息。 用EGLContext eglCreateContext(EGLDisplay dpy, EGLSurface write, EGLSurface read, EGLContext * share_list)来创建一个Context。用eglMakeCurrent来将当前context设置为默认context 绘制。 应用程序通过OpenGL API进行绘制，一帧完成之后，调用eglSwapBuffers(EGLDisplay dpy, EGLContext ctx)来显示。 DISPLAY、Surface、Context、Configuration DISPLAY可以理解为物理屏幕，对于PC就是显示器，对于手机，就是屏幕，获得这个句柄主要是用于正确放置surface，surface建立于DISPLAY以上。 Surface可以理解为画板，可以为物理屏幕上的像素，也可以是离屏渲染的FrameBuffer Context就是设置好这些以后，所处的一个配置环境。 相应的，EGL中，NativeDisplayType 平台显示数据类型，标识你所开发设备的物理屏幕NativeWindowType 平台窗口数据类型，标识系统窗口NativePixmapType 可以作为 Framebuffer 的系统图像（内存）数据类型，该类型只用于离屏渲染 获得DISPLAYthis-&gt;glContext-&gt;eglDisp = eglGetDisplay(EGL_DEFAULT_DISPLAY);如果你只是想得到一个系统默认的 Display ，你可以使用 EGL_DEFAULT_DISPLAY 参数。如果系统中没有一个可用的 native display ID 与给定的 display 参数匹配，函数将返回 EGL_NO_DISPLAY ，而没有任何 Error 状态被设置。由于设置无效的 display 值不会有任何错误状态，在你继续操作前请检测返回值。因此，上述函数还应该检查返回的eglDisp是不是 EGL_NO_DISPLAYassert(this-&gt;glContext-&gt;eglDisp != EGL_NO_DISPLAY)查询到系统的Display之后，需要初始化这个eglDisp, 并且获得这个DISPLAY所支持GL版本。 SurfaceSurface是可以绘制的画板，通常有屏幕像素、PixmapSurface(保存在系统内存中的位图)，PBuffer(保存在显存中的帧) iOS上的EGL配置具体参考：https://developer.apple.com/library/archive/documentation/3DDrawing/Conceptual/OpenGLES_ProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40008793 iOS和Android不一样，虽然iOS也支持EGL，但是是自己的一个版本。另外不能用纯C++来简历iOS上面的EGL上下文，必须采用部分object头来初始化。另外一点就是，EAGL不允许设置宽高等，直接获得context就好了。实际上，这个context还没有设置surface，后续才会去做这个设置。另外，后台运行的任务，也就是没有占用屏幕的应用是无法执行OpenGL的渲染指令的。 一个iOS离屏渲染的例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051EAGLNativeContext eaglContext;eaglContext.createMainContext();eaglContext.makeCurrent();GLuint frameBufferTexture;GLuint frameBuffer;int width = 640;int height = 480;glGenTextures(1, &amp;frameBufferTexture);glGenFramebuffers(1, &amp;frameBuffer);glBindFramebuffer(GL_FRAMEBUFFER, frameBuffer);glBindTexture(GL_TEXTURE_2D, frameBufferTexture);//use linear combination of pixel values when scaling and down-samplingglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);// specify texture warpingglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); // the s axisglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); // the t axis//feed no data, and bind texture to framebufferglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, width, height, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, frameBufferTexture, 0);GLuint depthRenderbuffer;glGenRenderbuffers(1, &amp;depthRenderbuffer);glBindRenderbuffer(GL_RENDERBUFFER, depthRenderbuffer);glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT16, width, height);glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, depthRenderbuffer);if(glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE)&#123; ERROR(&quot;Frame Buffer InComplete&quot;); return;&#125;// begin drawingglClearColor(0, 0, 1, 0);glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);glFlush();glBindFramebuffer(GL_FRAMEBUFFER, frameBuffer);unsigned char tmp_data[20 * 20 * 4];glReadPixels(0, 0, 20, 20, GL_RGBA, GL_UNSIGNED_BYTE, tmp_data);std::cout &lt;&lt; tmp_data &lt;&lt; std::endl; 我们可以看到在readPixel之前tmp_data全是0，而在read_pixel之后就会变成0, 0, 0xff, 0，注意一点是，texture大小在iOS是有限制的,具体可以看context。注意这段要放在view加载之后，否则可能无法获得context。 注意，其中深度buffer有没有并不影响平面的画，但是会影响三维的draw。 总结至此，离屏渲染实际上已经完成了跨平台，只需在android, windows, linux使用EGL，在iOS使用EAGL即可，只要对编译选项按平台稍加改造，就能够实现跨平台的opengles引擎的渲染逻辑的初始化。]]></content>
  </entry>
  <entry>
    <title><![CDATA[三维重建方法]]></title>
    <url>%2F2019%2F08%2F%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[小孔相机模型https://blog.csdn.net/lsh_2013/article/details/47615309 坐标系及其转换相机模型中有四个重要的坐标系 1.世界坐标系 ($X_w, Y_w, Z_w$)，世界坐标系就是物体在真实世界中的坐标 2.像平面坐标系($x, y$)，注意这个是像平面的物理坐标，单位是实际物理长度，如1cm等 3.像素坐标系($u, v$)，注意这个是像平面的像素坐标，是按个算的像素位置，如(3, 5)是指第三行第五个像素。 4.相机坐标系($X_c, Y_c, Z_c$), 是以相机为中心，相机朝向为坐标轴方向的坐标系，实际上就是世界坐标系进行了一定的线性变换得到的新的坐标系。(显然从世界坐标系转换到相机坐标系物体都是保持线性关系的，不会发生扭曲，相对位移等，因此这就是个仿射变换) 相机坐标系和世界坐标系的变换既然知道了这就是个仿射变换，那么其实转换形式也就定下来了。实际上就是一个三维旋转平移矩阵. 点击这里复习三维坐标系旋转平移的各种表示方法： https://zhuanlan.zhihu.com/p/45404840三维的旋转矩阵就是一个3x3的矩阵，是由三个旋转矩阵按照欧拉角的顺规顺序点乘得来的，维基百科有所有12种顺规的旋转矩阵表示：https://en.wikipedia.org/wiki/Euler_angles显然，旋转矩阵，加上平移分量，就可以用齐次坐标表示相机坐标系和世界坐标系的转换了。反正得到的旋转矩阵是这样的形式： \begin{bmatrix} X_c \\ Y_c \\ Z_c \\ 1 \end{bmatrix} = \begin{bmatrix} R & t \\ 0^T & 1 \\ \end{bmatrix} \begin{bmatrix} X_w \\ Y_w \\ Z_w \\ 1 \end{bmatrix}像素坐标系与像平面坐标系转换可以看到，像素坐标系和像平面坐标系还是比较容易转换的，其中一个关键参数就是一个像素的物理大小是多少，假设一个像素的物理大小是$(dx, dy)$，那么单位面积的像素个数就是$(\frac{1}{dx}, \frac{1}{dy})$转换关系就是： \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = \begin{bmatrix} \frac{1}{dx} & 0 & u_0 \\ 0 & \frac{1}{dy} & v_0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}相机坐标系与像平面坐标系关系也就是成像关系，符合相似三角形性质 我们可以看到 \begin{cases} \frac{x}{f} = \frac{X_c}{Z_c} \\ \frac{y}{f} = \frac{Y_c}{Z_c} \end{cases} \Rightarrow Z_c \begin{bmatrix} x \\ y \\ 1 \end{bmatrix} = \begin{bmatrix} f & 0 & 0 & 0 \\ 0 & f & 0 & 0 \\ 0 & 0 & 1 & 0 \end{bmatrix} \begin{bmatrix} X_c \\ Y_c \\ Z_c \\ 1 \end{bmatrix}综合上述三个转换关系，我们能够得到从世界坐标到像素坐标的转换关系 \begin{aligned} Z_c\begin{bmatrix} u \\ v \\ 1 \end{bmatrix} &= Z_c\begin{bmatrix} \frac{1}{dx} & 0 & u_0 \\ 0 & \frac{1}{dy} & v_0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} x \\ y \\ 1 \end{bmatrix} \\ &= \begin{bmatrix} \frac{1}{dx} & 0 & u_0 \\ 0 & \frac{1}{dy} & v_0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} f & 0 & 0 & 0 \\ 0 & f & 0 & 0 \\ 0 & 0 & 1 & 0 \end{bmatrix} \begin{bmatrix} X_c \\ Y_c \\ Z_c \\ 1 \end{bmatrix} \\ &= \begin{bmatrix} \frac{1}{dx} & 0 & u_0 \\ 0 & \frac{1}{dy} & v_0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} f & 0 & 0 & 0 \\ 0 & f & 0 & 0 \\ 0 & 0 & 1 & 0 \end{bmatrix} \begin{bmatrix} R & t \\ 0^T & 1 \\ \end{bmatrix} \begin{bmatrix} X_w \\ Y_w \\ Z_w \\ 1 \end{bmatrix} \\ &= KM\begin{bmatrix} X_w \\ Y_w \\ Z_w \\ 1 \end{bmatrix} \end{aligned}其中： K = \begin{bmatrix} \frac{1}{dx} & 0 & u_0 \\ 0 & \frac{1}{dy} & v_0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} f & 0 & 0 & 0 \\ 0 & f & 0 & 0 \\ 0 & 0 & 1 & 0 \end{bmatrix} \\ M=\begin{bmatrix} R & t \\ 0^T & 1 \\ \end{bmatrix}所以 \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} =K\frac{1}{Z_C}M\begin{bmatrix} X_w \\ Y_w \\ Z_w \\ 1 \end{bmatrix}注意，我们看到，这些矩阵计算过程中，是需要保留中间结果$Z_C$的，不能直接混在一起乘过去。实际上，K是OpenGL根据glViewPort计算出来的，用来决定OpenGL的像平面（三维空间里的二维平面， 范围是x, y都是[-1, 1]）和实际渲染的像素（实际渲染结果）的比例，因此在GLSL里面我们完全可以将所有矩阵都乘完，此时所有的矩阵等效于一个$M$，此后我们就管不着了，到了OpenGL内部去了，此时OpenGL会自动除以第三个参数，也就是$Z_C$，将[-1, 1]范围内的留下，然后再乘以K。比如一个常见的片段着色器可以这么写： 12345678910111213141516#version 330 corelayout (location = 0) in vec3 aPos;layout (location = 1) in vec3 aNormal;layout (location = 2) in vec2 aTexCoord;out vec2 TexCoord;uniform mat4 model;uniform mat4 view;uniform mat4 projection;void main()&#123; gl_Position = projection * view * model * vec4(aPos, 1.0); TexCoord = vec2(aTexCoord.x, aTexCoord.y);&#125; 实际上，到gl_Position为止，依然还是相机坐标，还没渲染到像平面（即还没除以$Z_C$），也显然没到像素(即还没乘以K)。而OpenGL的相机内参K非常简单，那就是：一般而言，f/dx = 渲染宽度，可以取img.cols/2, f/dy是渲染高度，可以取img.rows/2 ，也就是，像平面坐标(1, 1)映射到图像像素那就是(x=cols/2, y=rows/2)，以图像中心为坐标原点，刚好是右上角，所以不要觉得神奇，就是个约定。 K = \begin{bmatrix} \frac{f}{dx} & 0 & u_0 \\ 0 & \frac{f}{dy} & v_0 \\ 0 & 0 & 1 \end{bmatrix}OpenGL这个相机是假的，所以K是已知的，但是实际的相机K可不是这么简单的。K的参数完全由相机决定，称之为内部参数矩阵，而M的参数则由相机的位置所决定，称之为外部参数矩阵。实际成像模型，考虑到相机镜头加工不完善，还会存在畸变，比如由于多个光学镜头的主光轴不完全共线产生的径向和切向畸变。参考：https://blog.csdn.net/dcrmg/article/details/52950141切向畸变是由于透镜本身与相机传感器平面（成像平面）或图像平面不平行而产生的，这种情况多是由于透镜被粘贴到镜头模组上的安装偏差导致。 径向畸变就是沿着透镜半径方向分布的畸变，产生原因是光线在原理透镜中心的地方比靠近中心的地方更加弯曲，这种畸变在普通廉价的镜头中表现更加明显，径向畸变主要包括桶形畸变和枕形畸变两种。以下分别是枕形和桶形畸变示意图：]]></content>
  </entry>
  <entry>
    <title><![CDATA[美颜算法]]></title>
    <url>%2F2019%2F06%2F%E7%BE%8E%E9%A2%9C%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[美颜算法美颜算法主要是以下两种技术进行组合： 保边滤波：表面滤波、双边滤波、导向滤波等 锐化：对眼睛等部分采用拉普拉斯算子、非锐化掩蔽等进行锐化 这些算法常用到两个基础的算法：积分图以及直方图，用于加速计算。 保边滤波算法保边滤波算法一般需要使用到原图信息作为计算权重的一个重要因素。 表面模糊滤波(Surface Blur)表面模糊滤波是PS里面的一个磨皮算法，但是是其原理并未公开，是由一个PS技术爱好者通过excel拟合出来的。其计算公式为： q_k = \frac{\sum_{i=1}^{(2r+1)^2}[max(0, 1-\frac{|p_i-p_k|}{2.5Y})p_i]}{\sum_{i=1}^{(2r+1)^2}(max(0, 1-\frac{|p_i-p_k|}{2.5Y})}其中$p_k$是当前的中心像素，$p_i$是中心像素邻域的像素点，$q_k$则是当前中心像素的转换结果，也称之为响应。可以看到，在平坦区域，$p_i-p_k\approx 0$，此时表面滤波就是一个均值滤波。对于非平坦区域，特别不平坦的外围像素，其$max(0, 1-\frac{|p_i-p_k|}{2.5Y})$结果一般为0，不为0的邻域像素，其权重也随着差别变大而获得较低的权重，从而很好地保护了中心像素。O(1)效率的表面模糊算法 https://www.cnblogs.com/Imageshop/p/5995093.html 双边滤波(Bilateral Blur)双边滤波是在高斯滤波上做了一定的改进，其邻域像素的权重不仅由距离中心点的空间距离决定，还由邻域像素与其中心点的像素差别而决定。邻域像素的权重为： w_i = G(loc_i-loc_k)*G(p_i-p_k)其中$w_i$是邻域像素i的权重，$loc_i, loc_k$分别是邻域像素i以及中心像素k的空间位置。在平坦区域，$p_i-p_k\approx 0$，此时双边滤波退化为高斯滤波。在非平坦区域，由于$|p_i-p_k|$较大，因此$G(p_i-p_k)$较小，从而拉低了这些差别较大的像素的整体权重。与表面模糊一样，实现了对非平坦区域的细节保留。 导向滤波http://kaiminghe.com/eccv10/eccv10ppt.pdfhttps://blog.csdn.net/baimafujinji/article/details/74750283导向滤波也是非常类似的，其具体推导就不再重复了。其原理依然是，在平坦区域趋向于使用滑窗的均值，而在非平坦区域趋向于保留中心像素的值。它的精髓之处在于使用线性变换来计算响应，从而能够保证区域内guided image的梯度能够传导到响应中去，并且保持比例，避免了梯度翻转(就是响应中两个像素的大小关系与导向图或者原图不一致)。 你可以想象一种情况来理解这种假设。II中的甲处和乙处都是区域，而丙处是边缘。那甲处的梯度和乙处的梯度应该不会相差太大，例如乙处的梯度是甲处梯度的1.5倍。但是由于丙处是边缘，所以丙处的梯度会比较大，例如可能是甲处的6倍，也就是乙处的4倍。如果I和q之间满足线性关系，那么甲乙丙的梯度大小和倍数关系就都不会被扭曲。否则，如果二者之间的关系是非线性的，那么可能的结果是在q中，尽管丙处的梯度仍然大于乙处的梯度，进而大于甲处的梯度，但是倍数关系可能会扭曲。例如，丙处的梯度是乙处的1.5倍，而是甲处的6倍（即乙处的梯度是甲处的4倍），这时你就会想象，甲处是区域，而乙处和丙处就变成了边缘。可见非线性关系会使得引导图像对于边缘和区域的指示作用发生错乱。 看这个图，虽然响应（filterred）中，像素大小的偏序关系依然保留，但是由于映射比例不一致，导致与原图的差（上图的detail部分）存在波动。这时候将filter的结果应用回原图就会出现梯度翻转的现象(enhanced)。在非边缘处这样的现象不容易发生的，非边缘处主要是空间高斯起作用。在边缘处，主要是像素差高斯起主要作用，越靠近斜线的中心部分，也就是边界部分，邻域的像素波动就越大，而靠近两个平坦区域的像素，其波动相对较小，因此filtered曲线更加平缓，这就是上左图中filtered曲线先平缓后快速上升再平缓的原因。同时，guided filter更快，可以用于抠图，毛发模拟、去雾等一系列应用中去。 暗通道去雾算法https://www.jianshu.com/p/df9c963a392a 这里不得不提一下暗通道去雾算法，这里讲得最清晰，其中最关键的一步就是对无雾图像的假设，即下面的公式(6)： https://blkstone.github.io/2015/08/20/single-image-haze-removal-using-dark-channel/ 图像混合算法线性光混合假定两个相邻图层X和Y，X在下方，Y在上方，X与Y混合，则X是基色，Y是混合色，X与Y混合得到的颜色是结果色Z，对于线性光混合模式，其计算公式为： Z=X+2Y-256不透明度混合 Z= (X*(100-Opacity) + Y*Opacity)/100其中Opacity是0-100之间的数值，0代表上方的Y完全透明。 瘦脸宽脸之液化算法液化类算法一般是和磨皮一起出现的，其作用就是能够改变脸型。]]></content>
      <categories>
        <category>理论基础</category>
        <category>图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++11右值引用与完美转发]]></title>
    <url>%2F2019%2F05%2FCPP11%2FC-11%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E4%B8%8E%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91%2F</url>
    <content type="text"><![CDATA[C++11右值引用与完美转发C++11中右值引用常与完美转发相联系在一起。在详细深入之前，我们需要了解这样几条规律： 1.”右值和左值”，”右值引用和左值引用”两组概念是独立的。具有右值引用型的变量可能是左值。凡是可以取地址的均为左值，凡是命名变量，均为左值。比如说：1234void g(int &amp;&amp; a)&#123;&#125; 其中变量a虽然具有右值引用类型，但是在函数体内却是左值，有人会问，那这个右值引用有什么意义，意义就是外面在调用f的时候，必须传一个右值才能够匹配这个g，这个右值也告诉g函数内部，这个a是可以随时被强制类型转换到右值，或者move掉的。C++在实际调用g并传入a的时候，构造实参a的过程是在函数外部进行的，函数内部不再像按值调用一样需要重新初始化a，我们看到，下列代码中a只会被初始化一次，完整代码的运行结果如下。12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;using namespace std;class A&#123;public:A()&#123; std::cout &lt;&lt; &quot;Constructor&quot; &lt;&lt; std::endl;&#125;~A()&#123; std::cout &lt;&lt; &quot;Destructor&quot; &lt;&lt; std::endl;&#125;&#125;;void f(const A&amp; a)&#123; std::cout &lt;&lt; &quot;Calling LValue Version&quot; &lt;&lt; std::endl;&#125;void f(A&amp;&amp; a)&#123; std::cout &lt;&lt; &quot;Calling RValue Version&quot; &lt;&lt; std::endl;&#125;void g(A&amp;&amp; e)&#123; std::cout &lt;&lt; &quot;sentinel 3&quot; &lt;&lt; std::endl; f(e);&#125;int main()&#123; A a; std::cout &lt;&lt; &quot;sentinel 1&quot; &lt;&lt; std::endl; g(std::move(a)); std::cout &lt;&lt; &quot;sentinel 2&quot; &lt;&lt; std::endl; return 0;&#125;// 运行结果Constructorsentinel 1sentinel 3Calling LValue Versionsentinel 2Destructor 2.万能引用必须涉及类型推导，带类型推导不一定是万能引用。带类型推导的方式有模板函数以及auto decltype组合等。例如下面的代码块是万能引用，而上面的代码块只能是右值引用。 1234567891011121314template &lt;class A&gt;void f(A&amp;&amp; a) // 万能引用&#123;&#125;void f1(const A&amp;&amp; a) // 右值引用&#123;&#125;template &lt;class A&gt;class TemplateClass&#123;public:f(A&amp;&amp; a)&#123;&#125; // 右值引用，因为实例化TemplateClass的时候类型已经确定，函数调用时无需进行类型推导。template &lt;class B&gt;f1(B&amp;&amp; b)&#123;&#125; // 万能引用，因为函数调用时依然需要推导B的类型。&#125;; 3.const T&amp;可以接受任何实参，但是优先级不是最高的，如果存在同名的接受右值的形参，那么会优先调用右值形参的函数，否则会进行强制类型转换调用左值引用，const的存在使得即使原本是一个右值实参，也不会在函数内被改变，不会造成令调用者误解的情况，同时const的存在会延长右值的生命周期，使得至少在函数体内，右值是有效的。 4.move()并不会引发实际的操作，比如下面的代码中，A a的构造析构都与move无关，move只是一种强制类型转换，或者说是一种语法糖，告诉调用者，”a现在可以被安全移走，后续不保证a是有效的”等信息。1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;using namespace std;class A&#123;public:A()&#123; std::cout &lt;&lt; &quot;Constructor&quot; &lt;&lt; std::endl;&#125;~A()&#123; std::cout &lt;&lt; &quot;Destructor&quot; &lt;&lt; std::endl;&#125;&#125;;void f(const A&amp; a)&#123; std::cout &lt;&lt; &quot;Calling LValue Version&quot; &lt;&lt; std::endl;&#125;// void f(A&amp;&amp; a)&#123;// std::cout &lt;&lt; &quot;Calling RValue Version&quot; &lt;&lt; std::endl;// &#125;int main()&#123; A a; std::cout &lt;&lt; &quot;sentinel 1&quot; &lt;&lt; std::endl; f(std::move(a)); std::cout &lt;&lt; &quot;sentinel 2&quot; &lt;&lt; std::endl; return 0;&#125;// 输出结果Constructorsentinel 1Calling LValue Versionsentinel 2 Destructor 若最后一段稍微进行修改：12345678910111213int main()&#123; std::cout &lt;&lt; &quot;sentinel 1&quot; &lt;&lt; std::endl; f(A()); std::cout &lt;&lt; &quot;sentinel 2&quot; &lt;&lt; std::endl; return 0;&#125;// 输出结果sentinel 1ConstructorCalling LValue VersionDestructorsentinel 2 模板的推导规则带模板的引用参数推导规则：要理解参数推导规则，我们先来看一下引用叠加规则，注意下面的T不一定是模板，而是实际的类：1、T&amp; + &amp; = T&amp;2、T&amp; + &amp;&amp; = T&amp;3、T&amp;&amp; + &amp; = T&amp;4、T或T&amp;&amp; + &amp;&amp; = T&amp;&amp; 我们可以看到，只要存在一个&amp;,那就按左值引用&amp;来算，而只有只出现一个或者两个&amp;&amp;才是右值引用。当然，形参实参一个&amp;都没有必然是传值调用了。于是，如果我们的函数形参定义为&amp;&amp;，那么不管传入的参数是啥，都能够保持它的引用特性。引用的折叠是编译器的特性，也就是编译器如果看到三个&amp;&amp;&amp;，会直接用一个&amp;来进行替代。引用的折叠只能够发生在类型需要推导的情况下，如果类型不需要推导而出现了多个引用符号那么编译器会直接报错，比如我们是无法定义int&amp;&amp;&amp; i=0;这样的句子的，因为不涉及类型的推导，编译器不会自动将三个&amp;换成一个。 我们将示例代码稍微进行修改，以下面这段代码为例分析一下带模板的引用参数推导规则：123456789101112void F(const Widget&amp; a);void F(Widget&amp;&amp; a);template&lt;class A&gt;void G(A &amp;&amp;a)&#123;F(a); &#125;Widget w;G(w); // 传入左值，A被推导为Widget&amp;（注意万能引用传入左值就变成左值引用）， 左值， // 调用的是void F(const Widget&amp; a);G(std::move(w)) // 传入右值，A被推导为Widget，a的类型是右值引用，但是a本身在函数G内是一个左值，因此调用的依然是void F(const Widget&amp; a); 首先分析函数G引用参数的推导规则：分为两种情况讨论（再次提醒，T是实际编程时候一个确定的类型，不是template）：1、若实参为T&amp;，则模板参数A应被推导为引用类型T&amp;。（由引用叠加规则第2点T&amp; + &amp;&amp; = T&amp;和A&amp;&amp;=T&amp;，可得出A=T&amp;）唔，换个角度，这么理解, 传入T&amp;，也就是A &amp;&amp;a = T&amp; a, 只有当A = T&amp;才能达成，因为T &amp;&amp;&amp; = T&amp;。 2、若实参为T&amp;&amp;，则模板参数A应被推导为非引用类型T。（由引用叠加规则第4点T或T&amp;&amp; + &amp;&amp; = T&amp;&amp;和A&amp;&amp;=T&amp;&amp;，可得出A=T或T&amp;&amp;，强制规定A=T）同样，如果实参是T&amp;&amp;， 那么只有当A=T或者A=T&amp;&amp;才能做到，C++直接规定，这个时候，A=T而不是T&amp;&amp;. 这一切看起来都非常自然，然而，不能够忽略的是，上述函数G的函数体内，a实际上是一个左值，只是带有右值引用的型别，因此G(std::move(w))调用的f依然是void f(const A&amp; a);,这实际上大部分时候会与调用者的需求不一致。 完美转发为了解决这样的问题，需要有一种机制，使得调用实参的左右值特性能够被保留下来，于是就有了完美转发这样的概念。即std::forward&lt;T&gt;。将上述改为：12345template&lt;class A&gt;void G(A &amp;&amp;a)&#123;F(std::forward&lt;A&gt;(a)); &#125; 则能够将a的左右值特性和其他修饰完整转发到F函数中。和move不同的是，如果G接收的实参是左值，那么forward不会像move一样强制将实参转为右值。这是怎么做到的呢？上述例子中，如果G接收实参类型为T&amp;, 那么A推导为T&amp;，此时G实例化调用的是F(std::forward&lt;T&amp;&gt;(a));如果实参类型是T&amp;&amp;， 那么A推导为T，此时G实例化调用的是F(std::forward&lt;T&gt;(a));，forward会执行强制类型转换，转为右值类型。也就是说，std::forward会自动对非引用类型进行强制类型转换到右值。一个非常简单实现的forward函数如下, 如果G被传入右值，那么T推导为A, 这时候static_cast param折叠后变成static_cast param， 是一个右值。如果G被传入左值，那么T被推导为A&amp;, 这时候static_cast param折叠后变成static_cast param，是一个左值，不会被强制类型转换。12345template&lt;typename T&gt;T&amp;&amp; forward(typename remove_reference&lt;T&gt;::type&amp; param)&#123;return static_cast&lt;T&amp;&amp;&gt; param;&#125; forward在不带模板推导的情况下是非常容易出错的，不带模板推导的情况下，forward常用错引用符号，将完美转发的结果搞反，所以如果明确知道要使用一个右值，应该用move而不是forward, forward主要是针对带有模板推导的参数转发。]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++11泛型编程]]></title>
    <url>%2F2019%2F05%2FCPP11%2FC-11%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[C++11型别推导数组类型与指针类型的转换C++有一个一直以来大家都习以为常的特性，那就是数组名字就是数组首元素的指针。一个数组形参可以接受一个指向数组首元素指针的实参，看起来这两者是一样的，但是其实进行了某种程度的退化，如果使用不当，很可能会造成析构不当(数组部分元素没有被析构到)。注意有一种情况下，数组是不会退化成指针(也就是保留其大小信息)， 那就是被传引用调用时。 数组其实是有型别的，比如说const char name[]=&quot;hello&quot;;的型别就是const char [6], 它的引用版本(作为函数参数的时候)是 const char (&amp;)[6]。123template &lt;typename T&gt;void f(T&amp; param);void g(T param) 传引用调用的时候，利用数组类型带大小这个特点，我们能够在编译器就能够获得传入数组的大小，利用的是非类型模板参数。12345template &lt;typename T, std::size_t N&gt;constexpr std::size_t arraySize(T (&amp;)[N]) noexcept&#123;return N;&#125; auto关键字auto关键字在很多情况下和模板类型的推导是一致的，以下这种情况却需要区别对待，那就是initializer_list这一个新出的初始化变量的方法。（以后我们分别将这两种类型推导叫做模板类型推导和auto类型推导。）1234auto x1=27; //auto为intauto x2(27); // auto 为intauto x3&#123;27&#125; // auto为std::initializer_list&lt;int&gt;, 且只有一个元素，27auto x4=&#123;27&#125; //同上 auto推导会将大括号推导为initializer_list，这一点和其他推导是不同的，比如：123456789101112#include &lt;iostream&gt;using namespace std;auto x=&#123;11, 12, 13&#125;;template &lt;typename T&gt;void f(T param)&#123;std::cout &lt;&lt; &quot;I am called&quot; &lt;&lt; std::endl;&#125;;int main()&#123;f(&#123;11, 12, 13&#125;); // 错误，无法通过编译，默认不会讲花括号内转换成一个initializer_list类型。f(x); //正确， 输出I am called&#125; 另一个需要注意的是，auto用作函数返回值时，采用的是模板类型推导而不是auto类型推导，所以返回类似于{1, 2, 3}这样的initializer_list也是不被允许的。 还有一个容易被混淆的点就是auto非常类似于 模板类型推导，但是不同于函数模板参数中会保留修饰词如const, auto并不会保留（函数按值传递不保留修饰词，这里也一样，auto是复制变量时，就不会保留修饰词）。要想要保留修饰词，需要使用decltype关键字。1234Widget w;const Widget&amp; cw = w;auto myWidget1 = cw; // myWidget1是Widget类型，不再具有const和引用decltype(auto) myWidget2 = cw; // myWidget2是const Widget&amp;类型，能够保留修饰词 实际的编程中，应该多用auto来代替显式指定变量类型，以避免没必要的隐式的强制类型装换。 decltype关键字decltype一般用于返回值类型随着输入参数变化的函数，它的作用就是返回一个表达式或者一个值得型别。 decltype与C++11中的返回值型别尾序语法(trailing return type syntax)12345678910111213141516#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;template &lt;typename T, typename Index&gt;auto f(const T&amp; container, Index i) -&gt; decltype(container[i])&#123;std::cout &lt;&lt; container[i] &lt;&lt; std::endl;return container[i];&#125;int main()&#123;std::vector&lt;int&gt; v&#123;11, 12, 13&#125;; f(v, 0); //正确， 输出11&#125; 函数将会返回container[i]的类型的返回值，且是引用返回。decltype如果作用于比名字更加复杂的左值表达式中，将总是返回一个引用，比如对int x, decltype((x))将返回int&amp;, 而decltype(x)的推导结果却是int， 不带引用。这个区别只在C++14上面，自动推导返回值类型的时候比较重要，而在C++11中几乎不会用到。 非类型模板参数https://blog.csdn.net/lanchunhui/article/details/49634077 类的非类型模板参数类的非类型模板参数需要在实例化类的时候手工进行指定，而函数的非类型模板化参数则可以纯粹由编译器推导得出。非类型模板参数不允许类对象(enum除外)和浮点数，其余的是可以的。123456789101112131415161718emplate&lt;typename T, int MAXSIZE=20&gt;class Stack&#123;public:Stack():idx(0)&#123;&#125;bool empty() const &#123; return idx == 0;&#125;bool full() const &#123; return idx == MAXSIZE;&#125;void push(const T&amp;);void pop();T&amp; top();const T&amp; top() const;private:int idx; T elems[MAXSIZE];&#125;Stack&lt;int, 10&gt; stackSize10;Stack&lt;int&gt; stackSize20; //使用了缺省参数 函数的非类型模板参数形如下面的代码，不一样的是模板类型可以由推导得出，不一定需要显式传入。12345678template &lt;typename T, std::size_t N&gt;constexpr std::size_t arraySize(T (&amp;)[N]) noexcept&#123;return N;&#125;char helloStr[] = &quot;hello&quot;;arraySize(helloStr); //返回6 又如：12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;template &lt;typename T&gt;bool f(const T&amp; a, const T&amp; b)&#123;std::cout &lt;&lt; (a &gt; b) &lt;&lt; std::endl;return a &gt; b;&#125;template &lt;typename T&gt;class A&#123;public:A(T a)&#123;std::cout &lt;&lt; &quot;Constructor&quot; &lt;&lt; std::endl;&#125;&#125;;int main()&#123;f&lt;int&gt;(0, 1); //正确， f(0, 1); //正确，T会被正确推导 A&lt;int&gt; a(1); // 正确A b(1); // 错误，编译不通过&#125; C++泛型编程以及函数重载 enable_if_t enable_if SFINAE(Substitution Failure Is Not An Error)123456789101112long multiply(int i, int j) &#123; return i * j; &#125;template &lt;class T&gt;typename T::multiplication_result multiply(T t1, T t2)&#123;return t1 * t2;&#125;int main(void)&#123;multiply(4, 5);&#125; main 函数调用 multiply 会使编译器会尽可能去匹配所有候选函数，虽然第一个 multiply 函数明显是较优的匹配，但是为了得到一个最精确的匹配，编译器依然会尝试去匹配剩下的候选函数，此时就会去推导 第二个multiply 函数，中间在参数推导的过程中出现了一个无效的类型 int::multiplication_result ，但是因为 SFINAE 原则并不会报错。 待续]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[颜色模型与显示]]></title>
    <url>%2F2019%2F04%2F%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%98%BE%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[导言总用有五类颜色模型，分别是：CIE, RGB, YUV, HSL/HSV, and CMYK 来自色彩空间中的HSL、HSV、HSB有什么区别？ - MoonCancer的回答 - 知乎https://www.zhihu.com/question/22077462/answer/105844680 的回答可以很好地解释描述颜色的几个重要的方面： 色相（表，表现）：即色彩的相貌和特征。自然界中色彩的种类很多，色相指色彩的种类和名称。如；红、橙、黄、绿、青、蓝、紫等等颜色的种类变化就叫色相。明度（表，面子）：指色彩的亮度或明度，也叫明亮度。颜色有深浅、明暗的变化。比如，深黄、中黄、淡黄、柠檬黄等黄颜色在明度上就不一样，紫红、深红、玫瑰红、大红、朱红、桔红等红颜色在亮度上也不尽相同。这些颜色在明暗、深浅上的不同变化，也就是色彩的又一重要特征一一明度变化。色彩的明度变化有许多种情况，一是不同色相之间的明度变化。如：白比黄亮、黄比橙亮、橙比红亮、红比紫亮、紫比黑亮；二是在某种颜色中加白色，亮度就会逐渐提高，加黑色亮度就会变暗，但同时它们的纯度(颜色的饱和度)就会降低，三是相同的颜色，因光线照射的强弱不同也会产生不同的明暗变化。。纯度（里，里子）：指色彩的鲜艳程度，也叫饱和度。原色是纯度最高的色彩。颜色混合的次数越多，纯度越低，反之，纯度则高。原色中混入补色，纯度会立即降低、变灰。物体本身的色彩，也有纯度高低之分，西红柿与苹果相比，西红柿的纯度高些，苹果的纯度低些。 所谓的颜色模型，大都是在这几个方面进行的描述。 CIE颜色模型CIE是首个基于人类对颜色的感受来定义的颜色空间，后续也有一些改进版本，计算机视觉中接触较少，这里不多展开。 RGB颜色模型RGB模型是最容易理解的一个颜色模型了，RGB不是一种颜色空间，而是一种颜色模型，因为RGB以及其颜色混合是符合物理意义的，它的三个值都是代表着实际的物理意义。 sRGB主要用于互联网的图片，这涉及到一个叫做gamma校正的知识点，gamma校正也是一种常见的预处理方法。gamma校正主要原因是RGB是一种线性的模型，认为(0.5, 0, 0)的颜色亮度就是(1.0, 0, 0)的一半，但是显示器实际上并不是线性的。 YUV或者YIQ, YCbCr等。YUV中的Y是Luminance，流明，也就是明度，UV则用于指定色彩（色相）和饱和度(纯度)，YUV的产生主要是为了分离出灰度图，如果YUV只有Y，那么也是能够显示出来的，只不过只能够显示出灰度图而不带有颜色。 YCbCr是YUV的翻版，属于YUV系列，Y依然是明度，但是Cb和Cr则是蓝色色度和红色色度的分量。我们知道，灰度可以由RGB三个分量计算得出，那么如果知道RB和灰度，其实也是可以推算回来G的，这也是为什么大部分颜色空间都是三维的，因为最终基于的颜色模型就是只有三维，再怎么转换秩也不会提升，多余三维的都是因为某种目的故意添加冗余信息。 YCbCr 有许多取样格式，主要的采样格式有YCbCr 4:2:0、YCbCr 4:2:2、YCbCr 4:1:1和 YCbCr 4:4:4。其中YCbCr 4:1:1 比较常用，其含义为：每个点保存一个 8bit 的亮度值（也就是Y值），每 2x2 个点保存一个 Cr 和Cb 值，图像在肉眼中的感觉不会起太大的变化。所以，原来用 RGB(R,G,B 都是 8bit unsigned) 模型，每个点需要 8x3=24 bits（如下图第一个图）. 而使用YUV411仅需要 $8+(8/4)+(8/4)=12bits$，平均每个点占12bits。这样就把图像的数据压缩了一半。简而言之，就是认为人眼看的没那么精细，就让多个像素点共用一个颜色值来粗暴地达到压缩的效果。 YUV 444，未经压缩的版本 YUV 411, 水平每四个像素共用一个色度 YUV 422， 水平每两个像素共用一个色度 YUV 420， 这个有点特殊，也比较神奇。420不是说Cr就不要了，而是Cr和Cb轮流着要。什么意思呢，就是说，水平方向，第一行每两个像素抽一个Cr, 第二行每两个像素抽一个Cb，上下两行共享Cr和Cb，也就是说第一行用第二行的Cb, 第二行用第一行的Cr。这样子，一个2x2的像素框中，存4个Y值，1个Cr和一个Cb值，共需要六个byte， 比RGB需要的4 * 3 =12 bytes减少一倍。 HSV(又叫HSB)或者HSLHSV(HSB)或者HSL实际上是RGB颜色模型转换到柱坐标空间。也就是说，它们并不是一种新的颜色模型，只是RGB用某种方式由柱坐标所表示出来而已，RGB对于计算机非常友好，但是对于艺术创造者就不是了，很简单的例子，没人能说请往RGB三个通道进行调整所代表的颜色变动，人眼一般只能区分颜色，亮度，饱和度这样感性的问题 。HSV转换后的空间是: H (hue), S (saturation), V (value)，最后一个值也可以叫做B (brightness)，也就是 HSV == HSB，完全只是冠名权不同。HSV更多的是被艺术创造者所使用，因为它的三个值能够最直观地反映颜色的感官的变化。 HSL和HSV非常类似，只是L代表(Lightness)，和HSV的前两个字母虽然一样，但是实际空间是不一样的，只是用了一样的名字罢了。 HSB 和 HSL 在字面意思上是一样的： H 指的是色相（Hue），就是颜色名称，例如“红色”、“蓝色”； S 指的是饱和度（Saturation），即颜色的纯度； L（Lightness） 和 B（Brightness）是明度，颜色的明亮程度在原理和表现上，HSL 和 HSB 中的 H（色相） 完全一致，但二者的 S（饱和度）不一样， L 和 B （明度 ）也不一样： HSB 中的 S 控制纯色中混入白色的量，值越大，白色越少，颜色越纯； HSB 中的 B 控制纯色中混入黑色的量，值越大，黑色越少，明度越高 HSL 中的 S 和黑白没有关系，饱和度不控制颜色中混入黑白的多寡； HSL 中的 L 控制纯色中的混入的黑白两种颜色。 gamma校正当我们计算出场景中所有元素的最终颜色(RGB)后，我们必须将颜色显示到显示器上，但是显示器的显示能力是不同的，计算机的真彩色65535显示器并不能全部显示出来。显示器有一个物理特性，就是两倍的输入电压产生的并不是两倍的亮度，传统的CRT显示器输入电压产生的亮度约为输入电压（注意电压已经被归一化到0-1范围）的2.2次幂，这个2.2被称为显示器的gamma值。由gamma值我们知道显示器的亮度输出并不是线性的，线性的亮度输出需要非线性的电压调节。每一种设备都有其特定的gamma值，任何设备的gamma值基本不会等于1，等于1的设备是一种理想的线性的状态。 上图是人眼感受亮度和实际物理亮度的对比，人眼对比较暗的亮度变化比较敏感，对于比较亮的部分的变化则不那么敏感，上图中上面一行是人感受到的亮度变化，而下面一行则是光子数量的变化。可以看到，上面一行亮度由0.3到0.6,视觉上相当于下面一行0.1到0.2的变化。 我们从0.1到0.2这一档就可以看出，光子数量无需增加一倍，人眼感受到的亮度已经增加了一倍。而在亮的部分，下面一行(光子数)从0.7变化到1.0, 人眼感受到的亮度变化则几乎不变。人眼感受到的亮度这样的变化规律和显示器的gamma规律其实是非常接近的，这也是用gamma的一个原因，举个例子，假如gamma是2， 输入电压从0.1到0.2，实际上显示器显示的亮度是从$0.1^2$变成$0.2^2 = (0.1 + 0.1)^2 = 4 x 0.1^2$, 变成了四倍，而光子亮度（与电压相关）则只是增长了一倍。同样可以尝试比较下电压从0.9到1.0, 显示亮度 CRT中，物理亮度为电压的2.2次幂，而对于人眼，物理亮度也是人眼感受亮度的2次幂，这就解决了显示器亮度非线性的问题，因为非线性显示的亮度反而更加贴合人的肉眼观感，换句话说，我们只需线性变化电压即可获得线性的人眼感受亮度。在RGB颜色中，我们可以认为1就是最大电压，也就是颜色(1, 0, 0)就是强度最大的红色光。 在渲染图像时，又会产生另外的一种问题，这是因为大部分算法都假设是在线性空间里工作的，认为颜色的大小代表他的强度，是线性的。举个例子，(1.0, 0,0)代表红色，而(0.5, 0,0)就是强度减半的红色。不幸的是，在显示器中显示出来时，(1.0.0)依然是(1, 0, 0)但是， (0.5, 0, 0)则是(0.28, 0, 0)了，也就是强度不再是翻倍的关系，而是接近4.5倍。如果每个颜色都是人工调出来的还好，设计师的肉眼能够自动进行校正，本身就是在一个非线性的颜色空间里面工作，只要肉眼看起来强度是两倍就行了，不管实际的电压已经不是2倍关系。但是渲染还有一些计算光照等的算法可不是人眼，它假设就是颜色强度是线性的，0.5和1就能够产生强度是两倍而不是4.5倍的肉眼效果。这就是为啥需要对颜色进行gamma校正。校正的做法就是将颜色强度首先进行一定程度的加强，然后让显示器显示出来。上图中， 为了获得线性的颜色输出，我们将(0.5, 0,0 )进行以下转换： $(0.5, 0,0)^{\frac{1}{2.2}} =(0.5, 0,0)^{0.45}=(0.73, 0,0)$。然后显示出来的时候再被显示器进行一次转换变回0.5,$(0.5, 0,0)^{\frac{1}{2.2}}*(0.5, 0,0)^{2.2} =(0.5, 0,0)$ ，这样子，我们的颜色依然可以在线性空间中计算，只是显示到显示器之前进行一次gamma校正，这样，设计师在实际设计的时候也会在线性空间中进行，算法计算出来的结果也在该空间，就不会造成冲突了。从工作原理我们可以看到，gamma校正应该只在输出到显示器之前做一次，否则进行多次gamma校正会使得强度过大而失真。 CMYKCMKT是用于打印机的颜色模型，由于打印机是反射光，和RGB这样的光源不同，其颜色模型也是不同的，反射光用的是一种减法模型，白纸是能够反射所有光线的，颜料涂上去后，则只能反射颜料的颜色了。CMYK存储了四种基色，青色 Cyan， 品红 （magenta， 偏紫色的红色），黄色 Yellow和黑色 Dark， 我们知道，黑色就是从白色中减去所有的颜色得到的最终颜色。CMYK主要用于打印，这里不再继续展开。]]></content>
      <categories>
        <category>理论基础</category>
        <category>图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PCA推导]]></title>
    <url>%2F2019%2F04%2FPCA%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[PCA原理在介绍PCA的原理前，首先回顾一下坐标系的变换以及向量的点积。两个向量的点乘代表着一个向量在另一个向量方向上的投影，并乘上另一个向量的长度。如果另一个向量刚好是单位向量，那就纯粹是一个向量在另一个单位向量上的投影：$\frac{\vec{a}\vec{b}}{|\vec{a}|} = |\vec{b}|cos\theta$。回顾坐标系，一个向量在某个坐标系的坐标分别是该向量在各坐标轴上的投影长度，因此向量的坐标可以由其在某坐标系$x’Oy’$的坐标$x’, y’$与各坐标轴方向的单位向量的乘积得出。举个例子，在平面直角坐标系中，向量(1, 1)的坐标就是(1, 1)，如果将其坐标系整体逆时针旋转45度，即新的坐标轴变成 $(\frac{\sqrt{2}}{2}, \frac{\sqrt{2}}{2})$以及$(\frac{-\sqrt{2}}{2}, \frac{\sqrt{2}}{2})$，那么新的坐标将变成： \begin{vmatrix} \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} \\ \frac{-\sqrt{2}}{2}& \frac{\sqrt{2}}{2} \end{vmatrix} \cdot \begin{vmatrix} 1 \\ 1 \end{vmatrix} = \begin{vmatrix} \sqrt{2} \\ 0 \end{vmatrix}PCA的作用就是给原始数据找一个新的坐标系，使得数据在新的坐标系下，每个字段方差最大，也就是最容易区分彼此，尽可能保留原始数据。假设这样的一个新的坐标系记为$H$, 其中$H$每一行向量都是新坐标系的每一个坐标轴坐标，是单位向量，而数据矩阵$X$每一列就是原始的一个数据样本。因此经过PCA转换后的坐标为： Z=HX在这里，我们假设X已经进行中心化，也就是所有样本每一维的均值都是0，我们还希望转换后每一个样本尽可能分散分布，也就是转换后的坐标字段间协方差最大，防止出现冗余数据，尽量加大压缩比例。总结而言就是两个目标： 字段方差最大，从而保留尽可能多的信息 字段间协方差绝对值最小（最优值为0），尽量减少冗余信息 即： argmax_H tr(ZZ^T) = argmax_H tr(HXX^TH^T)\\ ZZ^T=diag(z_1, z_2, ..., z_n)这里我们解释下为什么需要$ZZ^T$而不是$Z^TZ$等之类的其他式子最大：我们知道，$Z$的每一列都是一个新的样本(sample)，每一行是坐标的一维，或称一个字段，那么$ZZ^T$的对角线就是每一个字段的方差和，第i行第j列的元素表示第i个字段和第j个字段的协方差。注意，是字段的方差和协方差，直接讨论样本的方差和协方差（即$Z^TZ$）是没有意义的，下面我们再解释为什么。由第二个目标，我们知道，转换后的坐标系彼此之间应该线性无关，为什么呢，因为仅凭第一个目标约束条件，$H$的每一行的约束没有差别，$H$的每一行将得到完全一样的优化结果，因此我们需要添加约束使得结果唯一。假设$ZZ^T$满足第二个条件，由于$XX^T$又是实对称矩阵，那么只要$H$是正交矩阵就能满足这个要求（注意这个是充分不必要条件，非正交矩阵$H$也能用于矩阵对角化，注意，如果是相似对角化那么这个就是充分必要条件了，相似对角化是$H^{-1}AH$这种形式的），为了结果的唯一性，我们选取$H$为单位正交矩阵，因此我们有一个额外的约束就是$H$每行向量单位正交，也就是： HH^T = I综上，使用拉格朗日乘子法，列出： f(H, XX^T) = tr(HXX^TH^T) - \vec{\alpha} tr(HH^T-I)分别求导得： \begin{align} \frac{df}{dH} = tr(2XX^TH^T - 2\vec{\alpha} H^T) &= 0 \\ \Rightarrow XX^TH^T &= \vec{\alpha} H^T \\ \end{align}显然$H$是$XX^T$的特征向量，代回$f(H, XX^T)$得$f(H, XX^T) = \vec{\alpha} I$注意理解时将$f$拆开成一行一行来看，每一行的最大化实际上就是最大化这一行对应的特征值，由此可知，若$\vec{\alpha}$取$XX^T$最大的前k个特征值便可最大化$f$，与此相对应，H总共有k行，每一行是对应的特征向量。 P.S. 解释下为什么$Z^TZ$没有意义，因为不管哪个假设，我们都限定了$H$是单位正交，我们有： Z^TZ =X^TH^THX = X^TX也就是，$Z^TZ$根本与$H$的选取无关，如果$H$满足单位正交矩阵的性质。 整体流程 首先对$X$进行中心化 求出$XX^T$的特征值和特征向量 根据要求，取前k大特征值及其对应的特征向量，特征向量作为$H$每行的向量，转换后的数据为$Z = H\cdot X$ 附录为什么对角化不需要正交假设正交矩阵$Q$满足$QAQ^T=\Lambda​$，那么我们有： \begin{align} QAQ^T&=\Lambda = \sqrt{\Lambda}\sqrt{\Lambda}^T \\ \Rightarrow \sqrt{\Lambda}^{-1}QAQ^T(\sqrt{\Lambda}^{T})^{-1} &= (\sqrt{\Lambda}^{-1}Q)A(\sqrt{\Lambda }^{-1}Q)^T \\ \Rightarrow Q'AQ'^T &=I, where\ Q'=\sqrt{\Lambda}^{-1}Q\\ \Rightarrow A &= (Q'^{-1})(Q'^T)^{-1} \\ &= Q'^{-1}(Q'^{-1})^{T}\\ \Rightarrow (A^{-1})^T&= Q'Q'^T \end{align}可以看到，$Q’$并非正交矩阵，其相乘为$(A^{-1})^T$而不是$\Lambda$]]></content>
      <categories>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯学派和频率学派]]></title>
    <url>%2F2019%2F04%2F%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE%E5%92%8C%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%2F</url>
    <content type="text"><![CDATA[概率和统计概率和统计并不是一个东西，概率是已知模型，求观测值出现的可能性。而统计是已知多个观测值，求概率符合的模型（分布）和参数。切换到机器学习，统计是训练模型阶段，而概率是inference阶段。 MAP（Maximum A Posteriori Estimation ）和MLE (Maximum Likelihood Estimation)MAP和MLE都是统计的过程，分别代表着统计里面的两个学派，贝叶斯学派和频率学派。以抛硬币为例，假如小明抛十次硬币分别出现2次正面和8次反面，那么按照两种学派，我们会得到什么样的统计结果呢： 频率学派 频率学派认为，由于制造工艺不稳定，这个硬币抛出正面的概率虽然不知道，但是一定是一个固定的值，毕竟就这一个硬币。记这个抛正面的概率为p，那么当p=0.2的时候，是最可能出现这样的结果的。这就是频率学派的看家内功最大似然法。 贝叶斯学派 贝叶斯学派认为，p是一个随机变量，但是应该是符合某种分布的，一般来讲硬币应该均匀的，因此p应该在0.5附近波动，虽然说p=0.2的时候最可能出现抛出的结果，但是p=0.3的时候也有可能出这种结果啊，只不过概率相对小一点而已。为什么贝叶斯学派会争这一点呢，因为贝叶斯学派认为，p本身的概率也是要考虑进去的，p=0.2本身就是件小概率事件，即使P(A|p=0.2)概率最大，也不代表P(A|p=0.2) * P(p=0.2)概率最大。 贝叶斯学派这种雨露均沾的方法难点就在于，p的分布也是很难得到的，即使得到，要想计算\int_{-\infty}^{\infty} P(A|p) * P(p)dP(p)在没有计算机的年代也是非常辛苦的。(计算机时代出现了类似蒙特卡洛之类的估计方法)。MLE可以看做是认为P(p)是均匀分布的MAP，这时候它就完全不需要考虑P(p)的概率分布了。 至于谁对谁错？至今都还没有个定论~]]></content>
      <categories>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CMake基础]]></title>
    <url>%2F2019%2F03%2FCPP11%2FCMake%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[主要参考资料https://cmake.org/cmake/help/v3.14/manual/cmake-language.7.html这份资料将cmake的语言特性完全讲述，是了解其他所有模块的基础。 cmake的组织cmake主要有两个类型的文件 CMakeLists.txt以及 *.cmake，按照逻辑分为三种： Directory (每个目录下面的CMakeLists.txt) Scripts&lt;Scripts&gt;.cmake Modules&lt;Module&gt;.cmake最顶层的CMakeLists.txt是通过cmake .. 来进行调用的，子模块的CMakeList.txt则通过上层的add_subdirectory()来引用。不管后缀名是.txt还是.cmake，实际上就类似于一个shell脚本。Script是另外一种，需要通过 cmake -P &lt;scripts&gt;.script来执行。script不会产生build system，不能定义target。Modules可以由Directory或者Scripts进行调用，详细可以看 cmake-modules， modules通过include()来调用。 CMake的编写CMake需要使用全英文编写，因为只有7位ASCII可以跨更多的平台使用。 variablecmake的variable是cmake的基础存储单元，很多命令都是以variable的方式进行存储的。variable的类型只有string一种，即使是逻辑上的int，bool之类的数据类型，也只不过是解析时候转换成相应的类型而已。直接修改variable的命令只有set和unset两个，其余的命令均为间接的方式进行的。 变量的引用采用${&lt;variable&gt;} 的方式，并且支持嵌套，${outer_${inner_variable}_variable}， 这样就variable有相应的作用域，一共有三种作用域： Function Scope在function()…endfunction()之间的代码，如果不指定PARENT_SCOPE, 那么所有的变量定义都只在该函数内有效(通过参数传进来的外部变量不受此限制)， 也就是说在function scope内部定义的变量只能在function内部及其嵌套子函数内部有效。 Directory Scope每一个目录下的CMakeLists.txt都使用一个特定的scope，该scope会继承所有父级目录的变量，因此可以默认使用来自上一级目录的变量。 Persistent CacheCache entries have an isolated binding scope modified only by explicit request, such as by the CACHE option of the set() and unset() commands. 要添加或者修改cache变量必须要显式指定，否则cache变量将一直独立存在。cache优先级是最低的, 优先级排序是function &gt; directory &gt; cache。看官网的这一段描述。 When evaluating Variable References, CMake first searches the function call stack, if any, for a binding and then falls back to the binding in the current directory scope, if any. If a “set” binding is found, its value is used. If an “unset” binding is found, or no binding is found, CMake then searches for a cache entry. If a cache entry is found, its value is used. Otherwise, the variable reference evaluates to an empty string. 如果希望修改Parent Scope的变量，需要加上parent scope这个参数。否则，修改只会在当前scope生效。注意，cache变量时独立一个scope，无所谓parent variable的set以及unsetnormal variableSet Normal Variableset( … [PARENT_SCOPE])Set the given in the current function or directory scope. If the PARENT_SCOPE option is given the variable will be set in the scope above the current scope. Each new directory or function creates a new scope. This command will set the value of a variable into the parent directory or calling function (whichever is applicable to the case at hand). cache variableset(&lt;variable&gt; &lt;value&gt;... CACHE &lt;type&gt; &lt;docstring&gt; [FORCE])Since cache entries are meant to provide user-settable values this does not overwrite existing cache entries by default. Use the FORCE option to overwrite existing entries.这个用来定义默认变量最好了，如果不开启force, 那么在存在这个变量时，将不会改变，这样子如果用户提供了参数，那么默认参数就不会生效。cache变量还需要指定type，The must be specified as one of: BOOLBoolean ON/OFF value. cmake-gui(1) offers a checkbox. FILEPATHPath to a file on disk. cmake-gui(1) offers a file dialog. PATHPath to a directory on disk. cmake-gui(1) offers a file dialog. STRINGA line of text. cmake-gui(1) offers a text field or a drop-down selection if the STRINGS cache entry property is set. INTERNALA line of text. cmake-gui(1) does not show internal entries. They may be used to store variables persistently across runs. Use of this type implies FORCE. Set Environment Variableset(ENV{&lt;variable&gt;} &lt;value&gt;...) listlist实际上是一个有特殊格式的string, 但是通过分号隔开， 如果想要打一个分号，那必须通过转义字符。建立list有以下几种方式：set(srcs a.c b.c c.c) # sets &quot;srcs&quot; to &quot;a.c;b.c;c.c&quot;或者： set(x a &quot;b;c&quot;) # sets &quot;x&quot; to &quot;a;b;c&quot;, not &quot;a;b\;c&quot; cmake的variable分为normal, cache, environment三种。 functioncmake的function定义规则如下：function(&lt;name&gt; [arg1 [arg2 [arg3 ...]]]) COMMAND1(ARGS ...) COMMAND2(ARGS ...) ... endfunction(&lt;name&gt;)]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[神经网络结构术语合集]]></title>
    <url>%2F2019%2F01%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%9C%AF%E8%AF%AD%E5%90%88%E9%9B%86%2F</url>
    <content type="text"><![CDATA[导言快速过一遍计算机视觉中用到的网络结构的名词描述。 Inception V1-V3 Inception结构InceptionV1 https://zhuanlan.zhihu.com/p/30756181InceptionV2 + InceptionV3 https://arxiv.org/pdf/1512.00567.pdf 设计思想主要来自InceptionV2V3的论文： https://arxiv.org/pdf/1512.00567.pdf Avoid representational bottlenecks, especially early in the network. Feed-forward networks can be represented by an acyclic graph from the input layer(s) to the classifier or regressor. This defines a clear direction for the information flow. For any cut separating the inputs from the outputs, one can access the amount of information passing though the cut. One should avoidbottlenecks with extreme compression. In general the representation size should gently decrease from the inputs to the outputs before reaching the final representation used for the task at hand. Theoretically, information content can not be assessed merely by the dimensionality of the representation as it discards important factors like correlation structure; the dimensionality merely provides a rough estimate of information content.第一条就是不要尝试在网络早期就将网络的信息压缩到太小，被前面网络去除掉的信息是不能够被后续找回的，因为CNN是一个无环路的图。 Higher dimensional representations are easier to process locally within a network. Increasing the activations per tile in a convolutional network allows for more disentangled features. The resulting networks will train faster.第二条的意思就是，更加高维的输入会更加方便寻找local feature, 也就是更加方便cnn来获得局部特征，因此神经网络的激活神经元应该高一些，保留的激活部分多一些，而不是压抑激活单元。 Spatial aggregation can be done over lower dimensional embeddings without much or any loss in representational power. For example, before performing a more spread out (e.g. 3 × 3) convolution, one can reduce the dimension of the input representation before the spatial aggregation without expecting serious adverse effects. We hypothesize that the reason for that is the strong correlation between adjacent unit results in much less loss of information during dimension reduction, if the outputs are used in a spatial aggregation context. Given that these signals should be easily compressible, the dimension reduction even promotes faster learning.第三条说的是，在底层的特征可以先压缩再进行卷积，并不会影响到最终的效果，这个假设成立的前提就是，上一层的神经网络输出存在相关性，允许被压缩。注意到这条和第一条是稍微有一些相反的，第一条建议的是不要过快进行信息的压缩，而这里提出的是可以先进行1x1压缩再进行卷积是不会对最终结果有太大影响。这里的度就是玄学所在了。 Balance the width and depth of the network. Optimal performance of the network can be reached by balancing the number of filters per stage and the depth of the network. Increasing both the width and the depth of the network can contribute to higher quality networks. However, the optimal improvement for a constant amount of computation can be reached if both areincreased in parallel. The computational budget should therefore be distributed in a balanced way between the depth and width of the network.第四条就更玄学了，增加网络的宽(每层更多的filter)和深(更深的网络，少用stride)都能够提高网络的表达能力，但是特定的计算能力预算下，怎样分配宽和深是一个不容易，甚至是玄学的事情。唔，道理都懂…其实有没有人想过为什么CNN一层一层垒在一起就能够有这么强的表达能力？ Inception系列网络Inception系列网络可以参考这个链接： https://zhuanlan.zhihu.com/p/30756181Inception是一种常见的模块，其作用是在同一层获得不同scale的卷积结果。scale在物体检测领域是非常重要的一个参数，设计再良好的特征，如果scale不对也很难获得好的检测结果，当前基于RPN或者基于Anchor的two-stage detection主要也是致力于解决scale问题，因为数据刷到现在，难点一般都是对小的物体存在大量的漏检，而增强对小物体的检测能力（recall）一般又会伴随而来是大量的误检(FP)。Inception系列网络最主要的思想就是在同一层卷积神经网络里面并行多个卷积核，并将卷积结果concat起来，从而在同一层中就能够获得不同感受野的feature map。 第一代GoogleNet提出InceptionV1论文来自： https://arxiv.org/pdf/1409.4842.pdf 图1 为什么能够用1x1来进行channel数量的缩减，因为存在这样的一个假设，在神经网络最后的输出层里面，feature map有多个部分是高度相关的，可以按照相关性分为多个组，每个组可以认为是抓住了原图像中特定的区域或者特定的特征，换句话说，信息存在冗余，这是可以用1x1来进行reduce的理论基础。 同样的，文章认为，这些相关组有些cover的区域比较小，有些比较大，这就要求同一层同scale的卷积应该有多种卷积核，至于为什么采用3x3 5x5并不是因为经过精确计算这些大小的核符合要求，而是因为方便和常用，有现成的实现。 由于高层网络更应该抓住高层信息，因此论文建议，越高的层，其3x3, 5x5的卷积核应该相应地增多。当然，实际上并没有这么做，因为会额外增加网络设计的复杂性，同时这个也是非常heuristic的想法，需要手工进行设置。 有人会比较好奇，3x3, 5x5之后的结果怎样进行concate，大小不是不一致的吗，其实主要是通过对原图padding然后进行convolution得到的，比如3x3比5x5输出feature map大小是要大2的，只需要让5x5padding为1（两边共补2）就可以了。看这个tensorflow实现的方法：12345678910111213141516171819202122232425262728import d2lzh as d2lfrom mxnet import gluon, init, ndfrom mxnet.gluon import nnclass Inception(nn.Block): # c1 - c4为每条线路里的层的输出通道数 def __init__(self, c1, c2, c3, c4, **kwargs): super(Inception, self).__init__(**kwargs) # 线路1，单1 x 1卷积层 self.p1_1 = nn.Conv2D(c1, kernel_size=1, activation=&apos;relu&apos;) # 线路2，1 x 1卷积层后接3 x 3卷积层 self.p2_1 = nn.Conv2D(c2[0], kernel_size=1, activation=&apos;relu&apos;) self.p2_2 = nn.Conv2D(c2[1], kernel_size=3, padding=1, activation=&apos;relu&apos;) # 线路3，1 x 1卷积层后接5 x 5卷积层 self.p3_1 = nn.Conv2D(c3[0], kernel_size=1, activation=&apos;relu&apos;) self.p3_2 = nn.Conv2D(c3[1], kernel_size=5, padding=2, activation=&apos;relu&apos;) # 线路4，3 x 3最大池化层后接1 x 1卷积层 self.p4_1 = nn.MaxPool2D(pool_size=3, strides=1, padding=1) self.p4_2 = nn.Conv2D(c4, kernel_size=1, activation=&apos;relu&apos;) def forward(self, x): p1 = self.p1_1(x) p2 = self.p2_2(self.p2_1(x)) p3 = self.p3_2(self.p3_1(x)) p4 = self.p4_2(self.p4_1(x)) return nd.concat(p1, p2, p3, p4, dim=1) # 在通道维上连结输出 其中1x1, 3x3, 5x5分别pad 0， 1， 2个像素，来使得输出和输入大小一致。 Inception V2 在V1基础上，添加了Batch Norm 用两个3x3代替一个5x5， 参数量减少，同时增加了网络的深度，计算到的感受野却没有改变。 作者想，那能不能用2x2或者更小的卷积核来替代大核呢，于是，极端地，作者认为可以用1xn和nx1的组合来替代一个nxn的大核。这样的替代在中层（输入大小从12到20部分）是有效的，但是不能够被用于底层，也就是一开始几层。原因没有进一步说明。用1xn和nx1来替代n x n, 同样减少参数，同时增加了网络深度。实验证明，在中间层网络，用1x7和7x1的效果不错。(玄学) 增加输出的channel数量(原则2)，如下图所示，将3x3拆成1x3和3x1两个平行的channel(注意不是串联)，从而保留高维的表达。 图2 可以使用并行结构来优化Pooling。前面的规则1提到Pooling会造成represtation bottleneck，一种解决办法就是在Pooling前用1x1卷积把特征数加倍（见图3右侧），这种加倍可以理解加入了冗余的特征，然后再作Pooling就只是把冗余的信息重新去掉，没有减少信息量。这种方法有很好的效果但因为加入了1x1卷积会极大的增大 计算量。替代的方法是使用两个并行的支路，一路1x1卷积，由于特征维度没有加倍计算量相比之前减少了一倍，一路是Pooling，最后再在特征维度拼合到一起（见图4右）。这种方法即有很好的效果，又没有增大计算量。图3 图4 Inception V3Inception V2 + 辅助的分类器就变成了v3。 这个新的思想就是使用一个分类器来筛选有用的梯度，使得有效信息能够传回到底层网络，避免梯度消失等情况。这个相当于早期的监督信息，这个输出层插在网络的中间，可以理解为将梯度回传的起始点设置在了中间，辅助整体的学习。FPN系列也用了类似的思想。 Inception V4https://arxiv.org/pdf/1602.07261.pdf在此基础上，添加stem模块，Inception A， B， C， Reduction A， B等。 Reduction主要的区别就是不是直接pool为2，而是分了几个分支做stride为2的conv。实际上感觉没有InceptionV2, V3那样的比较根本性的创新。 残差系列结构Resnet残差结构是神经网络另外一个神仙操作，可以较好地解决梯度消失等困难。使用残差结构的比较经典的论文有ResNet, DenseNet和SENet等。 ResnetResNet的一个重大创新设计就是这个Residual block。当然还有一个比较出名的就是其channel先减后增的bottleneck结构。 DenseNetDense就是将残差进行到底的一个网络结构。 使用DenseBlock，每一个block的输出都会直接输入到后面的每一个Block DenseBlock之间加入过渡层(Transition Layer)来结合不同大小的feature map，实质就是1x1卷积和一个stride&gt;1的pooling操作， 当然作者选择了stride=2 Attention机制：Spatial and Channel AttentionAttention可以简单理解为通过某种机制算出某些feature map的权重，以强调网络的部分中间结果。 SENethttps://arxiv.org/pdf/1709.01507.pdfSqueeze-and-Excitation Net, SE网络对每一个输出通道计算一个重要性权重加在输出feature中。这个权重是通过几层FC和激活得到的。应该也属于某种程度的channel attention. SCA-CNNhttps://arxiv.org/pdf/1611.05594.pdfCNN领域Attention的经典之作。包含channel和spatial attention.为什么说经典，因为简单。直接通过上一层或者历史feature map获得当前层的channel权重和每个位置的权重，然后将权重应用在当前层的卷积结果中。根据channel attention和spatial attention的应用先后，分成S-C和C-S模式，实际应用差别不大。 移动端优化方面Group ConvolutionAlexNet最早提出Group Convolution， 将N个channel分成M份，分别进行卷积，然后将结果concate在一起，从而减少参数量。后续再加入了channel shuffle，把性能下降稍微解决了。 Depth-Wise Convolution: MobileNet主要提出DepthWise Conv， 意思是，首先将上一层的feature map按channel拆开，然后首先每个channel自己单独做一次卷积，得到c个channel的卷积结果，然后做一个1x1的卷积，其实还是Inception那一套，只不过连channel这样的操作都被拆开而已。 Channel Shuffle: ShuffleNet代表性操作： channel shuffle, 就是先把输出通道group，然后group之间按一定规律交换channel来进行卷积得到下一层的feature map. BottleneckBottleneck是一类结构，其特点就是先猛下采样再上采样，形成一种类似于瓶颈的结构。比如resnet就使用了这样的结果来减少参数量和加深网络。另外大部分的encoder-decoder在大范围上也可以称作是bottleneck。 神经网络的几大范式Encoder-Decoder一般用于语言翻译、语义分割、以及基于heatmap的关键点检测等，其重要特点就是encoder和decoder的网络一般是对称的，且生成结果和输入结果的大小一般一致，或等比缩放。 HourglassHourglass说实在的也算是Encoder-Decoder的一种。 FPNFeature Pyramid Network，其特点是每一层feature map都会被直接利用，直接加到下一层(残差)，又或者直接用于预测结果，并将多层feature map的结果综合起来。FPN经各大网络验证，是一种高效的提升精度的方法，可惜，用在CPU上跑实时是比较难的，BU和TD过程需要耗时太多了。参考：https://towardsdatascience.com/review-fpn-feature-pyramid-network-object-detection-262fc7482610https://arxiv.org/pdf/1612.03144.pdf 操作子Pooling Soft Pooling， 也就是我们常说的Average Pooling Hard Pooling, 也就是我们常说的Max Pooling Global Pooling, 实际上就是Pooling，一般用在输出层来替代FC层，用于适配输出结果的个数。比较狠的作者还可能把一个WxH的feature map直接pool成1x1的单个数值。global pooling的好处就是不需要FC层存储那么多参数进行那么多计算，但是坏处也是显而易见那就是，精度不太好，不容易训练。 NormalizationBatch Normalization (BN)LRNLocal Response Normalization。 ReLU neurons have unbounded activations and we need LRN to normalize that.LRN一般是在激活、池化后进行的一中处理方法。有两种模式： accross-channel和within-channel， accross-channel就是最原始的，也就是feature每个点所在channel及其相邻多个channel之内做的，相当于做一个 local_size x 1 x 1(chw)的卷积，而withn-channel则类似于avg-pooling， 只是计算公式不一样。LRN采用的计算公式为每个点除以以下分母： (1 + (\alpha/n) \sum_i x_i^2)^\beta其中$\alpha$是预定义的超参数，$n$就是local_size的大小，其含义就是该点周围的值越大则每个点最后计算的值越小(所谓的神经元抑制原理)。PS：实际感觉用处不大。 物体检测框架为啥Two-Stage比One-Stage检测效果好，RetinaNet里面解释说，One Stage中Anchor是极其不均衡的，大量的负样本和少数的正样本混合是主要的原因，并据此提出Focal Loss. 首次超越Two Stage工作。 Yolo系列Yolo v2 v3用到的IoU-K-meanshttps://lars76.github.io/object-detection/k-means-anchor-boxes/其Kmeans算Anchor的中心的时候用的是同一个组内的anchor boxes长宽分别求平均数。V2用了FPN？ YoLo V3个人感觉最大的改进就是设置了三个scale的anchor，分别在不同的层进行输出，同时添加了Residual。 SSDSSD以及RetinaNet就是所谓的堆anchor狂魔。https://zhuanlan.zhihu.com/p/33544892 YoLo采用的是中心Anchor匹配，而SSD采用的是最大IoU匹配未能够匹配的Anchor，如果和某个正样本IoU大于0.5, 也认为是该样本在该Anchor的正例这里会出现一个问题就是，一个Anchor会存在非常多的负样本，但是正样本就一两个，也就是样本是及其不平衡的，这就需要使用RetinaNet中提出来的Focal Loss之类的方法来进行匹配了。或者训练时人工丢弃部分负样本Anchor。Anchor的Size是从0.2到0.9(相对于原图)，每个特征图的每个格子的anchor数量是一样的，这就造成了底层(feature map还比较大的时候)anchor数量比较多，而顶层anchor数量比较少。 传统算子边缘检测子CannySusan https://users.fmrib.ox.ac.uk/~steve/susan/susan/node8.html待续]]></content>
      <categories>
        <category>理论基础</category>
        <category>神经网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[配置PyCharm远程调试并本地显示matplotlib图像]]></title>
    <url>%2F2018%2F10%2F%E9%85%8D%E7%BD%AEPyCharm%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E5%B9%B6%E6%9C%AC%E5%9C%B0%E6%98%BE%E7%A4%BAmatplotlib%E5%9B%BE%E5%83%8F%2F</url>
    <content type="text"><![CDATA[背景远程机器为Ubuntu，本地机器为Linux、Mac、Window均可，这里以Mac为例。需要在Pycharm远程执行调试，但是部分中间结果，特别是图像处理结果通过matplotlib即时显示在本地机器上。该功能依赖X11forward。 远程机器（Ubuntu）需要执行的操作首先开启openssh-server的X11转发1、1sudo vim /etc/ssh/sshd_config 2、找到相应的项并修改为以下值：123X11Forwarding yesX11DisplayOffset 10X11UseLocalhost no 3、重启ssh服务 安装openbox1sudo apt-get install openbox 本地机器（Mac）需要执行的操作首先安装xquartz1brew install caskroom/cask/xquartz 其次开启ssh的X11，由于我们直接用PyCharm的shell，因此就改Pycharm即可1、通过Pycharm-&gt;Run-&gt;Edit Configurations，添加一条python的环境变量1DISPLAY=thucloud-PowerEdge-T630:10.0; 其中DISPLAY的值需要由以下命令获得：通过命令ssh -X user@IP连接到远程主机,执行echo $DISPLAY即可获得DISPLAY的值，将这个值填在Pycharm的环境变量里即可。注意，如果这个DISPLAY的值是空的，证明配置不对。 大功告成]]></content>
      <categories>
        <category>系统</category>
        <category>环境配置</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络爬虫SCRAPY爬取GOOGLE PLAY APPS]]></title>
    <url>%2F2018%2F10%2F%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%ABSCRAPY%E7%88%AC%E5%8F%96GOOGLE-PLAY-APPS%2F</url>
    <content type="text"><![CDATA[Scrapy框架介绍scrapy作为一种可以轻易扩展为分布式的爬虫框架，其内部框架采用类似于消息队列的方式进行任务的调度分发也就不奇怪了，消息队列使得各组件低耦合。至于这个消息队列是存在于单机内存中还是分布式集群中的一个节点，就看业务的需要了。采用生产者-消费者模式进行组织的系统实际上就是三块：任务的生产者，消费者以及消息队列。对应框架图上：生产者：Spiders消费者：Downloader消息队列：Scheduler以及Engine各部分组件由Engine进行驱动，Engine可以看做是一个main函数吧。生产者生产任务（在这里就是要爬取的url）放到消息队列，消费者从消息队列中取得任务进行实际的下载。下载结果交给生产者进行解析，解析结果的一部分是我们要提取的信息，它直接进入Pipeline进行处理，另一部分则是从下载结果中提取的新的任务（url），它将进入消息队列中。整个流程是： (1)一开始Scheduler的队列是空的，所以需要人工hard code一个起始的种子url列表，spider将这些url封装成Request，Engine将这些Request转给Scheduler (2)与此同时，一旦Scheduler队列非空，Engine将从Scheduler中抽取一个Request给Downloader进行实际下载，Downloader的产出即Response由engine转给spider (3)Spider抽取Response里面两类信息：第一类就是页面上我们实际要爬取的内容Item，以及这个页面包含的符合要求的url列表。Item由Engine转入Item的深层加工流水线Pipeline，进行进一步的筛选、存储等， url由Spider封装为Request经由Engine交给Scheduler。重复(2)框架图中engine和各组件交换Request和Response的过程中可以插入各种额外的流程，称之为中间件，所以不难想象一共有两种种中间件：Downloader middlewares(对应图中4，5)和 Spider middlewares(对应图中6，7)。除此之外，Item Pipeline中可以插入处理Item的各个步骤。 工程框架我们以爬取google play上面apk应用的信息为例。安装完scrapy后，可以采用scrapy startproject gglplay来创建一个叫做gglplay的爬虫工程，其结构如下：项目框架其中settings.py类似于一种静态配置文件，所有增加的中间件以及pipeline等都需要在settings中进行注册，类似于Android的manifest这样的角色。run_spider.py是人工添加进去的，下面会说到。 Spider首先，创建的项目中是没有默认Spider的，需要手工新建一个Spider类，继承scrapy.Spider或它的子类。也可以采用scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt; 来根据模板生成一个spider。 所有新增的Spider都需要放在spider文件夹下。 name变量每一个Spider的关键变量就是 name， 在启动的时候通过name来搜索这个spider。比如说scrapy crawl gglplay就启动了一个name=&#39;gglplay&#39;的爬虫。新增爬虫无需更新settings，只需要保证每个Spider都有唯一的name就好了。 allow_domains爬虫允许爬取的域 start_urls如上面所介绍，就是起始的url，种子url rule定义url匹配了某个规则后，用什么样的parse函数进行内容提取。比如说：Rule(LinkExtractor(allow=(“/store/apps/details”,)), callback=’parse_app’, follow=True)就定义了一旦LinkExtractor获得了匹配的url，那么对这个url进行下载后的内容将由parse_app这一个回调函数进行处理。这样子就能使得每个不同的页面，对应不同的parse函数，不会说要一个parse函数去处理所有的页面，毕竟格式不同，xpath不同，所需的信息也不同。MiddlewaresMiddleware分为Downloader middlewares和Spider middlewares。但是需要注意的是，Middleware需要在setting进行注册，定义middleware的处理顺序。 Spider middlewaresSpider middlewares在Spider的输入和输出做文章，所以关键的两个钩子就是process_spider_input和process_spider_output,都是顾名思义的了。12345678910111213141516171819class GglplaySpiderMiddleware(object): def process_spider_input(self, response, spider): # Called for each response that goes through the spider # middleware and into the spider. # Should return None or raise an exception. return None def process_spider_output(self, response, result, spider): # Called with the results returned from the Spider, after # it has processed the response. # Must return an iterable of Request, dict or Item objects. for i in result: # if result[&apos;package&apos;] not in spider.bf: # spider.bf.add(result[&apos;package&apos;]) # yield i # else: # continue yield i 在settings中的注册语句：123SPIDER_MIDDLEWARES = &#123; &apos;gglplay.middlewares.GglplaySpiderMiddleware&apos;: 543,&#125; 关于Spider Middleware，详细可以看http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html Downloader MiddlewareDownloader Middleware和Spider Middleware几乎一样，详细可以看：http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html Item Pipeline一般在Item Pipeline中进行item的筛选，持久化存储等工作，如果Pipeline中某个item被认定为需要丢弃，可以通过raise DropItem来发起，该Item就不会再经过后续的pipeline。定义好pipeline后还需要在settings中定义他们的顺序，比如：1234ITEM_PIPELINES = &#123; &apos;gglplay.pipelines.GglplayPipeline&apos;: 300, &apos;gglplay.pipelines.StoreItemPipeline&apos;: 400,&#125; 定义了两个模块的处理流程，item先经过gglplay.pipelines.GglplayPipeline,再经过gglplay.pipelines.StoreItemPipeline,注意到数字越小，处理优先级越高。详细可以看：http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html 运行脚本直接命令行scrapy crawl的方式难以调试，为了方便调试，我们可以在项目顶层建立一个driver，这样子在pycharm之类的IDE中就能够比较方便进行断点调试了。run_spider.py内容如下：1234567if __name__ == &quot;__main__&quot;: # TODO: do something here from scrapy import cmdline name = &apos;gglplay&apos; cmd = &apos;scrapy crawl &#123;0&#125;&apos;.format(name) cmdline.execute(cmd.split()) pass 整个项目放置在(private, 仅作者可见)：https://github.com/ruanmk/google-play-crawler]]></content>
      <categories>
        <category>系统</category>
        <category>系统架构</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[UBUNTU搭建DEEPSPEECH语音转录系统]]></title>
    <url>%2F2018%2F10%2FUBUNTU%E6%90%AD%E5%BB%BADEEPSPEECH%E8%AF%AD%E9%9F%B3%E8%BD%AC%E5%BD%95%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[介绍Mozilla开源了百度的DeepSpeech，实际上模型的关键突破在于既提高了速度，也提高了准确性，其提升来源于RNN的结构设计，还有匹配的并行化方案。开源的版本由于修改了CTCLoss的计算op，因此配置上比较恶心，需要一个特定版本的tensorflow，实际上我们可以通过修改代码，直接将WarpCTC作为一个op动态加载进来。DeepSpeech项目地址： https://github.com/mozilla/DeepSpeechTest WarpCTC地址（暂时不会用到）：https://github.com/baidu-research/warp-ctc 注意我们这里直接根据DeepSpeech的项目进行部署，不进行任何修改，也不手动引入WarpCTC。 安装在介绍其原理前，我们首先将这个库跑起来。关键步骤实际上都在https://github.com/mozilla/DeepSpeech/blob/master/README.md中，但是由于其采用了一个修改的op，因此还是会出现一些坑。以下安装流程基于 Ubuntu 14.04 x86_64， python 2.7基础上。 使用模型1、安装git large file storage各平台的安装说明在https://github.com/git-lfs/git-lfs/blob/master/INSTALLING.md, 针对Ubuntu 14.04, 执行下面代码即可：1curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash 2、下载代码安装完git-lfs之后，我们直接clone repo即可。1git clone https://github.com/mozilla/DeepSpeech 3、下载预训练好的文件（非必要）项目自带了一个英文的语音识别模型，大小为1.2G，可以另开一个线程下载，用于deepspeech的尝试。由于下载时间较长，到这步可以放着下载，先做后面的步骤。 4、创建python虚拟环境（当然也可以装在系统python中）,这里起名字py27，注意要安装virtualenv。12virtualenv py27 --python=python2.7source py27/bin/activate 5、安装deepspeech的python客户端(Python Binding)deepspeech有预编译的二进制文件（也可以自己编译）1pip install deepspeech 到这一步已经能够完成了整个的使用了，具体的使用参数为：1deepspeech -h 6、安装deepspeech的二进制命令行客户端（python和命令行客户端任选其一即可，只是个客户端程序）1python util/taskcluster.py --target . 至此，仅仅使用deepspeech进行inferrence的情况下，配置完成，如果需要训练自己的模型，还需要进行下面的配置。 训练模型要想训练模型，在完成使用模型相应的安装步骤后，还需要安装tensorflow训练库，由于使用了warpCTC，因此这里直接打包了一个修改过的tensorflow，个人认为没必要，还不如弄成一个独立的库。 1、 安装必要的库1234cd DeepSpeechpython util/taskcluster.py --target /tmp --source tensorflow --artifact tensorflow_warpctc-1.4.0-cp27-cp27mu-linux_x86_64.whlpip install /tmp/tensorflow_warpctc-1.4.0-cp27-cp27mu-linux_x86_64.whlpip install -r requirements.txt 每一步都必须做完。 如果是mac系统下，安装这个tensorflow版本即可（实际上最好最为额外的op引入，我非常讨厌这样重新打包tensorflow的方式）1pip install https://index.taskcluster.net/v1/task/project.deepspeech.tensorflow.pip.osx.08894f64fc67b7a8031fc68cb838a27009c3e6e6/artifacts/public/tensorflow_warpctc-1.4.0-cp27-cp27m-macosx_10_12_x86_64.whl 2、 必须下载native client(也就是上面的python binding基础上不再是选择，而是必须下载)1python util/taskcluster.py --target . 3、 检查1./DeepSpeech.py --help 如果不出错，那么训练的环境配置完成。具体的训练步骤可以继续参考README.md. 问题列表 pip install deepspeech返回can not find …之类的1、首先确保python是合适的版本，如果不放心。12sudo apt-get install python2.7 python2.7-dev build-essential libssl-dev libffi-dev python-devpip install --upgrade pip 问题的原因实际上来自libssl和libffi，因为不能识别部分header导致不能够正确比对python版本要求等。]]></content>
      <categories>
        <category>系统</category>
        <category>环境配置</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[用cmake发布库]]></title>
    <url>%2F2018%2F05%2FCPP11%2F%E7%94%A8cmake%E5%8F%91%E5%B8%83%E5%BA%93%2F</url>
    <content type="text"><![CDATA[基本原理除了用cmake进行库的编译以外，我们还需要掌握如何写一个cmake方便别人在使用我们的库的时候能够顺利链接。本篇仅说明一下整个链接和安装的思路，理清看文档的顺序，其具体的参数和函数签名都有详细的文档的。 首先推荐大家下载这一个Toy Example:https://gitlab.kitware.com/cmake/community/uploads/a91192d30ee2df45bd225b08c3a20c1d/FooBar.zip其展示了一个最小的，支持安装以及被其他库find_package的写法。另外可以参考这篇文章，用中文讲述地比较清晰：http://www.yeolar.com/note/2014/12/16/cmake-how-to-find-libraries/这里是关于find_package的完整API阐述：https://cmake.org/cmake/help/latest/command/find_package.html#command:find_package通过本篇文章，咱们希望知道以下目的是怎样达成的： 将我们需要对外公布的lib以及header安装在指定的位置 提供多个.cmake脚本（XXConfig.cmake, XXTarget.cmake, XXConfigVersion.cmake）， 使得客户在调用find_package的时候能够成功找到所需库和头文件的位置，这里我们用name来表示库的名字，这相当于设置了以下的变量：1234&lt;NAME&gt;_FOUND&lt;NAME&gt;_INCLUDE_DIRS or &lt;NAME&gt;_INCLUDES&lt;NAME&gt;_LIBRARIES or &lt;NAME&gt;_LIBRARIES or &lt;NAME&gt;_LIBS&lt;NAME&gt;_DEFINITIONS find_package做了啥为了理解要给find_package提供什么内容，我们首先要理解find_package到底做了哪一些步骤。find_package找库的位置可以分为两种方法： 模块模式(Module Mode)：查找形如Find&lt;name&gt;.cmake这样的脚本，通过该脚本定义以上的变量。查找的位置有两处：1. 设置的${CMAKE_MODULE_PATH}(由当前CmakeLists.txt脚本或调用命令行等设置)下；2. &lt;CMAKE_ROOT&gt;/Modules/ ，比如CMAKE_ROOT=/usr/bin/cmake/share/cmake-3.10, 这个位置保存了cmake认为编程人员常用的库，如lua: FindLua.cmake等。这些路径保留了Find&lt;name&gt;.cmake这样的路径，cmake匹配上后将直接执行，类似于include(Find&lt;name&gt;.cmake)。如果模块模式找不到相应的cmake文件，那么就会启动配置模式，配置模式则比较复杂。 配置模式(Config Mode ) The CONFIG option, the synonymous NO_MODULE option, or the use of options not specified in the basic signature all enforce pure Config mode. In pure Config mode, the command skips Module mode search and proceeds at once with Config mode search. 配置模式指定配置所在的位置非常直白，它有一系列的搜索顺序，但是日常我们只需要设置&lt;name&gt;_DIR为包含config的文件夹路径即可。如果&lt;name&gt;_DIR找到了所需的配置文件，那么就会停止搜索，否则会按照顺序进行搜索，可能构造的搜索地址为： CMake constructs a set of possible installation prefixes for the package. Under each prefix several directories are searched for a configuration file. The tables below show the directories searched. Each entry is meant for installation trees following Windows (W), UNIX (U), or Apple (A) conventions:12345678910&lt;prefix&gt;/ (W)&lt;prefix&gt;/(cmake|CMake)/ (W)&lt;prefix&gt;/&lt;name&gt;*/ (W)&lt;prefix&gt;/&lt;name&gt;*/(cmake|CMake)/ (W)&lt;prefix&gt;/(lib/&lt;arch&gt;|lib*|share)/cmake/&lt;name&gt;*/ (U)&lt;prefix&gt;/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/ (U)&lt;prefix&gt;/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/(cmake|CMake)/ (U)&lt;prefix&gt;/&lt;name&gt;*/(lib/&lt;arch&gt;|lib*|share)/cmake/&lt;name&gt;*/ (W/U)&lt;prefix&gt;/&lt;name&gt;*/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/ (W/U)&lt;prefix&gt;/&lt;name&gt;*/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/(cmake|CMake)/ (W/U) On systems supporting macOS Frameworks and Application Bundles the following directories are searched for frameworks or bundles containing a configuration file:123456&lt;prefix&gt;/&lt;name&gt;.framework/Resources/ (A)&lt;prefix&gt;/&lt;name&gt;.framework/Resources/CMake/ (A)&lt;prefix&gt;/&lt;name&gt;.framework/Versions/*/Resources/ (A)&lt;prefix&gt;/&lt;name&gt;.framework/Versions/*/Resources/CMake/ (A)&lt;prefix&gt;/&lt;name&gt;.app/Contents/Resources/ (A)&lt;prefix&gt;/&lt;name&gt;.app/Contents/Resources/CMake/ (A) 这其中&lt;prefix&gt;的变量替换顺序为(其实不用记住这么多，实际上常用的就是&lt;name&gt;_DIR)： Search paths specified in the _ROOT CMake variable and the _ROOTenvironment variable, where &lt;PackageName&gt; is the package to be found. The package root variables are maintained as a stack so if called from within a find module, root paths from the parent’s find module will also be searched after paths for the current package. This can be skipped if NO_PACKAGE_ROOT_PATH is passed. See policy CMP0074. Search paths specified in cmake-specific cache variables. These are intended to be used on the command line with a -DVAR=value. The values are interpreted as semicolon-separated lists. This can be skipped if NO_CMAKE_PATH is passed: 123CMAKE_PREFIX_PATHCMAKE_FRAMEWORK_PATHCMAKE_APPBUNDLE_PATH Search paths specified in cmake-specific environment variables. These are intended to be set in the user’s shell configuration, and therefore use the host’s native path separator (; on Windows and : on UNIX). This can be skipped if NO_CMAKE_ENVIRONMENT_PATH is passed: 1234&lt;PackageName&gt;_DIRCMAKE_PREFIX_PATHCMAKE_FRAMEWORK_PATHCMAKE_APPBUNDLE_PATH Search paths specified by the HINTS option. These should be paths computed by system introspection, such as a hint provided by the location of another item already found. Hard-coded guesses should be specified with the PATHS option. Search the standard system environment variables. This can be skipped if NO_SYSTEM_ENVIRONMENT_PATHis passed. Path entries ending in /bin or /sbin are automatically converted to their parent directories: 1PATH Search paths stored in the CMake User Package Registry. This can be skipped if NO_CMAKE_PACKAGE_REGISTRY is passed or by setting the CMAKE_FIND_PACKAGE_NO_PACKAGE_REGISTRY to TRUE. See the cmake-packages(7)) manual for details on the user package registry. Search cmake variables defined in the Platform files for the current system. This can be skipped if NO_CMAKE_SYSTEM_PATH is passed: 123CMAKE_SYSTEM_PREFIX_PATHCMAKE_SYSTEM_FRAMEWORK_PATHCMAKE_SYSTEM_APPBUNDLE_PATH Search paths stored in the CMake System Package Registry. This can be skipped if NO_CMAKE_SYSTEM_PACKAGE_REGISTRY is passed or by setting theCMAKE_FIND_PACKAGE_NO_SYSTEM_PACKAGE_REGISTRY to TRUE. See the cmake-packages(7)) manual for details on the system package registry. Search paths specified by the PATHS option. These are typically hard-coded guesses. config的名字只能有这两种形式：&lt;name&gt;Config.cmake 或者 &lt;lower-case-package-name&gt;-config.cmake，一旦设置好&lt;name&gt;_DIR，并且cmake通过这个路径找到了相应的两种形式(之一)的配置文件，就会设置&lt;name&gt;_CONFIG为找到的配置文件(两者之一)的全部路径。 自定义模块config.cmakefind_package. 不管是配置式还是模块式，最终都是设置相应的库的路径。 模块模式下面我们看一下模块式的一个例子：FindMFC.cmake12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# Distributed under the OSI-approved BSD 3-Clause License. See accompanying# file Copyright.txt or https://cmake.org/licensing for details.#.rst:# FindMFC# -------## Find MFC on Windows## Find the native MFC - i.e. decide if an application can link to the# MFC libraries.## ::## MFC_FOUND - Was MFC support found## You don&apos;t need to include anything or link anything to use it.# Assume no MFC supportset(MFC_FOUND &quot;NO&quot;)# Only attempt the try_compile call if it has a chance to succeed:set(MFC_ATTEMPT_TRY_COMPILE 0)if(WIN32 AND NOT UNIX AND NOT BORLAND AND NOT MINGW) set(MFC_ATTEMPT_TRY_COMPILE 1)endif()if(MFC_ATTEMPT_TRY_COMPILE) if(NOT DEFINED MFC_HAVE_MFC) set(CHECK_INCLUDE_FILE_VAR &quot;afxwin.h&quot;) configure_file($&#123;CMAKE_ROOT&#125;/Modules/CheckIncludeFile.cxx.in $&#123;CMAKE_BINARY_DIR&#125;$&#123;CMAKE_FILES_DIRECTORY&#125;/CMakeTmp/CheckIncludeFile.cxx) message(STATUS &quot;Looking for MFC&quot;) # Try both shared and static as the root project may have set the /MT flag try_compile(MFC_HAVE_MFC $&#123;CMAKE_BINARY_DIR&#125; $&#123;CMAKE_BINARY_DIR&#125;$&#123;CMAKE_FILES_DIRECTORY&#125;/CMakeTmp/CheckIncludeFile.cxx CMAKE_FLAGS -DCMAKE_MFC_FLAG:STRING=2 -DCOMPILE_DEFINITIONS:STRING=-D_AFXDLL OUTPUT_VARIABLE OUTPUT) if(NOT MFC_HAVE_MFC) configure_file($&#123;CMAKE_ROOT&#125;/Modules/CheckIncludeFile.cxx.in $&#123;CMAKE_BINARY_DIR&#125;$&#123;CMAKE_FILES_DIRECTORY&#125;/CMakeTmp/CheckIncludeFile.cxx) try_compile(MFC_HAVE_MFC $&#123;CMAKE_BINARY_DIR&#125; $&#123;CMAKE_BINARY_DIR&#125;$&#123;CMAKE_FILES_DIRECTORY&#125;/CMakeTmp/CheckIncludeFile.cxx CMAKE_FLAGS -DCMAKE_MFC_FLAG:STRING=1 OUTPUT_VARIABLE OUTPUT) endif() if(MFC_HAVE_MFC) message(STATUS &quot;Looking for MFC - found&quot;) set(MFC_HAVE_MFC 1 CACHE INTERNAL &quot;Have MFC?&quot;) file(APPEND $&#123;CMAKE_BINARY_DIR&#125;$&#123;CMAKE_FILES_DIRECTORY&#125;/CMakeOutput.log &quot;Determining if MFC exists passed with the following output:\n&quot; &quot;$&#123;OUTPUT&#125;\n\n&quot;) else() message(STATUS &quot;Looking for MFC - not found&quot;) set(MFC_HAVE_MFC 0 CACHE INTERNAL &quot;Have MFC?&quot;) file(APPEND $&#123;CMAKE_BINARY_DIR&#125;$&#123;CMAKE_FILES_DIRECTORY&#125;/CMakeError.log &quot;Determining if MFC exists failed with the following output:\n&quot; &quot;$&#123;OUTPUT&#125;\n\n&quot;) endif() endif() if(MFC_HAVE_MFC) set(MFC_FOUND &quot;YES&quot;) endif()endif() 配置模式具体参考https://gitlab.kitware.com/cmake/community/uploads/a91192d30ee2df45bd225b08c3a20c1d/FooBar.zip 关键是提供&lt;name&gt;Config.cmake和&lt;name&gt;ConfigVersion.cmake两个文件，并且在Version中配置PACKAGE_VERSION_COMPATIBLE和PACKAGE_VERSION_EXACT两个变量。 Export及其使用我们虽然通过find_package能够定义这些库所在的位置以及头文件的位置，但是需要一种方式将其作为一个target加进来，以用于编译和链接(否则他们只是纯粹的放在内存里的几个变量而已。这些需要通过target脚本来实现，一般target脚本都是和配置模式一起使用的，&lt;name&gt;Config.cmake中常include (&quot;${CMAKE_CURRENT_LIST_DIR}/&lt;name&gt;-target.cmake&quot;)来直接调用target，直白来说，target里面就是添加了这几个库作为target，一个例子如下, 这个脚本是cmake通过export命令生成的，具体可以参考https://cmake.org/cmake/help/v3.12/command/export.html： ：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# Generated by CMakeif(&quot;$&#123;CMAKE_MAJOR_VERSION&#125;.$&#123;CMAKE_MINOR_VERSION&#125;&quot; LESS 2.5) message(FATAL_ERROR &quot;CMake &gt;= 2.6.0 required&quot;)endif()cmake_policy(PUSH)cmake_policy(VERSION 2.6)#----------------------------------------------------------------# Generated CMake target import file.#----------------------------------------------------------------# Commands may need to know the format version.set(CMAKE_IMPORT_FILE_VERSION 1)# Protect against multiple inclusion, which would fail when already imported targets are added once more.set(_targetsDefined)set(_targetsNotDefined)set(_expectedTargets)foreach(_expectedTarget foo bar) list(APPEND _expectedTargets $&#123;_expectedTarget&#125;) if(NOT TARGET $&#123;_expectedTarget&#125;) list(APPEND _targetsNotDefined $&#123;_expectedTarget&#125;) endif() if(TARGET $&#123;_expectedTarget&#125;) list(APPEND _targetsDefined $&#123;_expectedTarget&#125;) endif()endforeach()if(&quot;$&#123;_targetsDefined&#125;&quot; STREQUAL &quot;$&#123;_expectedTargets&#125;&quot;) unset(_targetsDefined) unset(_targetsNotDefined) unset(_expectedTargets) set(CMAKE_IMPORT_FILE_VERSION) cmake_policy(POP) return()endif()if(NOT &quot;$&#123;_targetsDefined&#125;&quot; STREQUAL &quot;&quot;) message(FATAL_ERROR &quot;Some (but not all) targets in this export set were already defined.\nTargets Defined: $&#123;_targetsDefined&#125;\nTargets not yet defined: $&#123;_targetsNotDefined&#125;\n&quot;)endif()unset(_targetsDefined)unset(_targetsNotDefined)unset(_expectedTargets)# Create imported target fooadd_library(foo SHARED IMPORTED)# Create imported target baradd_executable(bar IMPORTED)# Import target &quot;foo&quot; for configuration &quot;Debug&quot;set_property(TARGET foo APPEND PROPERTY IMPORTED_CONFIGURATIONS DEBUG)set_target_properties(foo PROPERTIES IMPORTED_LOCATION_DEBUG &quot;/Users/rmk/Downloads/FooBar/cmake-build-debug/foo/libfoo.dylib&quot; IMPORTED_SONAME_DEBUG &quot;/Users/rmk/Downloads/FooBar/cmake-build-debug/foo/libfoo.dylib&quot; )# Import target &quot;bar&quot; for configuration &quot;Debug&quot;set_property(TARGET bar APPEND PROPERTY IMPORTED_CONFIGURATIONS DEBUG)set_target_properties(bar PROPERTIES IMPORTED_LOCATION_DEBUG &quot;/Users/rmk/Downloads/FooBar/cmake-build-debug/bar/bar&quot; )# This file does not depend on other imported targets which have# been exported from the same project but in a separate export set.# Commands beyond this point should not need to know the version.set(CMAKE_IMPORT_FILE_VERSION)cmake_policy(POP) 生成配置模式所需文件的CMakeLists.txt脚本摘自https://gitlab.kitware.com/cmake/community/uploads/a91192d30ee2df45bd225b08c3a20c1d/FooBar.zip123456789101112131415161718192021222324252627282930313233# Add all targets to the build-tree export setexport(TARGETS foo bar FILE &quot;$&#123;PROJECT_BINARY_DIR&#125;/FooBarTargets.cmake&quot;)# Export the package for use from the build-tree# (this registers the build-tree with a global CMake-registry)export(PACKAGE FooBar)# Create the FooBarConfig.cmake and FooBarConfigVersion filesfile(RELATIVE_PATH REL_INCLUDE_DIR &quot;$&#123;INSTALL_CMAKE_DIR&#125;&quot; &quot;$&#123;INSTALL_INCLUDE_DIR&#125;&quot;)# ... for the build treeset(CONF_INCLUDE_DIRS &quot;$&#123;PROJECT_SOURCE_DIR&#125;&quot; &quot;$&#123;PROJECT_BINARY_DIR&#125;&quot; CACHE PATH &quot;&quot;)configure_file(FooBarConfig.cmake.in &quot;$&#123;PROJECT_BINARY_DIR&#125;/FooBarConfig.cmake&quot; @ONLY)# ... for the install treeset(CONF_INCLUDE_DIRS &quot;\$&#123;FOOBAR_CMAKE_DIR&#125;/$&#123;REL_INCLUDE_DIR&#125;&quot;)configure_file(FooBarConfig.cmake.in &quot;$&#123;PROJECT_BINARY_DIR&#125;$&#123;CMAKE_FILES_DIRECTORY&#125;/FooBarConfig.cmake&quot; @ONLY)# ... for bothconfigure_file(FooBarConfigVersion.cmake.in &quot;$&#123;PROJECT_BINARY_DIR&#125;/FooBarConfigVersion.cmake&quot; @ONLY)# Install the FooBarConfig.cmake and FooBarConfigVersion.cmakeinstall(FILES &quot;$&#123;PROJECT_BINARY_DIR&#125;$&#123;CMAKE_FILES_DIRECTORY&#125;/FooBarConfig.cmake&quot; &quot;$&#123;PROJECT_BINARY_DIR&#125;/FooBarConfigVersion.cmake&quot; DESTINATION &quot;$&#123;INSTALL_CMAKE_DIR&#125;&quot; COMPONENT dev)# Install the export set for use with the install-tree# allowing others to include FooBarTargets.cmakeinstall(EXPORT FooBarTargets DESTINATION &quot;$&#123;INSTALL_CMAKE_DIR&#125;&quot; COMPONENT dev) 参考资料http://www.voidcn.com/article/p-ydfqrabf-ru.htmlhttps://gitlab.kitware.com/cmake/community/wikis/doc/tutorials/How-to-create-a-ProjectConfig.cmake-filehttp://www.yeolar.com/note/2014/12/16/cmake-how-to-find-libraries/ 例子：https://gitlab.kitware.com/cmake/community/uploads/a91192d30ee2df45bd225b08c3a20c1d/FooBar.zipexport函数: https://cmake.org/cmake/help/v3.12/command/export.html]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>CMake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[由人脸识别引发的Softmax改进]]></title>
    <url>%2F2018%2F05%2F%E7%94%B1%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E5%BC%95%E5%8F%91%E7%9A%84Softmax%E6%94%B9%E8%BF%9B%2F</url>
    <content type="text"><![CDATA[背景Softmax由于其每个分类正负样本的概率是对称的，使得其类内不够紧凑，针对这一缺点各种文章百花齐放，各种小修小改，其关键目的就是提高inter-class dispension和intra-class compactness.对于close-set的人脸识别任务，现有的分类手段已经能够做得比较好了，但是对于open-set的人脸识别任务，就要求即使是不在训练集里面的人脸，也应该要将同一个人的脸的feature映射到特征空间里一个紧凑的位置从而使得无监督的聚类算法可以介入。这里有一个基本的要求，就是类内的最大距离一定不能大于类间的最小距离，部分文章还额外加上一个margin，也就是类内的最大距离要小于类间的最小距离减去margin，也就是还得留出一定的隔离带。这个要求也被大部分的Siamese类network所接受。open-set的人脸识别实际上是一种metric learning， 学的关键就是这个feature，而不是后面的classifier 下面我们来看看基于改进softmax的每一家具体的方案。注意：以下的x是需要学习的样本的特征表示，是要学习的目的之一啊，不是固定的，我们要学的就是一个可以无监督分类的x，所谓metric learning, 可以理解为固定W学习x然后固定x计算新的W，W对应FC层的权重，x则是这之前的神经网络提取的特征，Wx一般输入到Softmax中，下面的所有推导中，都假设当前W固定，下一步是优化x，并说明为啥这些改动会使得得到的x更加紧凑 CenterLoss (ECCV2016)这是由 https://kpzhang93.github.io/papers/eccv2016.pdf (A Discriminative Feature Learning Approach for Deep Face Recognition)这篇文章提出的。并且这样类似的方法并不只此一家，softmax + 某种能够强调类内compactness的loss都可以，比如softmax + tripletloss（不实用，好难设计样本对，exmaple mining不好做，训练时直接一步loss为0欠拟合是喜闻乐见的）等等。毕竟属于社会主义初级阶段，依然还是loss之间的排列组合。这篇文章还澄清了一对很重要的概念，那就是separable features和discriminative feature。separable feature可以理解为神经网络fc前最后一层，是线性可分的。而discriminative则不仅要separable，还必须保持类内紧凑，从而方便最近邻聚类等算法进行聚类，以保持对未知类别的可分性。换句话说，给一个不在训练集里面的人脸的多个样本，输出的feature不仅要和库里面的不同，并且这几个额外的样本在特征空间里面是要聚成一团的，可以无监督地得出这是一个新的类别。这样子就使得人脸识别模型在新来一个人的脸后不需要重新进行训练。从close-set的识别能力扩展到了open-set。 正如其名字所表示的那样，center loss在每一个batch中，对每一类的所有样本的feature算了一个均值，然后损失函数为原softmax（类间差异）+center loss（类内紧凑）。这篇文章开了一个类内紧凑的头，但是缺点是 每个batch都得要预先算一个中心，每个batch中心又是在不断改变的，这就导致了不一定会收敛(实际上作者将centor loss的权重调的比较小所以这个问题在实验中并没有体现出来。 这篇文章还有一个副产物，那就是发现softmax的结果总是天然地按照弧度扇形分布，这个结果被后续的文章所使用，并产生了angular margin这么一个新的热词。 SphereFace (CVPR2017)https://arxiv.org/pdf/1704.08063.pdf首次提出angular margin，不再是之前画个二维散点图然后用直线区分几个分类的那种（Euclidean margin，比如SVM），现在它将样本看做是分布在圆弧(二维)或者高维球面上的点，根据圆（球）心角来区分几个不同的分类。 第一阶段 Modified-Softmax也是初步的A-Softmax作者提出，softmax的结果虽然很像可以按角度去进行区分，实际上却又不是那么简单（比如上图a在不限制$W$的模长的情况下，样本在特征空间上的分布是不均匀的），于是需要对softmax进行一些修改。为了方便说明，这里以二分类为例，对于原始softmax, 两个类的分界线可以写成： W_1x+b1=W_2x+b2\Rightarrow (W_1-W_2)x + b_1-b_2=0这就是softmax上面的幂指数相等的那个线。在原始的softmax函数中，两个W的模能够对分界线有较大的影响，想象到极限情况下，$\lVert W_1\rVert=+\infty,\lVert W_2\rVert=0$，这时候符合第一类的样本只需要满足$W_1x&gt;0$,bias此时已经变得不重要了。这个条件此时是非常容易满足的，只要不是完全和$W_1$正交就好，也就是$W_1$这边x的空间会摊得非常大，而$W_2$这边就被压缩的几乎看不到了，图b能够稍微看到一些这样的迹象，但是不准确。当然，一个正常训练的样本均衡的模型实际上并不会出现这样的$W$。如图b所示，两个向量的中间位置的夹角，并不能够区分两类样本（稍微调整下位置还是可以的），也就是，这个中心，还不够‘中心’，因为组成这个中心的两边是不平衡的。中心不平衡带来的问题就是，从$W_1$到$W_2$这个扇形里面，每一个单位弧度所包含的样本概率密度是不一样的，靠近$W_1$这边，由于$W_1$的模较大，其对应的同角度的x的模长范围就限制得比较松，或者同等模长的$x$则可以取值的角度范围较大，此时的实际分界线是偏向于模长较短的$W_2$这边的(即留给$W_1$更多位置)，而不是图b中的二分位置。有问题吗？没问题，只是没必要这样而已，如果能够限制两$W$的模长一致，那么就不需要算这个实际的分界点了，直接就是$(W_1+W_2)/2$，也就是角平分线就可以了。为了方便，假如我们限制$\lVert W_1\rVert = \lVert W_2\rVert$,且$b_1=b_2=0$,那么我们有这样的分界线： \lVert x\rVert (cos(\theta_1)-cos(\theta_2))=0这时候学习到的样本空间就能够很好地由角度分开了(毕竟现在就是在直接优化$\theta$啊，能学不到嘛。。。实际上是优化x和W来达到优化$\theta​$的目的)，对应上图d。至此，我们已经能够用angular来替代euclidean softmax了,但是仅仅是替代，依然还没解决类内不紧凑的问题。 第二阶段 增加类内紧凑性后的A-Softmax为了进一步分开两类，显然像SVM一样引入一块间隔margin能够增加模型的鲁棒性。这块margin中的样本不会被判断为任何一个类，实际上模型学习到的feature不会映射到这个区间内。看图f，在没有引入m之前，中间的Angular Bisector就是两类的分界线，在分界线的左边，以$W_1$为中心，越往两边其被分为第一类的置信度就越低，在分界线附近分为任何一类的置信度就一样了。要引入一个间隔，实际上就是以angular bisector为中心，在附近引入一块区域，特征落在这块区域中时，既不是第一类，也不是第二类。压缩的办法比较粗暴，那就是在bisector左边压缩$\theta_1$，而在右边压缩$\theta_2$，以左侧为例，引入下式作为判断类1的分界点： \lVert x\rVert (cos(m\theta_1)-cos(\theta_2))>0右侧判断类2的则相应的是： \lVert x\rVert (cos(m\theta_2)-cos(\theta_1))>0看左边对应的公式，这条式子的特别之处就是$\theta_2$是不变的，而使用$m\theta_1$来整体替代之前的$\theta_1$，$m$是一个大于1的数值，这就会压缩$\theta_1$的取值范围，又不影响$\theta_2$,如果此时$\theta_1$靠近bisector附近，那么$\lVert x\rVert (cos(m\theta_1)-cos(\theta_2))&lt;0$, 此时该样本不能被判为类1.同理用一样的方法对另一边进行操作，也会压缩另一个类2的取值范围，类2也会出现一个区域不能被判为2，这段既不能为1也不能为2的区域就组成了我们要的margin.训练过程中落在这些区域的样本由于被梯度往左右两边(拉向$W_1, W_2$)时loss会更少，因此充分训练后，可分的样本都不会出现在这个区域中。 CosFacecosface的想法也是比较类似的，但是m放的位置不同，它采用的是： \lVert x\rVert (cos(\theta_1)-m-cos(\theta_2))>0 \lVert x\rVert (cos(\theta_2)-m-cos(\theta_1))>0注意这个减号，因为cos在$[0, \pi]$之间是单调递减的，这个作用大致也是相当于往$\theta$乘上一个大于1的数，来压缩相应边$\theta$的取值范围。 ArcFacehttps://arxiv.org/pdf/1801.07698.pdf一样的配方，m放在了cos里面，间隔改成了： \lVert x\rVert (cos(\theta_1 + m)-cos(\theta_2))>0 \lVert x\rVert (cos(\theta_2+m)-cos(\theta_1))>0几种Loss的区别ArcFace里面详细分析了几种修补版softmax的区别，并指出只有ArcFace这种方式能够保持间隔在每个$\theta_1, \theta_2​$保持一致。]]></content>
      <categories>
        <category>理论基础</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>损失函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++虚函数的意义]]></title>
    <url>%2F2018%2F05%2FCPP11%2FCpp%E8%99%9A%E5%87%BD%E6%95%B0%E7%9A%84%E6%84%8F%E4%B9%89%2F</url>
    <content type="text"><![CDATA[下面以一个简单的例子说明virtual的作用，作为继承和多态的重要组件，如果没有虚函数，那么多态的实现将非常的困难。首先明确一点，类成员函数中this的类型取决于该函数定义的位置，在父类中，this的类型是父类，在子类中，this的类型是子类。比如父类A和B，父类有一个成员函数test(), 其函数体中通过this调用了test1, 如果子类没有override这个函数，那么子类中，test()函数体里面this的类型依然是父类的类型。我们看下面三个例子来理解这一点：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;thread&gt;//This function will be called from a threadclass A&#123;public: void test()&#123; this-&gt;test1(); &#125; void test1()&#123; std::cout &lt;&lt; &quot;I am base&quot; &lt;&lt; std::endl; &#125;&#125;;class B:public A&#123; virtual void test1()&#123; std::cout &lt;&lt; &quot;I am Not Base&quot; &lt;&lt; std::endl; &#125;&#125;;int main() &#123; //Launch a thread B b; b.test(); return 0;&#125;// 运行结果// I am base// I am base 这个例子中，子类B没有覆盖A::test，因此test函数体内，this类型依然是A*，这就造成了b.test()调用的是A::test1()，这往往不是想要的结果。而如果加上virtual, 那么就能够调用到真正想要调用的函数了，看下面的改动：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;class A&#123;public: void test()&#123; this-&gt;test1(); &#125; virtual void test1()&#123; std::cout &lt;&lt; &quot;I am base&quot; &lt;&lt; std::endl; &#125;&#125;;class B:public A&#123; virtual void test1()&#123; std::cout &lt;&lt; &quot;I am Not Base&quot; &lt;&lt; std::endl; &#125;&#125;;int main() &#123; B b; b.test(); A a; a.test(); return 0;&#125;// 运行结果// I am Not Base// I am base 这个例子中，test1是虚函数，因此即使B没有覆盖test函数，this的编译时类型依然是A*，但是在调用this-&gt;test1()的时候会查找虚函数表，然后知道this实际类型应该是B*并调用B::test1()。具体要调用A::test1还是B::test1只能在运行时知道。注意哦，如果子类同时覆盖了调用的函数test，那么也是能够调用到想要的test1的，因为此时编译时this的类型就已经是B*了。看下面的代码：123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;class A&#123;public: void test()&#123; this-&gt;test1(); &#125; void test1()&#123; std::cout &lt;&lt; &quot;I am base&quot; &lt;&lt; std::endl; &#125;&#125;;class B:public A&#123;public: void test1()&#123; std::cout &lt;&lt; &quot;I am Not Base&quot; &lt;&lt; std::endl; &#125; void test()&#123; this-&gt;test1(); &#125;&#125;;int main() &#123; B b; b.test(); A a; a.test(); return 0;&#125;// 运行结果// I am Not Base// I am base]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++Map的区别]]></title>
    <url>%2F2018%2F05%2FCPP11%2FCppMap%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[导言面试别人时我常问一个编程题，也就是leetcode上的two sum，其中使用map和unordered_map的速度区别高达(打败)40%和(打败)88%,也就是快了接近一倍。使用map打败40%, 20ms, 使用unorderred_map打败88%， 12ms。 123456789101112131415class Solution &#123;public:vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; std::unordered_map&lt;int, int&gt; m; for(int i=0; i &lt; nums.size(); i++ )&#123; int residual = target-nums[i]; if(m.find(nums[i]) != m.end())&#123; return &#123;m[nums[i]], i&#125;; &#125;else&#123; m.insert(pair&lt;int, int&gt;(residual, i)); &#125; &#125; return &#123;&#125;;&#125;&#125;; 那么他们有什么区别呢？ 原理上的区别原理上来说，map采用二叉树(如红黑树等)来存储键值，键是有序的，而unordered_map则是采用哈希的方法来存储，是无序的。map的键必须定义operator &lt;，而unordered_map必须定义operator =。C++的unordered_map其实就是Hashmap，但是因为c++有太多第三方库占用了std::hash_map这么一个名字，因此起名叫做unordered_map. (毕竟大家都能给std加料，这也是namespace的设计我感觉到还存在不足的地方) 另有hash_set, hash_multiset等数据结构https://cloud.tencent.com/developer/article/1338322 使用上的区别map由于是有序的，因此可以按区间取元素，存在以下方法，而unordered_map则不存在以下方法： lower_boundReturn iterator to lower bound (public member function ) upper_boundReturn iterator to upper bound (public member function ) equal_rangeGet range of equal elements (public member function ) 其他容器也类似，有两个版本，在原理上分使用二叉树的和使用hashmap的，在是否允许键重复分multiXXX和非multi的。]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[卡尔曼滤波器]]></title>
    <url>%2F2018%2F04%2F%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8%2F</url>
    <content type="text"><![CDATA[卡尔曼滤波器卡尔曼滤波可以看这篇文章：http://web.mit.edu/kirtley/kirtley/binlustuff/literature/control/Kalman%20filter.pdf 基本假设卡尔曼滤波器的基本假设是，对于t时刻一个状态值 x_t ,注意状态值是一个n维向量。它是通过某种转换关系从上一个时刻的状态 x_{t-1} 转换过来的，并且这个转换过程是存在白噪的，也就是： \begin{equation} x_t = \Phi x_{t-1} + \omega_t \end{equation}同时，卡尔曼滤波认为$x_t$的观测值$z_t$（观测值是一个m维向量，m和n不一定相等，取决于测量方法）与其状态值也存在一个关系： z_t = Hx_t + v_t这里显然$v_t​$就是测量误差，这里也认为这个测量误差符合高斯分布。 卡尔曼滤波认为这两个转换关系中的$\Phi​$和$H​$都是不随着时间改变的，是一个固定的值，由所建模的物理问题所决定，不需要每一帧重新计算，至于初始值是什么，就需要看卡尔曼滤波建模的实际物理量是什么了，比如说这个物理量是速度的话，且是匀加速运动，由于两帧之间的速度关系由加速度来决定，那么加速度就由$\Phi​$来进行建模。 问题定义定义了这么多，实际上我们要怎样从每一帧及其历史的观测值找到实际的$x_t$呢？答案是，找不到真实的$x_t$, 只能找到它的最优估计值$\hat{x_t}$，定义计算到的$\hat{x_t}$与实际的$x_t$的误差为$e_t = x_t- \hat{x_t}$， 显然，我们的目标函数可以定义为： \tag{loss} \min\sum_i^n E(e_{t,i}^2)也就是每一维误差的平方和。换一种角度，用概率的思维可以表达为最大似然函数，也就是给定观测值，求实际值的最大似然： \max P(\hat{x_t}|z_t)我们认为测量误差$v_t$符合高斯分布，那么 \begin{align} \max P(\hat{x_t}|z_t) &= \max P(z_t/H - v_t/H|z_t) \\ &=\max P(v_t|z_t) \\ &= \max P(v_t) \\ &= \max C_t e^{\frac{-(z_t-Hx_t)^2}{2\sigma^2}} \\ \end{align}其中$C_t$是高斯分布的常数项，最大化多帧似然函数为： \max \Pi_t{P(\hat{x_t}|z_t)}取对数改连乘为连加，再对$\sigma_t$求导即可求出每一帧最优的$\sigma_t$ 卡尔曼滤波变量定义以均方误差为例，我们优化的目标是： \min\sum_i^n E(e_{t,i}^2)为了获得这个最小的均方误差，我们先定义三个协方差矩阵： \begin{align} Q &= E[\omega_t\omega_t^T] \\ R &= E[v_tv_t^T] \\ P_t &= E[e_te_t^T] \\ &= E[(x_t-\hat{x_t})(x_t-\hat{x_t})^T] \end{align}那么我们需要最小化的就是$P_t$的迹$Tr(P_t)$。现在我们使用类似迭代证明的方式来进行说明，假如通过某种途径，我们初步获得了$x_t$的估计值，记为$\hat{x’_t}$，这时候需要通过卡尔曼滤波来进一步优化这样的一个结果。假如我们认为每一步的精细化都是一种线性变换，那么精细化的公式都是类似于$\hat{x_t}=a\hat{x’_t} + b$这样的形式，卡尔曼滤波认为更加精细化的结果可以通过以下的式子获得： \hat{x_t} = \hat{x'_{t}} + K_t(z_t - H\hat{x'_{t}})这条公式为什么成立下面会说明。其中$K_t$称之为Kalman gain, 记所谓的innovation 或measurement residual为 i_t = z_t - H\hat{x'_{t}}将$z_t$代入得： \hat{x_t} = \hat{x'_{t}} + K_t(Hx_t+ v_t - H\hat{x'_{t}})现在我们知道了怎样精细化对$x_t$的预测，那么接下来的问题就是解决$K_t$以及消除$x_t$了。由优化目标，我们应该选择一个$K_t$使其最小化$Tr(P_t)$，因此我们需要获得$P_t$关于$K_t$的式子，再进行求导计算。由于： x_t-\hat{x_t} = x_t-\hat{x'_{t}} - K_t(Hx_t + v_t - H\hat{x'_{t}}) = (I-K_tH)(x_t-\hat{x'_{t}})-K_tv_t将\hat{x_t}代入P_t中，注意到噪声v_t和x_t以及\hat{x'_{t}}显然都不相关，因此: \begin{align} P_t &= E[(x_t-\hat{x_t})(x_t-\hat{x_t})^T] \\ &= (I-K_tH)E[(x_t-\hat{x_t})(x_t-\hat{x_t})^T](I-K_tH) + K_tE[v_tv_t^T]K_t^T \\ &= (I-K_tH)P'_t(I-K_tH) + K_tRK_t^T \\ &= P'_t - K_tHP'_t - P'_tH^TK_t^T + K_t(HP'_kH^T+R)K_t^T \end{align}上式用$P’_t$消除了对$x_t$的依赖，而$P’_t$同$\hat{x’_t}$一样认为是通过某种途径初步获得的，两者在迭代一开始的初始值一般是0。将$P_t$的迹与$K_t$进行求导，注意到公式： \nabla_ATr(AB) = B^T我们有： \frac{dTr(P_t)}{dK_t} = -2(HP'_t)^T + 2K_t(HP'_kH^T+R)使之为0，求得最优的$K_t$为： K_t = P'_tH^T(HP'_tH^T+R)^{-1}其中记$S_t = HP’_tH^T+R$。将$K_t$代入$P_t$, 可以消除后两项得： \begin{align} P_t &= P'_t - K_tHP'_t \\ &= P'_t - P'_tH^T(HP'_tH^T+R)^{-1}HP'_t \\ &= (I-K_tH)P'_k \\ \end{align}我们现在获得了同一帧之间所有变量的迭代优化公式，现在需要将前后两帧联系起来。卡尔曼滤波认为，下一帧的粗略估计值与上一帧的精细估计值存在这样的关系： \hat{x}'_{t+1} = \Phi \hat{x_t}根据这一假设，我们能得到所有其他的粗略估计值： \begin{align} e'_{t+1} &= x_{t+1}-x'_{t+1} \\ &=(\Phi x_t + \omega_t) - \Phi \hat{x}_t \\ &= \Phi e_t + \omega_t \\ \end{align} \begin{align} P'_{t+1} &= E[(\Phi e_t+\omega_t)(\Phi e_t+\omega_t)^T] \\ &= E[(\Phi e_t)(\Phi e_t)^T] + E[\omega_t\omega_t^T] \\ &= \Phi P_t\Phi + Q \end{align}整体流程 初始化$P’_0, e’_0, \hat{x’_0}$为0，或者为其他数字，这是根据建模需求的求出来的 计算$K_t = P’_tH^T(HP’_tH^T+R)^{-1}$ 计算出当前帧调整后的状态 \hat{x_t} = \hat{x'_{t}} + K_t(Hx_t+ v_t - H\hat{x'_{t}}) 更新卡尔曼滤波的参数 $P_t = P’_t - K_tHP’_t$ 准备下一帧的粗略估计值 $\hat{x}’_{t+1} = \Phi \hat{x_t}​$ $P’_{t+1}= \Phi P_t\Phi + Q$ 小结可以看出，卡尔曼滤波的更新跟状态量一点关系都没有，即使没有状态量，卡尔曼滤波每一帧的参数更新都是固定的。这也是为什么称之为滤波器的原因之一。]]></content>
      <categories>
        <category>理论基础</category>
        <category>动态跟踪</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++11并发技术]]></title>
    <url>%2F2018%2F03%2FCPP11%2FC-11%E5%B9%B6%E5%8F%91%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[thread与std::asyncC++ 11 增加了对线程的基本支持，其使用方式与其他语言的线程写法几乎一样，也就是定义需要跑的函数，然后开启多个线程，线程内部提供同步的数据结构。一个标准的线程写法如下图所示： 1234567891011121314#include &lt;iostream&gt;#include &lt;thread&gt;//This function will be called from a threadvoid call_from_thread() &#123; std::cout &lt;&lt; &quot;Hello, World&quot; &lt;&lt; std::endl;&#125;int main() &#123; //Launch a thread std::thread t1(call_from_thread); //Join the thread with the main thread t1.join(); return 0;&#125; C++11除了线程外，还提供了一个更高阶抽象的std::async， 如果没有其他的要求，最好使用std::async这样的方法，而不是裸的线程，这是因为async可以获得返回的结果。总结而言，C++11新引入的并发元素有： 任务、期值、线程、互斥量条件变量和原子对象等一套。 thread_local线程一个重要的概念就是线程的局部变量，因为局部变量的创建与普通的C++变量创建时机是不一样的，仅在线程使用变量时才会创建，且每个线程创建一次。部分内容可以参考：http://cifangyiquan.net/programming/thread_local/.我们看以下例子来了解下thread_local这一关键字的重要作用：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;thread&gt;//This function will be called from a threadclass A&#123;public: int data=0; void p(int i)&#123; data += i; std::cout &lt;&lt; data &lt;&lt; std::endl; &#125;&#125;;thread_local A a;void call_from_thread(A&amp; a, int i) &#123; a.p(i);&#125;int main() &#123; //Launch a thread std::thread t1(call_from_thread, std::ref(a), 1); std::thread t2(call_from_thread, std::ref(a), 3); //Join the thread with the main thread t1.join(); t2.join(); return 0;&#125;// 输出结果// 3// 4 稍微改变一下：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;thread&gt;//This function will be called from a threadclass A&#123;public: int data=0; void p(int i)&#123; data += i; std::cout &lt;&lt; data &lt;&lt; std::endl; &#125;&#125;;thread_local A a;void call_from_thread(int i) &#123; a.p(i);&#125;int main() &#123; //Launch a thread std::thread t1(call_from_thread, 1); std::thread t2(call_from_thread, 3); //Join the thread with the main thread t1.join(); t2.join(); return 0;&#125;// 输出结果// 1// 3 为什么呢？这是因为第一种通过ref调用的方式，a是在主线程创建并传递到子线程的，而第二种方式，则是在线程创建时，每个线程创建时才创建的a。为了展示这一过程，我们将构造函数和析构函数打印出来：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;//This function will be called from a threadstd::mutex cout_mutex; class A&#123;public: int data=0; A()&#123; cout_mutex.lock(); std::cout &lt;&lt; &quot;ID: &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;Object A Constructed&quot; &lt;&lt; std::endl; cout_mutex.unlock(); &#125; ~A()&#123; cout_mutex.lock(); std::cout &lt;&lt; &quot;ID: &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;Object A Destroyed&quot; &lt;&lt; std::endl; cout_mutex.unlock(); &#125; void p(int i)&#123; data += i; std::cout &lt;&lt; data &lt;&lt; std::endl; &#125;&#125;;thread_local A a;void call_from_thread(int i) &#123; std::cout &lt;&lt; &quot;ID: &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot; Thread created&quot; &lt;&lt; std::endl; a.p(i);&#125;int main() &#123; //Launch a thread std::thread t1(call_from_thread, 1); std::thread t2(call_from_thread, 3); //Join the thread with the main thread t1.join(); t2.join(); return 0;&#125;// 输出结果ID: 140123813201664 Thread created ID: 140123813201664Object A Constructed 3 ID: 140123813201664Object A DestroyedID: 140123821594368 Thread createdID: 140123821594368Object A Constructed1 ID: 140123821594368Object A Destroyed]]></content>
      <categories>
        <category>语言基础</category>
        <category>C++</category>
      </categories>
  </entry>
</search>
